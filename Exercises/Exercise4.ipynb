{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_Text_Representation_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8C8XaaSrrb6T",
        "m1FM2CMTQf8w"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a3195a23a37842c29a5ba37068343d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07c4a0c773d64f65abb2e6d3eb8e993f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24ddab00c1474b409277b54d58ac09dd",
              "IPY_MODEL_91de5b7e432341e893f097490670ebae"
            ]
          }
        },
        "07c4a0c773d64f65abb2e6d3eb8e993f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24ddab00c1474b409277b54d58ac09dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94492cfe7d1e4af9a6535f6ea6a24770",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0055612cdcd44e87ba966ac9c10710b8"
          }
        },
        "91de5b7e432341e893f097490670ebae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a783d35aef684db09ae5a361e552be2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.61MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_747c45b058284ba2a227e783a44969f9"
          }
        },
        "94492cfe7d1e4af9a6535f6ea6a24770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0055612cdcd44e87ba966ac9c10710b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a783d35aef684db09ae5a361e552be2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "747c45b058284ba2a227e783a44969f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63fa76c345c74bdba28f3e7ffda823ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_600a917abd22471ab10c53e105033421",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45c41b25d06c4234bdf05a5922893440",
              "IPY_MODEL_284c18ebeec4435a98788755600cacd9"
            ]
          }
        },
        "600a917abd22471ab10c53e105033421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45c41b25d06c4234bdf05a5922893440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e867e2ffc7a2411ebbcf33f9512967b4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55d61e4eb5664032890b584fa62e2eb1"
          }
        },
        "284c18ebeec4435a98788755600cacd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_440655ae618343d79ce5b7284f0b6a7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 158B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e71841678fe747488d38392a1393fe63"
          }
        },
        "e867e2ffc7a2411ebbcf33f9512967b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55d61e4eb5664032890b584fa62e2eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "440655ae618343d79ce5b7284f0b6a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e71841678fe747488d38392a1393fe63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77a24b04bfa64a20af469694d619d5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a0348151f5049f09a8a2b16b409c571",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_441fa1b39cd84edca6e286d91d26816c",
              "IPY_MODEL_9ceaed202aef45e39a1ebc3e96b0663f"
            ]
          }
        },
        "6a0348151f5049f09a8a2b16b409c571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "441fa1b39cd84edca6e286d91d26816c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_afc58290a4cc47b98893bca868a08444",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de855821f6d442ecb80d1db5b529d67d"
          }
        },
        "9ceaed202aef45e39a1ebc3e96b0663f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f656695e9384a469f047817f7554714",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 5.31MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42f0bc82f4fa48ad9f5fcbb75cc9bc43"
          }
        },
        "afc58290a4cc47b98893bca868a08444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de855821f6d442ecb80d1db5b529d67d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f656695e9384a469f047817f7554714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42f0bc82f4fa48ad9f5fcbb75cc9bc43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb897cf8f59242c29ac300500cd3f6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_441c6a4c57a744a49c8a59c492e5a529",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e84f73b2ad8641d18e98276f9256fab0",
              "IPY_MODEL_910db535450f4e99bdce1792dfe802f4"
            ]
          }
        },
        "441c6a4c57a744a49c8a59c492e5a529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e84f73b2ad8641d18e98276f9256fab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8fa475d6df647cdafa09684f017119b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbf4b497b31a47a183cc12529917d0d6"
          }
        },
        "910db535450f4e99bdce1792dfe802f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c3eacc345fa49f3837e48829cf7f54c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 8.61kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c771381539440c48a30061d598fcecb"
          }
        },
        "e8fa475d6df647cdafa09684f017119b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbf4b497b31a47a183cc12529917d0d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c3eacc345fa49f3837e48829cf7f54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c771381539440c48a30061d598fcecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e6db1582de445f19a937ed4e9dbd442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_677abc3389b9408ca2b9be199016706b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0d27e816c2b94e14be6274b047ea3b2d",
              "IPY_MODEL_0d05bac4fd244acfb1eb6359e778af0d"
            ]
          }
        },
        "677abc3389b9408ca2b9be199016706b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d27e816c2b94e14be6274b047ea3b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_510d9d917cca4dc19f2c5f926b536ee9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_516aab789ca24ca9b6c174b66c07b0f2"
          }
        },
        "0d05bac4fd244acfb1eb6359e778af0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd82065432ea43729e96c3148a4cb6e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6dfa41f42314808a3c410c2ff593f59"
          }
        },
        "510d9d917cca4dc19f2c5f926b536ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "516aab789ca24ca9b6c174b66c07b0f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd82065432ea43729e96c3148a4cb6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6dfa41f42314808a3c410c2ff593f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C-JoGit/Zalando_Analytics_HWR_BIPM/blob/main/Exercises/Exercise4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EijbeBX0qx_H"
      },
      "source": [
        "# Exercise 4. Text Representation Part 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toZg6eERq72W"
      },
      "source": [
        "In this exercise we will apply the following models to the stemmed data from Exercise 2:\n",
        "\n",
        "1.   Word2Vec\n",
        "2.   Doc2vec\n",
        "3.   BERT\n",
        "\n",
        "At the end, we will derive a corpus with each of them which can be used in downstream tasks such as classification and clustering (see next exercises).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ja1Ri6c1lG",
        "outputId": "b63f5721-2da1-4484-b9c9-133922946e93"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\r\u001b[K     |▏                               | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 27.4MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 31.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 33.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 35.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 36.7MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 36.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 36.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 37.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 102kB 38.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 112kB 38.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 38.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 133kB 38.1MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 38.1MB/s eta 0:00:01\r\u001b[K     |██                              | 153kB 38.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 38.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 174kB 38.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 184kB 38.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 194kB 38.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 204kB 38.1MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 38.1MB/s eta 0:00:01\r\u001b[K     |███                             | 225kB 38.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 235kB 38.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 245kB 38.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 256kB 38.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 266kB 38.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 276kB 38.1MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 38.1MB/s eta 0:00:01\r\u001b[K     |████                            | 296kB 38.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 307kB 38.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 317kB 38.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 327kB 38.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 337kB 38.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 348kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 368kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 378kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 389kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 399kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 409kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 419kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 440kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 450kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 460kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 471kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 481kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 491kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 501kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 512kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 522kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 532kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 542kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 552kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 563kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 573kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 583kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 593kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 604kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 614kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 624kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 634kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 645kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 655kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 665kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 675kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 686kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 696kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 706kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 716kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 727kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 737kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 747kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 757kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 768kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 778kB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 788kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 798kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 808kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 819kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 829kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 839kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 849kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 860kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 870kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 880kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 890kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 901kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 911kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 921kB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 931kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 942kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 952kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 962kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 972kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 983kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 993kB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.8MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 38.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 38.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPiuxK5jrVM4"
      },
      "source": [
        "# Import packages\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.spatial.distance import cosine\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk2E1gjxrXxj"
      },
      "source": [
        "## 0. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKLv-1vX-mRI",
        "outputId": "d2c86141-4089-453d-9290-18729fb43745"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKnjwa_mu-hN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69d8c35-aaf7-45a4-a5db-3e9f32a27acd"
      },
      "source": [
        "# Import dataset\n",
        "data_lemma=pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/lemma.pkl\", \"rb\"))\n",
        "print(data_lemma[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car wonder enlighten car see day door sport car look late early call bricklin door small addition bumper separate rest body know tellme model engine specs year production car history info funky looking car mail thank\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C8XaaSrrb6T"
      },
      "source": [
        "## 1. Word2Vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdV3nVDJaYkc"
      },
      "source": [
        "In this section we will train the word2vec model on the lemmatized data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CmhI73QwURO"
      },
      "source": [
        "# Prepare the dataset for the word2vec model\n",
        "corpus_gen=[doc.split() for doc in data_lemma]\n",
        "\n",
        "# Train the model for embeddings of size 100 considering words appearing in more than 566 documents, default window=5\n",
        "model = Word2Vec(corpus_gen, size=100, min_count=566)\n",
        "model.save('word2vec.model')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkOJS7nV216t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e9dd29-5134-4375-f1d8-125011b6500d"
      },
      "source": [
        "print([i for i in sorted(model.wv.vocab.keys())])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['able', 'accept', 'access', 'act', 'action', 'actually', 'add', 'address', 'advance', 'ago', 'agree', 'allow', 'american', 'answer', 'anybody', 'appear', 'apple', 'application', 'apply', 'appreciate', 'apr', 'april', 'area', 'argument', 'armenian', 'armenians', 'article', 'ask', 'assume', 'atheist', 'attack', 'available', 'away', 'bad', 'base', 'begin', 'believe', 'bible', 'big', 'bike', 'bit', 'black', 'board', 'body', 'book', 'box', 'break', 'bring', 'build', 'buy', 'call', 'car', 'card', 'care', 'carry', 'case', 'cause', 'center', 'certain', 'certainly', 'change', 'check', 'child', 'chip', 'christ', 'christian', 'christians', 'church', 'city', 'claim', 'clear', 'clinton', 'clipper', 'close', 'code', 'color', 'com', 'come', 'comment', 'company', 'consider', 'contact', 'contain', 'continue', 'control', 'copy', 'correct', 'cost', 'country', 'couple', 'course', 'cover', 'create', 'crime', 'current', 'data', 'date', 'datum', 'david', 'day', 'deal', 'death', 'decide', 'design', 'device', 'die', 'difference', 'different', 'discussion', 'disk', 'display', 'dos', 'drive', 'driver', 'drug', 'early', 'earth', 'easy', 'edu', 'effect', 'email', 'encryption', 'end', 'entry', 'error', 'event', 'evidence', 'example', 'exist', 'expect', 'experience', 'explain', 'face', 'fact', 'faith', 'faq', 'far', 'fast', 'fax', 'feel', 'figure', 'file', 'follow', 'force', 'form', 'format', 'free', 'friend', 'ftp', 'function', 'game', 'general', 'get', 'give', 'go', 'goal', 'god', 'good', 'gov', 'government', 'graphic', 'great', 'ground', 'group', 'guess', 'gun', 'guy', 'hand', 'happen', 'hard', 'hardware', 'have', 'head', 'hear', 'hell', 'help', 'high', 'history', 'hit', 'hockey', 'hold', 'home', 'hope', 'house', 'human', 'ibm', 'idea', 'image', 'important', 'include', 'individual', 'info', 'information', 'instead', 'interested', 'internet', 'involve', 'isn', 'israel', 'israeli', 'issue', 'jesus', 'jewish', 'jews', 'job', 'john', 'key', 'kill', 'kind', 'know', 'large', 'later', 'law', 'lead', 'learn', 'leave', 'let', 'level', 'life', 'light', 'like', 'likely', 'line', 'list', 'little', 'live', 'local', 'long', 'look', 'lose', 'lot', 'love', 'low', 'mac', 'machine', 'mail', 'major', 'make', 'man', 'mark', 'matter', 'max', 'maybe', 'mean', 'member', 'memory', 'mention', 'message', 'michael', 'mike', 'mind', 'mit', 'mode', 'model', 'money', 'monitor', 'month', 'nasa', 'national', 'need', 'net', 'netcom', 'network', 'new', 'news', 'non', 'note', 'number', 'offer', 'old', 'open', 'opinion', 'order', 'org', 'original', 'output', 'package', 'pass', 'paul', 'pay', 'people', 'period', 'person', 'phone', 'place', 'plan', 'play', 'player', 'point', 'police', 'position', 'possible', 'post', 'power', 'present', 'president', 'press', 'pretty', 'price', 'probably', 'problem', 'product', 'program', 'protect', 'provide', 'pub', 'public', 'purpose', 'question', 'quote', 'rate', 'read', 'real', 'reason', 'receive', 'reference', 'release', 'religion', 'remember', 'reply', 'report', 'request', 'require', 'research', 'result', 'return', 'right', 'rule', 'run', 'sale', 'save', 'say', 'school', 'science', 'screen', 'scsi', 'season', 'second', 'security', 'see', 'sell', 'send', 'sense', 'server', 'service', 'set', 'short', 'show', 'similar', 'simple', 'simply', 'single', 'site', 'situation', 'size', 'small', 'software', 'sort', 'sound', 'source', 'space', 'speak', 'speed', 'stand', 'standard', 'start', 'state', 'statement', 'steve', 'stop', 'study', 'stuff', 'subject', 'suggest', 'sun', 'support', 'suppose', 'sure', 'system', 'take', 'talk', 'team', 'technology', 'tell', 'term', 'test', 'text', 'thank', 'thing', 'think', 'time', 'today', 'true', 'truth', 'try', 'turkish', 'turn', 'type', 'understand', 'university', 'use', 'user', 'uucp', 'value', 'version', 'video', 'view', 'want', 'war', 'washington', 'way', 'weapon', 'week', 'well', 'white', 'win', 'window', 'windows', 'woman', 'wonder', 'word', 'work', 'world', 'wouldn', 'write', 'wrong', 'year', 'yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61g8-b1xN6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc735d9-3324-4fb8-83da-6bf8bf9fe2b3"
      },
      "source": [
        "# Embedding for 'car'\n",
        "vector = model.wv['car']\n",
        "vector"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.6109092 ,  1.3330501 , -1.3809166 ,  0.76868606,  0.06161551,\n",
              "       -0.21493743,  0.08975235,  0.6029217 ,  1.0982993 ,  0.07122575,\n",
              "       -1.3275511 , -1.0173836 ,  0.45278516, -1.2391918 , -0.6974798 ,\n",
              "        0.56633997,  1.5104824 ,  0.6253911 ,  0.9597482 , -1.5507442 ,\n",
              "       -1.4778956 , -1.0247847 , -0.7961584 , -0.5562887 ,  0.63455874,\n",
              "       -1.1249799 , -1.7093805 ,  0.2777721 ,  1.2156094 , -0.85552096,\n",
              "        0.19843642,  1.7316579 , -0.30975705, -0.06821839, -1.2790812 ,\n",
              "        0.3186357 , -0.5643113 , -1.4352485 ,  0.08280188,  0.14729495,\n",
              "        0.21802603, -0.9665456 ,  1.1950902 ,  0.51323384,  0.6008748 ,\n",
              "        0.24895026, -1.425857  ,  1.0360487 ,  0.17624019, -0.84510106,\n",
              "       -0.22483894,  0.60674095, -0.3922483 ,  0.82571435,  0.804116  ,\n",
              "        0.33028728,  0.13911949,  1.6067307 , -0.55362195, -0.89019895,\n",
              "       -0.22220126,  0.44630054,  0.8836802 , -1.8297411 ,  0.52251315,\n",
              "       -0.5769102 , -0.48168692, -1.1687733 , -1.6857878 , -1.5454416 ,\n",
              "       -0.81727856, -0.31668982,  0.6364156 ,  0.6348376 ,  1.260281  ,\n",
              "       -0.9109318 ,  0.2840755 ,  0.00968547,  0.1443345 , -0.99385786,\n",
              "       -0.7155298 , -0.73612726, -0.30639604,  1.0601127 , -1.4684869 ,\n",
              "       -0.11666249,  0.13751012, -0.09740931,  0.2299623 ,  0.58012307,\n",
              "        0.22070661, -0.6334114 , -1.4330103 , -0.0271429 ,  0.6529474 ,\n",
              "        0.552658  ,  1.8685205 ,  0.9459253 , -1.0135702 , -1.4024595 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXNcOMaEy_w7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b236df6a-3198-44da-a017-0d41ab1d3277"
      },
      "source": [
        "# Most similar representations to 'car' based on cosine similarity\n",
        "model.wv.most_similar('car')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bike', 0.6022545695304871),\n",
              " ('buy', 0.5634679794311523),\n",
              " ('get', 0.5026164054870605),\n",
              " ('speed', 0.4842330813407898),\n",
              " ('light', 0.4688034653663635),\n",
              " ('turn', 0.45954322814941406),\n",
              " ('pay', 0.4526820480823517),\n",
              " ('friend', 0.4401146173477173),\n",
              " ('guy', 0.4394468069076538),\n",
              " ('figure', 0.4387744069099426)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYduazP05lH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455fbedc-58a0-4621-99ed-89f4e37ad7ea"
      },
      "source": [
        "# Embeddings' arithmetics\n",
        "model.wv.most_similar(positive=['bike', 'machine'], topn=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('buy', 0.6576911211013794)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8OM3aCWvEZC"
      },
      "source": [
        "In the following we will derive the corpus. Note that word2vec (as opposed to doc2vec) generates one embedding for each word in the document. These then need to be aggregated at a document level. The simplest way is to determine the average over all words, but you can also use other aggregators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFBqJ2VS2rYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863dca0f-d1ab-4067-dff8-f7c786abc584"
      },
      "source": [
        "# Document representation for the text\n",
        "corpus_w2v=[[model.wv[word] for word in doc if word in model.wv.vocab.keys()] for doc in corpus_gen]\n",
        "positive=[i for i in range(len(corpus_gen)) if len(corpus_w2v[i])>0]\n",
        "\n",
        "corpus_w2v2=[corpus_w2v[i] for i in positive]\n",
        "data_lemma2=[data_lemma[i] for i in positive]\n",
        "\n",
        "# Document average representation\n",
        "corpus_w2v_avg_clean=[sum(words)/len(words) for words in corpus_w2v2]\n",
        "\n",
        "# This corpus can be used later in clustering and classification tasks\n",
        "print(corpus_w2v_avg_clean[10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.14873949  0.02097726 -0.03202476  0.01849939 -0.50044674 -0.661097\n",
            "  0.47235054  0.23082788  0.2311119  -0.37507364 -0.1644413  -0.41786528\n",
            " -0.49764758 -0.16024014 -0.18873264  0.03298237  0.3168346   0.01432757\n",
            "  0.06435312 -0.5995266  -0.03951619  0.0548044  -0.43617597  0.08818642\n",
            "  0.2267098   0.03535873 -0.52702165 -0.03133269 -0.2134932  -0.30461583\n",
            " -0.0557395   0.58988094  0.02019771 -0.12913556 -0.09264978  0.24552904\n",
            "  0.18652423  0.21345684 -0.12243894  0.29940176 -0.11727002  0.02341542\n",
            " -0.40388682  0.37229824  0.18009521 -0.04752867 -0.1744095   0.14383641\n",
            "  0.49741048  0.30134234 -0.24714772 -0.31985456  0.2178731  -0.11193708\n",
            " -0.08371949  0.11823459  0.03852409  0.328524    0.11106371  0.06652474\n",
            " -0.42896995  0.10074733  0.00410577 -0.25970107  0.03383336  0.27288067\n",
            " -0.0936849  -0.10606506 -0.21589877 -0.46932176 -0.10034835 -0.15499108\n",
            "  0.22964504 -0.06628765 -0.18045184 -0.2491117   0.333259    0.22237097\n",
            " -0.41053253 -0.19132157 -0.10518885 -0.2265482   0.15700208 -0.09030946\n",
            " -0.24411698 -0.07526577  0.34166262  0.16485932  0.076231    0.03852306\n",
            " -0.08754321  0.2040941  -0.37593928  0.24829601 -0.04039578  0.23492874\n",
            "  0.56335646  0.41065443 -0.03189725 -0.44467834]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKUP2dEI-y51",
        "outputId": "c9058389-6bd7-4d2f-e5c4-7cc1128b6393"
      },
      "source": [
        "len(corpus_w2v)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p2H3WBAAdLk",
        "outputId": "77ac445b-d7ec-464b-9d9b-5d1f594c2b60"
      },
      "source": [
        "len(corpus_w2v_avg_clean)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olxITXGWBBw8",
        "outputId": "37094e4a-f774-47ff-ea1b-558dda745cb8"
      },
      "source": [
        "len(data_lemma2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp3DPPMfvduE",
        "outputId": "281a40e4-a010-415f-8d59-0fd28e9294e0"
      },
      "source": [
        "model.wv.similar_by_vector(corpus_w2v_avg_clean[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('car', 0.8668628931045532),\n",
              " ('friend', 0.5587462186813354),\n",
              " ('bike', 0.5526930093765259),\n",
              " ('get', 0.5419541597366333),\n",
              " ('buy', 0.5166246294975281),\n",
              " ('month', 0.4957149028778076),\n",
              " ('lot', 0.4892970025539398),\n",
              " ('see', 0.47523200511932373),\n",
              " ('light', 0.47500720620155334),\n",
              " ('couple', 0.46947041153907776)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdDZTUaCVx7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f6f345-786d-4a32-985f-d27b511e86b4"
      },
      "source": [
        "# Most simlar words to the document based on average representation\n",
        "# This can be used to evaluate different aggregation methods and also provides interpretation of the document representation\n",
        "print([token for (token,_) in model.wv.similar_by_vector(corpus_w2v_avg_clean[0])])\n",
        "\n",
        "# cosine similarity to other documents\n",
        "result=[(1 - cosine(corpus_w2v_avg_clean[0],corpus_w2v_avg_clean[i])) for i in range(1,len(corpus_w2v_avg_clean))]\n",
        "most_similar=data_lemma2[result.index(max(result))+1]\n",
        "print(data_lemma2[0])\n",
        "print('')\n",
        "print(most_similar)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['car', 'friend', 'bike', 'get', 'buy', 'month', 'lot', 'see', 'light', 'couple']\n",
            "car wonder enlighten car see day door sport car look late early call bricklin door small addition bumper separate rest body know tellme model engine specs year production car history info funky looking car mail thank\n",
            "\n",
            "aussie need info car show australia car enthusiast australia particularly interested american muscle car make amc ford chrysler mopar usa weeks june chicago sun thursday denver friday sunday austin texas monday friday oklahoma city friday monday anaheim california tuesday thursday las vegas nevada friday sunday grand canion monday tuesday june las angeles san diego vicinity wednesday june sunday june june south lake tahoe cal sunday june wednesday june reno thursday june san fransisco thursday june sunday june wonder send information car show swap meets drag meet model car show period anybody tell pomona swap meet year place visit car museum private collection collection bit information appreciate interested find model car scale model interste amc car particular amx javelin scrambler rebel machine kit plastic diecast interested selling tell interested send bring model australian high performance car interest reply email johnt spri level unisa edu thanks john tsimbinos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sutGaxDrBite",
        "outputId": "894746b6-383c-47b3-bf6a-c08bdb5069de"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk3iCFMnVPco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "f57a9b54-ce1b-4dc0-a61a-b96fcafd2fd8"
      },
      "source": [
        "# Corpus as data frame that can be used in downstream tasks such as classification\n",
        "corpus_w2v_avg_df=pd.DataFrame(corpus_w2v_avg_clean)\n",
        "corpus_w2v_avg_df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.431838</td>\n",
              "      <td>0.554915</td>\n",
              "      <td>-0.473366</td>\n",
              "      <td>0.348348</td>\n",
              "      <td>-0.018400</td>\n",
              "      <td>-0.339263</td>\n",
              "      <td>-0.183222</td>\n",
              "      <td>0.476204</td>\n",
              "      <td>0.261883</td>\n",
              "      <td>0.104020</td>\n",
              "      <td>-0.463734</td>\n",
              "      <td>0.034340</td>\n",
              "      <td>-0.193403</td>\n",
              "      <td>-0.199116</td>\n",
              "      <td>-0.295663</td>\n",
              "      <td>0.107863</td>\n",
              "      <td>0.625886</td>\n",
              "      <td>0.189125</td>\n",
              "      <td>0.058026</td>\n",
              "      <td>-0.390009</td>\n",
              "      <td>-0.572118</td>\n",
              "      <td>-0.283647</td>\n",
              "      <td>-0.239579</td>\n",
              "      <td>-0.016996</td>\n",
              "      <td>0.056712</td>\n",
              "      <td>-0.304037</td>\n",
              "      <td>-0.582649</td>\n",
              "      <td>0.182191</td>\n",
              "      <td>0.191718</td>\n",
              "      <td>-0.246879</td>\n",
              "      <td>-0.074590</td>\n",
              "      <td>0.549232</td>\n",
              "      <td>-0.400909</td>\n",
              "      <td>-0.293866</td>\n",
              "      <td>-0.499848</td>\n",
              "      <td>-0.058122</td>\n",
              "      <td>0.041033</td>\n",
              "      <td>-0.380195</td>\n",
              "      <td>-0.023467</td>\n",
              "      <td>0.222867</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.236732</td>\n",
              "      <td>0.134452</td>\n",
              "      <td>0.381511</td>\n",
              "      <td>-0.547509</td>\n",
              "      <td>-0.032724</td>\n",
              "      <td>0.080252</td>\n",
              "      <td>-0.278591</td>\n",
              "      <td>-0.450295</td>\n",
              "      <td>-0.566273</td>\n",
              "      <td>-0.369666</td>\n",
              "      <td>0.110985</td>\n",
              "      <td>0.126148</td>\n",
              "      <td>0.016420</td>\n",
              "      <td>0.200239</td>\n",
              "      <td>0.468257</td>\n",
              "      <td>-0.259085</td>\n",
              "      <td>-0.061002</td>\n",
              "      <td>0.181229</td>\n",
              "      <td>-0.056870</td>\n",
              "      <td>-0.376331</td>\n",
              "      <td>-0.049177</td>\n",
              "      <td>-0.148495</td>\n",
              "      <td>-0.138359</td>\n",
              "      <td>0.267975</td>\n",
              "      <td>-0.497886</td>\n",
              "      <td>0.058346</td>\n",
              "      <td>-0.209580</td>\n",
              "      <td>0.109051</td>\n",
              "      <td>0.330032</td>\n",
              "      <td>0.035222</td>\n",
              "      <td>0.055810</td>\n",
              "      <td>-0.292968</td>\n",
              "      <td>-0.611761</td>\n",
              "      <td>-0.077148</td>\n",
              "      <td>0.261068</td>\n",
              "      <td>-0.032985</td>\n",
              "      <td>0.787022</td>\n",
              "      <td>0.283526</td>\n",
              "      <td>-0.294245</td>\n",
              "      <td>-0.557787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.565932</td>\n",
              "      <td>0.022020</td>\n",
              "      <td>-0.158700</td>\n",
              "      <td>0.265362</td>\n",
              "      <td>-0.227214</td>\n",
              "      <td>-0.505071</td>\n",
              "      <td>-0.028102</td>\n",
              "      <td>0.279170</td>\n",
              "      <td>-0.012853</td>\n",
              "      <td>0.123492</td>\n",
              "      <td>-0.127158</td>\n",
              "      <td>-0.125798</td>\n",
              "      <td>0.123329</td>\n",
              "      <td>0.084097</td>\n",
              "      <td>0.146630</td>\n",
              "      <td>-0.105508</td>\n",
              "      <td>-0.252665</td>\n",
              "      <td>0.235758</td>\n",
              "      <td>0.031799</td>\n",
              "      <td>-0.021608</td>\n",
              "      <td>-0.254935</td>\n",
              "      <td>-0.170193</td>\n",
              "      <td>-0.183221</td>\n",
              "      <td>0.292699</td>\n",
              "      <td>0.161802</td>\n",
              "      <td>0.090474</td>\n",
              "      <td>0.054026</td>\n",
              "      <td>-0.022362</td>\n",
              "      <td>-0.044380</td>\n",
              "      <td>-0.116532</td>\n",
              "      <td>0.137857</td>\n",
              "      <td>0.192450</td>\n",
              "      <td>0.027356</td>\n",
              "      <td>0.190490</td>\n",
              "      <td>0.272204</td>\n",
              "      <td>0.031263</td>\n",
              "      <td>0.084432</td>\n",
              "      <td>0.019332</td>\n",
              "      <td>0.000909</td>\n",
              "      <td>0.129401</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016898</td>\n",
              "      <td>0.047800</td>\n",
              "      <td>-0.032475</td>\n",
              "      <td>-0.046595</td>\n",
              "      <td>0.012133</td>\n",
              "      <td>0.253037</td>\n",
              "      <td>0.309540</td>\n",
              "      <td>0.282954</td>\n",
              "      <td>-0.220799</td>\n",
              "      <td>-0.313654</td>\n",
              "      <td>-0.324893</td>\n",
              "      <td>0.060379</td>\n",
              "      <td>0.243885</td>\n",
              "      <td>0.096802</td>\n",
              "      <td>-0.216924</td>\n",
              "      <td>-0.159189</td>\n",
              "      <td>-0.124687</td>\n",
              "      <td>-0.009255</td>\n",
              "      <td>-0.084051</td>\n",
              "      <td>-0.169770</td>\n",
              "      <td>0.211311</td>\n",
              "      <td>-0.141519</td>\n",
              "      <td>0.239964</td>\n",
              "      <td>0.036097</td>\n",
              "      <td>0.102962</td>\n",
              "      <td>-0.003999</td>\n",
              "      <td>-0.006897</td>\n",
              "      <td>0.158554</td>\n",
              "      <td>0.252246</td>\n",
              "      <td>0.051677</td>\n",
              "      <td>0.031839</td>\n",
              "      <td>0.211974</td>\n",
              "      <td>-0.426352</td>\n",
              "      <td>-0.131084</td>\n",
              "      <td>0.286821</td>\n",
              "      <td>-0.200112</td>\n",
              "      <td>0.249652</td>\n",
              "      <td>0.216993</td>\n",
              "      <td>0.027926</td>\n",
              "      <td>-0.435021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.200032</td>\n",
              "      <td>0.082920</td>\n",
              "      <td>0.035689</td>\n",
              "      <td>0.056912</td>\n",
              "      <td>-0.071762</td>\n",
              "      <td>-0.456534</td>\n",
              "      <td>0.092231</td>\n",
              "      <td>0.182064</td>\n",
              "      <td>0.049008</td>\n",
              "      <td>-0.102243</td>\n",
              "      <td>-0.191550</td>\n",
              "      <td>-0.078892</td>\n",
              "      <td>-0.305604</td>\n",
              "      <td>0.159843</td>\n",
              "      <td>0.046580</td>\n",
              "      <td>-0.129662</td>\n",
              "      <td>0.114227</td>\n",
              "      <td>0.106086</td>\n",
              "      <td>-0.138237</td>\n",
              "      <td>-0.181097</td>\n",
              "      <td>-0.251417</td>\n",
              "      <td>0.003998</td>\n",
              "      <td>-0.219730</td>\n",
              "      <td>0.220798</td>\n",
              "      <td>-0.069019</td>\n",
              "      <td>0.252755</td>\n",
              "      <td>-0.169710</td>\n",
              "      <td>0.065510</td>\n",
              "      <td>-0.024233</td>\n",
              "      <td>-0.287221</td>\n",
              "      <td>-0.127491</td>\n",
              "      <td>0.365946</td>\n",
              "      <td>0.077198</td>\n",
              "      <td>-0.143094</td>\n",
              "      <td>0.005304</td>\n",
              "      <td>0.004201</td>\n",
              "      <td>0.188143</td>\n",
              "      <td>0.074862</td>\n",
              "      <td>0.123630</td>\n",
              "      <td>0.516551</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.142152</td>\n",
              "      <td>-0.017457</td>\n",
              "      <td>-0.051287</td>\n",
              "      <td>0.040982</td>\n",
              "      <td>-0.208166</td>\n",
              "      <td>0.354930</td>\n",
              "      <td>0.076283</td>\n",
              "      <td>0.030184</td>\n",
              "      <td>-0.049415</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.014660</td>\n",
              "      <td>-0.050442</td>\n",
              "      <td>0.302029</td>\n",
              "      <td>-0.136115</td>\n",
              "      <td>-0.098770</td>\n",
              "      <td>-0.281404</td>\n",
              "      <td>-0.166820</td>\n",
              "      <td>0.207283</td>\n",
              "      <td>-0.371864</td>\n",
              "      <td>-0.086545</td>\n",
              "      <td>0.045530</td>\n",
              "      <td>-0.114873</td>\n",
              "      <td>-0.054142</td>\n",
              "      <td>0.019535</td>\n",
              "      <td>-0.152330</td>\n",
              "      <td>-0.063802</td>\n",
              "      <td>0.149671</td>\n",
              "      <td>0.004373</td>\n",
              "      <td>0.125275</td>\n",
              "      <td>0.126435</td>\n",
              "      <td>-0.066584</td>\n",
              "      <td>0.020336</td>\n",
              "      <td>-0.120725</td>\n",
              "      <td>-0.117072</td>\n",
              "      <td>0.245615</td>\n",
              "      <td>-0.107552</td>\n",
              "      <td>0.147411</td>\n",
              "      <td>0.175608</td>\n",
              "      <td>0.069617</td>\n",
              "      <td>-0.267371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.160912</td>\n",
              "      <td>0.136576</td>\n",
              "      <td>0.109901</td>\n",
              "      <td>-0.071512</td>\n",
              "      <td>-0.074774</td>\n",
              "      <td>-0.101220</td>\n",
              "      <td>-0.064318</td>\n",
              "      <td>0.103438</td>\n",
              "      <td>-0.130130</td>\n",
              "      <td>0.090833</td>\n",
              "      <td>0.054140</td>\n",
              "      <td>-0.158247</td>\n",
              "      <td>0.045144</td>\n",
              "      <td>-0.039138</td>\n",
              "      <td>0.066327</td>\n",
              "      <td>0.320677</td>\n",
              "      <td>-0.320255</td>\n",
              "      <td>0.137952</td>\n",
              "      <td>0.055627</td>\n",
              "      <td>-0.021837</td>\n",
              "      <td>0.014825</td>\n",
              "      <td>0.119302</td>\n",
              "      <td>0.069419</td>\n",
              "      <td>0.040153</td>\n",
              "      <td>0.236112</td>\n",
              "      <td>0.293467</td>\n",
              "      <td>-0.264766</td>\n",
              "      <td>-0.034988</td>\n",
              "      <td>-0.044967</td>\n",
              "      <td>-0.264113</td>\n",
              "      <td>0.006071</td>\n",
              "      <td>0.283053</td>\n",
              "      <td>-0.184789</td>\n",
              "      <td>0.084338</td>\n",
              "      <td>0.148789</td>\n",
              "      <td>0.102815</td>\n",
              "      <td>0.055481</td>\n",
              "      <td>0.117734</td>\n",
              "      <td>0.115995</td>\n",
              "      <td>-0.096065</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.165093</td>\n",
              "      <td>0.377994</td>\n",
              "      <td>0.082963</td>\n",
              "      <td>-0.225038</td>\n",
              "      <td>-0.056618</td>\n",
              "      <td>0.057364</td>\n",
              "      <td>-0.186196</td>\n",
              "      <td>-0.097822</td>\n",
              "      <td>0.073737</td>\n",
              "      <td>-0.222788</td>\n",
              "      <td>-0.275767</td>\n",
              "      <td>-0.170693</td>\n",
              "      <td>0.452746</td>\n",
              "      <td>-0.057721</td>\n",
              "      <td>-0.362362</td>\n",
              "      <td>-0.190018</td>\n",
              "      <td>0.264088</td>\n",
              "      <td>0.366123</td>\n",
              "      <td>-0.094306</td>\n",
              "      <td>-0.055067</td>\n",
              "      <td>0.078254</td>\n",
              "      <td>-0.053449</td>\n",
              "      <td>-0.341444</td>\n",
              "      <td>-0.006161</td>\n",
              "      <td>-0.045779</td>\n",
              "      <td>-0.081027</td>\n",
              "      <td>0.377295</td>\n",
              "      <td>0.058653</td>\n",
              "      <td>0.013858</td>\n",
              "      <td>0.292270</td>\n",
              "      <td>0.026712</td>\n",
              "      <td>0.081584</td>\n",
              "      <td>0.024326</td>\n",
              "      <td>0.256704</td>\n",
              "      <td>0.065339</td>\n",
              "      <td>0.292300</td>\n",
              "      <td>0.202322</td>\n",
              "      <td>0.197504</td>\n",
              "      <td>0.279884</td>\n",
              "      <td>-0.189950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.327761</td>\n",
              "      <td>0.182905</td>\n",
              "      <td>0.212345</td>\n",
              "      <td>0.060562</td>\n",
              "      <td>-0.148076</td>\n",
              "      <td>0.141264</td>\n",
              "      <td>0.255315</td>\n",
              "      <td>0.215460</td>\n",
              "      <td>-0.159637</td>\n",
              "      <td>0.119614</td>\n",
              "      <td>-0.012543</td>\n",
              "      <td>-0.212388</td>\n",
              "      <td>-0.026973</td>\n",
              "      <td>0.093226</td>\n",
              "      <td>0.107102</td>\n",
              "      <td>0.011576</td>\n",
              "      <td>-0.561428</td>\n",
              "      <td>0.141061</td>\n",
              "      <td>-0.155791</td>\n",
              "      <td>-0.044034</td>\n",
              "      <td>-0.021383</td>\n",
              "      <td>-0.078656</td>\n",
              "      <td>-0.236567</td>\n",
              "      <td>0.091189</td>\n",
              "      <td>0.290366</td>\n",
              "      <td>0.623660</td>\n",
              "      <td>-0.282102</td>\n",
              "      <td>-0.074444</td>\n",
              "      <td>-0.025233</td>\n",
              "      <td>-0.393009</td>\n",
              "      <td>0.043411</td>\n",
              "      <td>0.276344</td>\n",
              "      <td>0.180421</td>\n",
              "      <td>-0.139247</td>\n",
              "      <td>0.189232</td>\n",
              "      <td>0.226216</td>\n",
              "      <td>-0.052958</td>\n",
              "      <td>0.275459</td>\n",
              "      <td>0.142644</td>\n",
              "      <td>-0.071291</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.117870</td>\n",
              "      <td>0.181709</td>\n",
              "      <td>-0.288382</td>\n",
              "      <td>-0.057900</td>\n",
              "      <td>-0.168090</td>\n",
              "      <td>0.168625</td>\n",
              "      <td>0.062552</td>\n",
              "      <td>0.396909</td>\n",
              "      <td>0.067817</td>\n",
              "      <td>0.029313</td>\n",
              "      <td>-0.272469</td>\n",
              "      <td>-0.180449</td>\n",
              "      <td>0.239860</td>\n",
              "      <td>0.006977</td>\n",
              "      <td>-0.189842</td>\n",
              "      <td>-0.355355</td>\n",
              "      <td>-0.073495</td>\n",
              "      <td>0.002169</td>\n",
              "      <td>0.062991</td>\n",
              "      <td>0.168059</td>\n",
              "      <td>0.183793</td>\n",
              "      <td>-0.383441</td>\n",
              "      <td>-0.470033</td>\n",
              "      <td>-0.110488</td>\n",
              "      <td>0.027732</td>\n",
              "      <td>0.138039</td>\n",
              "      <td>0.344597</td>\n",
              "      <td>0.038892</td>\n",
              "      <td>0.304522</td>\n",
              "      <td>0.409449</td>\n",
              "      <td>-0.203215</td>\n",
              "      <td>0.026743</td>\n",
              "      <td>0.121462</td>\n",
              "      <td>0.050136</td>\n",
              "      <td>0.359521</td>\n",
              "      <td>0.040295</td>\n",
              "      <td>-0.080378</td>\n",
              "      <td>-0.047023</td>\n",
              "      <td>0.453389</td>\n",
              "      <td>-0.132171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        97        98        99\n",
              "0  0.431838  0.554915 -0.473366  ...  0.283526 -0.294245 -0.557787\n",
              "1  0.565932  0.022020 -0.158700  ...  0.216993  0.027926 -0.435021\n",
              "2  0.200032  0.082920  0.035689  ...  0.175608  0.069617 -0.267371\n",
              "3  0.160912  0.136576  0.109901  ...  0.197504  0.279884 -0.189950\n",
              "4  0.327761  0.182905  0.212345  ... -0.047023  0.453389 -0.132171\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1EFSaifCauV",
        "outputId": "509a2443-6e1d-486a-860f-98ff1916c864"
      },
      "source": [
        "len(corpus_w2v_avg_df)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xU9j17DYQu-"
      },
      "source": [
        "pickle.dump(corpus_w2v_avg_df, open(\"/content/drive/MyDrive/Colab Notebooks/WordtoVecModel.pkl\", \"wb\"))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1FM2CMTQf8w"
      },
      "source": [
        "## 2. Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar_f51MHQZL3"
      },
      "source": [
        "# Run doc2vec on the tagged texts\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus_gen)]\n",
        "model2 = Doc2Vec(documents, vector_size=100, min_count=566)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUm1Bfw_R_h_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6371268a-f778-4463-e092-7ee526ffd659"
      },
      "source": [
        "# Embedding for the first document\n",
        "vector = model2.infer_vector(corpus_gen[0])\n",
        "vector"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.04789714,  0.07085122,  0.06939712,  0.05581448, -0.00750191,\n",
              "       -0.10455576, -0.04523741,  0.09602484,  0.09121901, -0.01692073,\n",
              "       -0.07685312,  0.02729572, -0.0545367 ,  0.01446081, -0.05093332,\n",
              "        0.08788661, -0.00073461,  0.05819418,  0.01522579,  0.06609607,\n",
              "       -0.03178501, -0.00318004, -0.01149177, -0.006744  ,  0.02110712,\n",
              "        0.03374053, -0.04595241,  0.01703607, -0.0561133 , -0.03547852,\n",
              "        0.00472683,  0.07527841, -0.07168986, -0.01108005, -0.08198757,\n",
              "        0.03246092,  0.08594696,  0.00258418,  0.01722172, -0.029672  ,\n",
              "       -0.02956345, -0.18091534,  0.04489931,  0.03255635, -0.00533456,\n",
              "        0.03040555, -0.10571268,  0.05677893,  0.06720766,  0.01656134,\n",
              "        0.08023549,  0.01606058, -0.02798738,  0.04438192, -0.03808644,\n",
              "       -0.0331932 , -0.01948151,  0.00779004, -0.05082292, -0.10607371,\n",
              "       -0.07750382,  0.0319143 ,  0.03494918, -0.07328069,  0.02113496,\n",
              "        0.0402196 , -0.04457681, -0.03642835,  0.05391117, -0.05630227,\n",
              "        0.03452469,  0.04601034,  0.00424384,  0.06253432, -0.07336637,\n",
              "       -0.03315108, -0.02868434,  0.06921536, -0.06977397, -0.07639115,\n",
              "       -0.01459873,  0.0692993 , -0.06865013, -0.03739737, -0.00549411,\n",
              "        0.05508673, -0.0115478 ,  0.09925495,  0.0874827 ,  0.03285103,\n",
              "        0.05251783,  0.08597317, -0.04516944,  0.02446413,  0.08678729,\n",
              "        0.01644265,  0.0137026 , -0.03221187,  0.07058884, -0.03742513],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4YP1drRDCLe",
        "outputId": "b9fd09f8-6a35-4c0c-9167-e9a76afb4012"
      },
      "source": [
        "\n",
        "# cosine similarity to other documents\n",
        "result=[(1 - cosine(vector,model2.infer_vector(corpus_gen[i]))) for i in range(1,len(corpus_gen))]\n",
        "most_similar=data_lemma[result.index(max(result))+1]\n",
        "\n",
        "print(most_similar)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mitsubishi hard drive help mitsubishi hard drive help hard disk new mitsubishi hard drive rll mfm storage format suspect switch setting move movement drive place switch setting drive switch switch select drive number info drive know number configure let know email cyl head think type thank advance chuck brown charles brown brown galois nscf org university brown moe coe uga edu augusta georgia cbrowni eis calstate edu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVKFlkydDy4P",
        "outputId": "07cc3318-0c0f-4165-d4e6-3460e86b437c"
      },
      "source": [
        "len(corpus_gen)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmyNi6XVU2o-"
      },
      "source": [
        "# Final corpus for classification\n",
        "corpus_d2v=pd.DataFrame([model2.infer_vector(doc) for doc in corpus_gen])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2SVegMSVP0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "8e831b30-054b-4628-e308-b8ef6142ea22"
      },
      "source": [
        "corpus_d2v.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.033106</td>\n",
              "      <td>0.098918</td>\n",
              "      <td>0.050923</td>\n",
              "      <td>0.045089</td>\n",
              "      <td>-0.016510</td>\n",
              "      <td>-0.083881</td>\n",
              "      <td>-0.041904</td>\n",
              "      <td>0.102570</td>\n",
              "      <td>0.084924</td>\n",
              "      <td>-0.019586</td>\n",
              "      <td>-0.059430</td>\n",
              "      <td>0.016196</td>\n",
              "      <td>-0.042996</td>\n",
              "      <td>-0.020928</td>\n",
              "      <td>-0.047943</td>\n",
              "      <td>0.086731</td>\n",
              "      <td>0.016809</td>\n",
              "      <td>0.059472</td>\n",
              "      <td>0.011163</td>\n",
              "      <td>0.031227</td>\n",
              "      <td>-0.025990</td>\n",
              "      <td>-0.030775</td>\n",
              "      <td>-0.013724</td>\n",
              "      <td>-0.004509</td>\n",
              "      <td>0.048144</td>\n",
              "      <td>0.027729</td>\n",
              "      <td>-0.058544</td>\n",
              "      <td>0.008638</td>\n",
              "      <td>-0.023791</td>\n",
              "      <td>-0.076936</td>\n",
              "      <td>-0.004910</td>\n",
              "      <td>0.090226</td>\n",
              "      <td>-0.069956</td>\n",
              "      <td>-0.016542</td>\n",
              "      <td>-0.077008</td>\n",
              "      <td>0.015614</td>\n",
              "      <td>0.040372</td>\n",
              "      <td>-0.013879</td>\n",
              "      <td>0.041780</td>\n",
              "      <td>-0.025325</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.079405</td>\n",
              "      <td>0.034498</td>\n",
              "      <td>0.020610</td>\n",
              "      <td>-0.097783</td>\n",
              "      <td>0.003420</td>\n",
              "      <td>0.011522</td>\n",
              "      <td>-0.051112</td>\n",
              "      <td>-0.057745</td>\n",
              "      <td>0.030581</td>\n",
              "      <td>-0.049891</td>\n",
              "      <td>0.010007</td>\n",
              "      <td>0.046470</td>\n",
              "      <td>-0.015335</td>\n",
              "      <td>0.065181</td>\n",
              "      <td>-0.062260</td>\n",
              "      <td>-0.021381</td>\n",
              "      <td>-0.024897</td>\n",
              "      <td>0.058858</td>\n",
              "      <td>-0.043589</td>\n",
              "      <td>-0.083691</td>\n",
              "      <td>-0.017372</td>\n",
              "      <td>0.044659</td>\n",
              "      <td>-0.112701</td>\n",
              "      <td>-0.030502</td>\n",
              "      <td>-0.025539</td>\n",
              "      <td>0.064363</td>\n",
              "      <td>0.005199</td>\n",
              "      <td>0.063228</td>\n",
              "      <td>0.074967</td>\n",
              "      <td>0.040241</td>\n",
              "      <td>0.037232</td>\n",
              "      <td>0.067679</td>\n",
              "      <td>-0.034197</td>\n",
              "      <td>0.018707</td>\n",
              "      <td>0.096093</td>\n",
              "      <td>0.004697</td>\n",
              "      <td>0.055006</td>\n",
              "      <td>-0.011854</td>\n",
              "      <td>0.057327</td>\n",
              "      <td>-0.051704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.087314</td>\n",
              "      <td>-0.006708</td>\n",
              "      <td>0.070973</td>\n",
              "      <td>-0.000895</td>\n",
              "      <td>-0.020421</td>\n",
              "      <td>-0.033985</td>\n",
              "      <td>-0.025585</td>\n",
              "      <td>0.037588</td>\n",
              "      <td>-0.011117</td>\n",
              "      <td>0.046840</td>\n",
              "      <td>-0.000195</td>\n",
              "      <td>-0.005179</td>\n",
              "      <td>0.021102</td>\n",
              "      <td>0.026539</td>\n",
              "      <td>-0.007511</td>\n",
              "      <td>-0.024511</td>\n",
              "      <td>-0.044508</td>\n",
              "      <td>0.009384</td>\n",
              "      <td>-0.017811</td>\n",
              "      <td>-0.020195</td>\n",
              "      <td>-0.035385</td>\n",
              "      <td>-0.076433</td>\n",
              "      <td>0.003944</td>\n",
              "      <td>0.042920</td>\n",
              "      <td>-0.014621</td>\n",
              "      <td>0.034137</td>\n",
              "      <td>0.034253</td>\n",
              "      <td>-0.009089</td>\n",
              "      <td>-0.022839</td>\n",
              "      <td>0.001922</td>\n",
              "      <td>-0.018337</td>\n",
              "      <td>-0.031380</td>\n",
              "      <td>0.021241</td>\n",
              "      <td>0.019520</td>\n",
              "      <td>0.005970</td>\n",
              "      <td>0.024516</td>\n",
              "      <td>0.096515</td>\n",
              "      <td>-0.001737</td>\n",
              "      <td>-0.063147</td>\n",
              "      <td>-0.039192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023904</td>\n",
              "      <td>0.017436</td>\n",
              "      <td>-0.040995</td>\n",
              "      <td>0.030023</td>\n",
              "      <td>0.036790</td>\n",
              "      <td>0.096343</td>\n",
              "      <td>0.101129</td>\n",
              "      <td>0.071277</td>\n",
              "      <td>0.014044</td>\n",
              "      <td>-0.089072</td>\n",
              "      <td>0.003651</td>\n",
              "      <td>-0.000497</td>\n",
              "      <td>0.025844</td>\n",
              "      <td>0.090702</td>\n",
              "      <td>-0.055280</td>\n",
              "      <td>-0.039763</td>\n",
              "      <td>-0.093893</td>\n",
              "      <td>0.003165</td>\n",
              "      <td>-0.066528</td>\n",
              "      <td>-0.009757</td>\n",
              "      <td>0.056503</td>\n",
              "      <td>-0.025540</td>\n",
              "      <td>0.063258</td>\n",
              "      <td>-0.053109</td>\n",
              "      <td>0.009131</td>\n",
              "      <td>0.009380</td>\n",
              "      <td>-0.088039</td>\n",
              "      <td>0.013424</td>\n",
              "      <td>0.055650</td>\n",
              "      <td>0.041001</td>\n",
              "      <td>0.021923</td>\n",
              "      <td>0.054340</td>\n",
              "      <td>-0.045752</td>\n",
              "      <td>-0.066931</td>\n",
              "      <td>0.036386</td>\n",
              "      <td>-0.060174</td>\n",
              "      <td>0.009829</td>\n",
              "      <td>0.025389</td>\n",
              "      <td>0.019687</td>\n",
              "      <td>-0.123803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.020082</td>\n",
              "      <td>0.076726</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>-0.095554</td>\n",
              "      <td>0.054477</td>\n",
              "      <td>-0.048383</td>\n",
              "      <td>-0.001178</td>\n",
              "      <td>0.069049</td>\n",
              "      <td>0.104295</td>\n",
              "      <td>0.031209</td>\n",
              "      <td>-0.012774</td>\n",
              "      <td>0.028132</td>\n",
              "      <td>-0.190988</td>\n",
              "      <td>0.124783</td>\n",
              "      <td>0.084488</td>\n",
              "      <td>-0.035021</td>\n",
              "      <td>-0.004754</td>\n",
              "      <td>0.133061</td>\n",
              "      <td>-0.066553</td>\n",
              "      <td>-0.150080</td>\n",
              "      <td>-0.015618</td>\n",
              "      <td>0.068147</td>\n",
              "      <td>-0.024178</td>\n",
              "      <td>0.008021</td>\n",
              "      <td>-0.161173</td>\n",
              "      <td>0.062074</td>\n",
              "      <td>0.003902</td>\n",
              "      <td>0.023934</td>\n",
              "      <td>0.005674</td>\n",
              "      <td>-0.063869</td>\n",
              "      <td>-0.021318</td>\n",
              "      <td>0.042629</td>\n",
              "      <td>0.009544</td>\n",
              "      <td>-0.009217</td>\n",
              "      <td>0.016111</td>\n",
              "      <td>0.020191</td>\n",
              "      <td>0.041092</td>\n",
              "      <td>0.030274</td>\n",
              "      <td>-0.002066</td>\n",
              "      <td>0.144035</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044755</td>\n",
              "      <td>-0.061010</td>\n",
              "      <td>0.048108</td>\n",
              "      <td>0.045380</td>\n",
              "      <td>-0.035040</td>\n",
              "      <td>0.238326</td>\n",
              "      <td>0.032068</td>\n",
              "      <td>0.082385</td>\n",
              "      <td>0.055611</td>\n",
              "      <td>-0.088862</td>\n",
              "      <td>0.081477</td>\n",
              "      <td>-0.064901</td>\n",
              "      <td>0.114603</td>\n",
              "      <td>-0.034756</td>\n",
              "      <td>0.050653</td>\n",
              "      <td>-0.014394</td>\n",
              "      <td>-0.071905</td>\n",
              "      <td>-0.007106</td>\n",
              "      <td>-0.117127</td>\n",
              "      <td>0.088055</td>\n",
              "      <td>0.075215</td>\n",
              "      <td>0.000832</td>\n",
              "      <td>0.041479</td>\n",
              "      <td>0.014910</td>\n",
              "      <td>0.021439</td>\n",
              "      <td>-0.051645</td>\n",
              "      <td>0.015267</td>\n",
              "      <td>0.004228</td>\n",
              "      <td>0.042628</td>\n",
              "      <td>0.021603</td>\n",
              "      <td>0.021316</td>\n",
              "      <td>0.080637</td>\n",
              "      <td>-0.065208</td>\n",
              "      <td>0.017536</td>\n",
              "      <td>0.069011</td>\n",
              "      <td>0.019527</td>\n",
              "      <td>-0.069017</td>\n",
              "      <td>0.079466</td>\n",
              "      <td>-0.083851</td>\n",
              "      <td>-0.029499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.019127</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>-0.003839</td>\n",
              "      <td>-0.007965</td>\n",
              "      <td>-0.035752</td>\n",
              "      <td>-0.015379</td>\n",
              "      <td>-0.002444</td>\n",
              "      <td>0.002232</td>\n",
              "      <td>-0.022033</td>\n",
              "      <td>0.022873</td>\n",
              "      <td>-0.049688</td>\n",
              "      <td>0.002810</td>\n",
              "      <td>0.021491</td>\n",
              "      <td>0.027247</td>\n",
              "      <td>0.010128</td>\n",
              "      <td>0.043042</td>\n",
              "      <td>-0.023250</td>\n",
              "      <td>-0.003554</td>\n",
              "      <td>0.049331</td>\n",
              "      <td>0.014763</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.008772</td>\n",
              "      <td>0.021482</td>\n",
              "      <td>-0.039993</td>\n",
              "      <td>-0.018215</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.013622</td>\n",
              "      <td>0.007840</td>\n",
              "      <td>-0.006262</td>\n",
              "      <td>-0.016387</td>\n",
              "      <td>0.021047</td>\n",
              "      <td>0.003252</td>\n",
              "      <td>-0.023872</td>\n",
              "      <td>0.054374</td>\n",
              "      <td>0.018616</td>\n",
              "      <td>-0.008516</td>\n",
              "      <td>0.016500</td>\n",
              "      <td>0.016950</td>\n",
              "      <td>0.014876</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023895</td>\n",
              "      <td>0.054719</td>\n",
              "      <td>-0.006145</td>\n",
              "      <td>-0.011333</td>\n",
              "      <td>0.031115</td>\n",
              "      <td>-0.014977</td>\n",
              "      <td>-0.027866</td>\n",
              "      <td>0.009456</td>\n",
              "      <td>0.026328</td>\n",
              "      <td>0.010133</td>\n",
              "      <td>-0.036406</td>\n",
              "      <td>-0.019964</td>\n",
              "      <td>0.047808</td>\n",
              "      <td>-0.031970</td>\n",
              "      <td>-0.052114</td>\n",
              "      <td>-0.013230</td>\n",
              "      <td>0.051730</td>\n",
              "      <td>0.032968</td>\n",
              "      <td>0.009265</td>\n",
              "      <td>0.008906</td>\n",
              "      <td>-0.007720</td>\n",
              "      <td>0.047693</td>\n",
              "      <td>-0.029446</td>\n",
              "      <td>0.033402</td>\n",
              "      <td>-0.013943</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>0.062104</td>\n",
              "      <td>-0.025988</td>\n",
              "      <td>-0.041461</td>\n",
              "      <td>0.031528</td>\n",
              "      <td>-0.030165</td>\n",
              "      <td>0.026802</td>\n",
              "      <td>-0.015122</td>\n",
              "      <td>0.072199</td>\n",
              "      <td>-0.053174</td>\n",
              "      <td>0.022593</td>\n",
              "      <td>0.036794</td>\n",
              "      <td>0.049933</td>\n",
              "      <td>-0.006916</td>\n",
              "      <td>0.013190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.006459</td>\n",
              "      <td>0.025785</td>\n",
              "      <td>0.148373</td>\n",
              "      <td>0.046946</td>\n",
              "      <td>0.006658</td>\n",
              "      <td>-0.020200</td>\n",
              "      <td>0.017593</td>\n",
              "      <td>0.070860</td>\n",
              "      <td>0.058141</td>\n",
              "      <td>0.030598</td>\n",
              "      <td>-0.129147</td>\n",
              "      <td>0.012850</td>\n",
              "      <td>-0.015445</td>\n",
              "      <td>0.079050</td>\n",
              "      <td>-0.002163</td>\n",
              "      <td>0.033394</td>\n",
              "      <td>-0.124316</td>\n",
              "      <td>0.094877</td>\n",
              "      <td>0.072353</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>0.001051</td>\n",
              "      <td>-0.001674</td>\n",
              "      <td>-0.026987</td>\n",
              "      <td>0.024704</td>\n",
              "      <td>0.127752</td>\n",
              "      <td>-0.018889</td>\n",
              "      <td>-0.002900</td>\n",
              "      <td>-0.034714</td>\n",
              "      <td>-0.002294</td>\n",
              "      <td>0.033560</td>\n",
              "      <td>0.045775</td>\n",
              "      <td>0.009591</td>\n",
              "      <td>0.020055</td>\n",
              "      <td>-0.025792</td>\n",
              "      <td>0.001648</td>\n",
              "      <td>0.016852</td>\n",
              "      <td>0.068201</td>\n",
              "      <td>0.064958</td>\n",
              "      <td>0.003224</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003139</td>\n",
              "      <td>0.039928</td>\n",
              "      <td>0.021083</td>\n",
              "      <td>-0.049624</td>\n",
              "      <td>0.027466</td>\n",
              "      <td>0.033412</td>\n",
              "      <td>0.056385</td>\n",
              "      <td>0.041078</td>\n",
              "      <td>0.073926</td>\n",
              "      <td>0.055372</td>\n",
              "      <td>0.053146</td>\n",
              "      <td>-0.051430</td>\n",
              "      <td>0.014331</td>\n",
              "      <td>0.043536</td>\n",
              "      <td>-0.048152</td>\n",
              "      <td>-0.096933</td>\n",
              "      <td>-0.088210</td>\n",
              "      <td>-0.000173</td>\n",
              "      <td>-0.057735</td>\n",
              "      <td>0.052815</td>\n",
              "      <td>-0.012372</td>\n",
              "      <td>0.092582</td>\n",
              "      <td>-0.083830</td>\n",
              "      <td>0.045299</td>\n",
              "      <td>0.016906</td>\n",
              "      <td>0.094267</td>\n",
              "      <td>0.002661</td>\n",
              "      <td>0.015150</td>\n",
              "      <td>0.097696</td>\n",
              "      <td>0.021847</td>\n",
              "      <td>-0.011965</td>\n",
              "      <td>0.040954</td>\n",
              "      <td>-0.032073</td>\n",
              "      <td>-0.018053</td>\n",
              "      <td>0.085566</td>\n",
              "      <td>0.026778</td>\n",
              "      <td>-0.019486</td>\n",
              "      <td>0.014699</td>\n",
              "      <td>0.056411</td>\n",
              "      <td>-0.076907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        97        98        99\n",
              "0  0.033106  0.098918  0.050923  ... -0.011854  0.057327 -0.051704\n",
              "1  0.087314 -0.006708  0.070973  ...  0.025389  0.019687 -0.123803\n",
              "2 -0.020082  0.076726  0.000217  ...  0.079466 -0.083851 -0.029499\n",
              "3  0.019127  0.003650 -0.003839  ...  0.049933 -0.006916  0.013190\n",
              "4  0.006459  0.025785  0.148373  ...  0.014699  0.056411 -0.076907\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4hnYK7pZdwn"
      },
      "source": [
        "pickle.dump(corpus_d2v, open(\"/content/drive/MyDrive/Colab Notebooks/DoctoVecModel.pkl\", \"wb\"))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma9iL0Y-vJAG"
      },
      "source": [
        "## 3. BERT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PutarxWsbKPc"
      },
      "source": [
        "Confirm that GPU is detected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8Rl80AGbIcQ",
        "outputId": "92d1169b-494f-4fd5-916f-c867f0184f78"
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg1j-HN2bhIl"
      },
      "source": [
        "Assign the GPU device to torch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrucJQXVbgie",
        "outputId": "e8f8fbfd-ff7f-45cb-d5c5-8353131f96a4"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvgLCEFzvUYU"
      },
      "source": [
        "In order to apply BERT, we need to derive three data objects for the text data:\n",
        "1. Add [CLS] at the beginning and [SEP] at the end of each text. [SEP] is a legacy from teh model training. The result for [CLS] is then used later as document representation for classification tasks.\n",
        "2. Tokenize the texts using BERT tokenizer\n",
        "3. Pad or truncate the text to the maximum length (maximum 512)\n",
        "4. Map the remaining tokens to BERT dictionary \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfsZbJTovPAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889b7f55-5ef6-4f30-f598-29e518ab0bbe"
      },
      "source": [
        "# 1. Add [CLS] at the beginning and [SEP] at the end of each text.\n",
        "sentences = [\"[CLS] \" + query + \" [SEP]\" for query in data_lemma]\n",
        "print(sentences[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] car wonder enlighten car see day door sport car look late early call bricklin door small addition bumper separate rest body know tellme model engine specs year production car history info funky looking car mail thank [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVhJhuTNw3vm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204,
          "referenced_widgets": [
            "a3195a23a37842c29a5ba37068343d24",
            "07c4a0c773d64f65abb2e6d3eb8e993f",
            "24ddab00c1474b409277b54d58ac09dd",
            "91de5b7e432341e893f097490670ebae",
            "94492cfe7d1e4af9a6535f6ea6a24770",
            "0055612cdcd44e87ba966ac9c10710b8",
            "a783d35aef684db09ae5a361e552be2c",
            "747c45b058284ba2a227e783a44969f9",
            "63fa76c345c74bdba28f3e7ffda823ac",
            "600a917abd22471ab10c53e105033421",
            "45c41b25d06c4234bdf05a5922893440",
            "284c18ebeec4435a98788755600cacd9",
            "e867e2ffc7a2411ebbcf33f9512967b4",
            "55d61e4eb5664032890b584fa62e2eb1",
            "440655ae618343d79ce5b7284f0b6a7a",
            "e71841678fe747488d38392a1393fe63",
            "77a24b04bfa64a20af469694d619d5fa",
            "6a0348151f5049f09a8a2b16b409c571",
            "441fa1b39cd84edca6e286d91d26816c",
            "9ceaed202aef45e39a1ebc3e96b0663f",
            "afc58290a4cc47b98893bca868a08444",
            "de855821f6d442ecb80d1db5b529d67d",
            "9f656695e9384a469f047817f7554714",
            "42f0bc82f4fa48ad9f5fcbb75cc9bc43"
          ]
        },
        "outputId": "c0562e65-0c3e-4a19-bdcc-e82c1f56948b"
      },
      "source": [
        "# 2. Tokenize the texts using BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print(tokenized_texts[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3195a23a37842c29a5ba37068343d24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63fa76c345c74bdba28f3e7ffda823ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77a24b04bfa64a20af469694d619d5fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "['[CLS]', 'car', 'wonder', 'en', '##light', '##en', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'brick', '##lin', 'door', 'small', 'addition', 'bumper', 'separate', 'rest', 'body', 'know', 'tell', '##me', 'model', 'engine', 'spec', '##s', 'year', 'production', 'car', 'history', 'info', 'funky', 'looking', 'car', 'mail', 'thank', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC_lwMCmdurn",
        "outputId": "c862ac0a-6f7d-40f4-ef1d-3bd120fa279d"
      },
      "source": [
        "# Show token IDs based on BERT's training\n",
        "print(tokenizer.convert_tokens_to_ids(tokenized_texts[0]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2482, 4687, 4372, 7138, 2368, 2482, 2156, 2154, 2341, 4368, 2482, 2298, 2397, 2220, 2655, 5318, 4115, 2341, 2235, 2804, 21519, 3584, 2717, 2303, 2113, 2425, 4168, 2944, 3194, 28699, 2015, 2095, 2537, 2482, 2381, 18558, 24151, 2559, 2482, 5653, 4067, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS5uylwxySbP"
      },
      "source": [
        "In order to determine the maximum sequence length, we look at the list statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "6pEoPoTIkmge",
        "outputId": "8f34a9a7-7576-40de-f0f2-fd9bef6718c1"
      },
      "source": [
        "leng=[]\n",
        "for t in tokenized_texts:\n",
        "  leng.append(len(t))\n",
        "df=pd.DataFrame(leng)\n",
        "df.describe()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11314.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>170.791232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>394.855169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>63.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>103.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>166.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8235.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  11314.000000\n",
              "mean     170.791232\n",
              "std      394.855169\n",
              "min        4.000000\n",
              "25%       63.000000\n",
              "50%      103.000000\n",
              "75%      166.000000\n",
              "max     8235.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "Y-bq1lCQn4vK",
        "outputId": "3ceae3b8-9245-421a-a5dd-afa0172b5683"
      },
      "source": [
        "df.quantile([.95, .99])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.95</th>\n",
              "      <td>412.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.99</th>\n",
              "      <td>1303.96</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0\n",
              "0.95   412.00\n",
              "0.99  1303.96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMXYZrCRxCu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ae93c1-34c3-48a4-ed68-128da155faae"
      },
      "source": [
        "# 3. Pad the text to the maximum length, max 512\n",
        "\n",
        "# Pad sequences that are less than MAX_LEN, if more, remove from the end\n",
        "sentences_padded = pad_sequences(tokenized_texts,  dtype=object,maxlen=412,  value='[PAD]', truncating=\"post\",padding=\"post\")\n",
        "print(sentences_padded[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]' 'car' 'wonder' 'en' '##light' '##en' 'car' 'see' 'day' 'door'\n",
            " 'sport' 'car' 'look' 'late' 'early' 'call' 'brick' '##lin' 'door' 'small'\n",
            " 'addition' 'bumper' 'separate' 'rest' 'body' 'know' 'tell' '##me' 'model'\n",
            " 'engine' 'spec' '##s' 'year' 'production' 'car' 'history' 'info' 'funky'\n",
            " 'looking' 'car' 'mail' 'thank' '[SEP]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSorqlkhv792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4202b9-635f-4f94-8668-5b73b431b95d"
      },
      "source": [
        "#4. Map the tokens to BERT dictionary \n",
        "# Convert the tokens to their index numbers in the BERT vocabulary\n",
        "sentences_converted = [tokenizer.convert_tokens_to_ids(s) for s in sentences_padded]\n",
        "print(sentences_converted[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2482, 4687, 4372, 7138, 2368, 2482, 2156, 2154, 2341, 4368, 2482, 2298, 2397, 2220, 2655, 5318, 4115, 2341, 2235, 2804, 21519, 3584, 2717, 2303, 2113, 2425, 4168, 2944, 3194, 28699, 2015, 2095, 2537, 2482, 2381, 18558, 24151, 2559, 2482, 5653, 4067, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyiBA71874Ww"
      },
      "source": [
        "# Create attention masks\n",
        "masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in sentences_converted:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  masks.append(seq_mask)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga2etroyhmCg"
      },
      "source": [
        "# 5. Generate embeddings\n",
        "\n",
        "#Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "inputs = torch.LongTensor(sentences_converted)\n",
        "masks = torch.LongTensor(masks)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU3Bc9vcrf3l",
        "outputId": "47b38ec6-498b-46c6-b620-ac2679379df5"
      },
      "source": [
        "inputs.size()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11314, 412])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scHjWdSdAgVI",
        "outputId": "21b61977-6329-4a77-870f-43e8d45d8d6d"
      },
      "source": [
        "masks.size()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11314, 412])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unk7mmko2Y2_",
        "outputId": "550555da-1da1-4551-ed01-d87363592d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "bb897cf8f59242c29ac300500cd3f6d3",
            "441c6a4c57a744a49c8a59c492e5a529",
            "e84f73b2ad8641d18e98276f9256fab0",
            "910db535450f4e99bdce1792dfe802f4",
            "e8fa475d6df647cdafa09684f017119b",
            "fbf4b497b31a47a183cc12529917d0d6",
            "9c3eacc345fa49f3837e48829cf7f54c",
            "9c771381539440c48a30061d598fcecb",
            "1e6db1582de445f19a937ed4e9dbd442",
            "677abc3389b9408ca2b9be199016706b",
            "0d27e816c2b94e14be6274b047ea3b2d",
            "0d05bac4fd244acfb1eb6359e778af0d",
            "510d9d917cca4dc19f2c5f926b536ee9",
            "516aab789ca24ca9b6c174b66c07b0f2",
            "dd82065432ea43729e96c3148a4cb6e6",
            "b6dfa41f42314808a3c410c2ff593f59"
          ]
        }
      },
      "source": [
        "# Apply Pretrained model to the sentences\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb897cf8f59242c29ac300500cd3f6d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e6db1582de445f19a937ed4e9dbd442",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REYqHgGy60sW",
        "outputId": "88915e02-105b-492e-c49c-89ed8608425d"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5jVGRi6tMJq"
      },
      "source": [
        "# Set the batch size.  \n",
        "batch_size = 16  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(inputs, masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH09MuNavJ9u",
        "outputId": "5b15f616-3662-4a62-e304-8de8c4fbf08e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result=[]\n",
        "i=0\n",
        "for batch in prediction_dataloader:\n",
        "  #print(i)\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  \n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate embeddings\n",
        "      outputs = model(b_input_ids)\n",
        "\n",
        "  embeddings = outputs.pooler_output #CLS embeddings for the batch\n",
        "\n",
        "  # Move em to CPU\n",
        "  embeddings = embeddings.detach().cpu().numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  result.append(embeddings)\n",
        "  i=i+1\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V2cxivqCTDf"
      },
      "source": [
        "#708 batches*16 texts with embedding size 768"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFtgYQZRCxXK"
      },
      "source": [
        "final=[]\n",
        "for b in result:\n",
        "   for e in b:\n",
        "      final.append(e)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnhbzdZYMFAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "835285e8-b8bc-440f-b36c-4c4f4683687d"
      },
      "source": [
        "# Final corpus\n",
        "corpus_bert_df=pd.DataFrame(final)\n",
        "corpus_bert_df.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>728</th>\n",
              "      <th>729</th>\n",
              "      <th>730</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.120891</td>\n",
              "      <td>-0.280994</td>\n",
              "      <td>-0.963245</td>\n",
              "      <td>0.419622</td>\n",
              "      <td>0.778366</td>\n",
              "      <td>-0.196418</td>\n",
              "      <td>-0.313293</td>\n",
              "      <td>0.232870</td>\n",
              "      <td>-0.862499</td>\n",
              "      <td>-0.955871</td>\n",
              "      <td>0.223536</td>\n",
              "      <td>0.886177</td>\n",
              "      <td>0.327486</td>\n",
              "      <td>0.866635</td>\n",
              "      <td>-0.249378</td>\n",
              "      <td>0.088374</td>\n",
              "      <td>0.439759</td>\n",
              "      <td>0.016313</td>\n",
              "      <td>0.064368</td>\n",
              "      <td>0.730549</td>\n",
              "      <td>0.462973</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>-0.408310</td>\n",
              "      <td>0.307045</td>\n",
              "      <td>0.337647</td>\n",
              "      <td>0.908904</td>\n",
              "      <td>-0.068019</td>\n",
              "      <td>-0.055471</td>\n",
              "      <td>0.252830</td>\n",
              "      <td>0.328617</td>\n",
              "      <td>0.393255</td>\n",
              "      <td>0.119468</td>\n",
              "      <td>-0.622634</td>\n",
              "      <td>-0.270945</td>\n",
              "      <td>-0.978561</td>\n",
              "      <td>-0.187582</td>\n",
              "      <td>0.180457</td>\n",
              "      <td>0.127950</td>\n",
              "      <td>-0.101807</td>\n",
              "      <td>-0.250290</td>\n",
              "      <td>...</td>\n",
              "      <td>0.428010</td>\n",
              "      <td>-0.247050</td>\n",
              "      <td>-0.033118</td>\n",
              "      <td>-0.254504</td>\n",
              "      <td>-0.322066</td>\n",
              "      <td>-0.023203</td>\n",
              "      <td>-0.252481</td>\n",
              "      <td>-0.285563</td>\n",
              "      <td>0.193448</td>\n",
              "      <td>0.033795</td>\n",
              "      <td>0.999958</td>\n",
              "      <td>-0.736765</td>\n",
              "      <td>-0.848266</td>\n",
              "      <td>-0.186036</td>\n",
              "      <td>-0.336793</td>\n",
              "      <td>0.301686</td>\n",
              "      <td>-0.462011</td>\n",
              "      <td>-0.999997</td>\n",
              "      <td>0.255416</td>\n",
              "      <td>-0.859095</td>\n",
              "      <td>0.803370</td>\n",
              "      <td>-0.318131</td>\n",
              "      <td>0.902804</td>\n",
              "      <td>-0.754084</td>\n",
              "      <td>0.307099</td>\n",
              "      <td>-0.061251</td>\n",
              "      <td>0.624030</td>\n",
              "      <td>0.844899</td>\n",
              "      <td>-0.087035</td>\n",
              "      <td>-0.475938</td>\n",
              "      <td>0.161414</td>\n",
              "      <td>-0.928535</td>\n",
              "      <td>0.863065</td>\n",
              "      <td>-0.074633</td>\n",
              "      <td>-0.002260</td>\n",
              "      <td>-0.675741</td>\n",
              "      <td>0.185203</td>\n",
              "      <td>-0.855487</td>\n",
              "      <td>-0.178540</td>\n",
              "      <td>-0.240451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.183047</td>\n",
              "      <td>-0.320446</td>\n",
              "      <td>-0.967441</td>\n",
              "      <td>0.510457</td>\n",
              "      <td>0.806681</td>\n",
              "      <td>-0.212261</td>\n",
              "      <td>-0.239628</td>\n",
              "      <td>0.210489</td>\n",
              "      <td>-0.880438</td>\n",
              "      <td>-0.945462</td>\n",
              "      <td>0.122012</td>\n",
              "      <td>0.914262</td>\n",
              "      <td>0.214913</td>\n",
              "      <td>0.882294</td>\n",
              "      <td>-0.172117</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.382229</td>\n",
              "      <td>0.015465</td>\n",
              "      <td>0.056818</td>\n",
              "      <td>0.700129</td>\n",
              "      <td>0.484552</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>-0.460843</td>\n",
              "      <td>0.301718</td>\n",
              "      <td>0.323201</td>\n",
              "      <td>0.921945</td>\n",
              "      <td>-0.133789</td>\n",
              "      <td>-0.070382</td>\n",
              "      <td>0.238025</td>\n",
              "      <td>0.354671</td>\n",
              "      <td>0.378942</td>\n",
              "      <td>0.101619</td>\n",
              "      <td>-0.541697</td>\n",
              "      <td>-0.292166</td>\n",
              "      <td>-0.978894</td>\n",
              "      <td>-0.117593</td>\n",
              "      <td>0.185518</td>\n",
              "      <td>0.117982</td>\n",
              "      <td>-0.145663</td>\n",
              "      <td>-0.236753</td>\n",
              "      <td>...</td>\n",
              "      <td>0.481052</td>\n",
              "      <td>-0.270803</td>\n",
              "      <td>-0.048760</td>\n",
              "      <td>-0.217497</td>\n",
              "      <td>-0.346388</td>\n",
              "      <td>0.035731</td>\n",
              "      <td>-0.253299</td>\n",
              "      <td>-0.326463</td>\n",
              "      <td>0.175167</td>\n",
              "      <td>-0.009337</td>\n",
              "      <td>0.999946</td>\n",
              "      <td>-0.775669</td>\n",
              "      <td>-0.875688</td>\n",
              "      <td>-0.178330</td>\n",
              "      <td>-0.360491</td>\n",
              "      <td>0.283788</td>\n",
              "      <td>-0.451560</td>\n",
              "      <td>-0.999997</td>\n",
              "      <td>0.240596</td>\n",
              "      <td>-0.880769</td>\n",
              "      <td>0.822632</td>\n",
              "      <td>-0.391792</td>\n",
              "      <td>0.911289</td>\n",
              "      <td>-0.800638</td>\n",
              "      <td>0.229179</td>\n",
              "      <td>-0.054229</td>\n",
              "      <td>0.605605</td>\n",
              "      <td>0.866382</td>\n",
              "      <td>-0.109120</td>\n",
              "      <td>-0.466791</td>\n",
              "      <td>0.175150</td>\n",
              "      <td>-0.939977</td>\n",
              "      <td>0.888713</td>\n",
              "      <td>-0.089563</td>\n",
              "      <td>-0.091914</td>\n",
              "      <td>-0.731656</td>\n",
              "      <td>0.169998</td>\n",
              "      <td>-0.887561</td>\n",
              "      <td>-0.124455</td>\n",
              "      <td>-0.239807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.448309</td>\n",
              "      <td>-0.472410</td>\n",
              "      <td>-0.966038</td>\n",
              "      <td>0.469346</td>\n",
              "      <td>0.783993</td>\n",
              "      <td>-0.309353</td>\n",
              "      <td>-0.071450</td>\n",
              "      <td>0.402272</td>\n",
              "      <td>-0.900948</td>\n",
              "      <td>-0.996757</td>\n",
              "      <td>-0.014901</td>\n",
              "      <td>0.911494</td>\n",
              "      <td>0.588971</td>\n",
              "      <td>0.869020</td>\n",
              "      <td>0.128399</td>\n",
              "      <td>-0.312896</td>\n",
              "      <td>0.298809</td>\n",
              "      <td>-0.298606</td>\n",
              "      <td>0.229429</td>\n",
              "      <td>0.730347</td>\n",
              "      <td>0.562585</td>\n",
              "      <td>0.999993</td>\n",
              "      <td>-0.376672</td>\n",
              "      <td>0.494585</td>\n",
              "      <td>0.460912</td>\n",
              "      <td>0.939935</td>\n",
              "      <td>-0.356034</td>\n",
              "      <td>0.246502</td>\n",
              "      <td>0.618172</td>\n",
              "      <td>0.554519</td>\n",
              "      <td>0.120343</td>\n",
              "      <td>0.322657</td>\n",
              "      <td>-0.796389</td>\n",
              "      <td>-0.403809</td>\n",
              "      <td>-0.979325</td>\n",
              "      <td>-0.658267</td>\n",
              "      <td>0.306179</td>\n",
              "      <td>-0.154930</td>\n",
              "      <td>-0.216211</td>\n",
              "      <td>-0.144139</td>\n",
              "      <td>...</td>\n",
              "      <td>0.308660</td>\n",
              "      <td>-0.323581</td>\n",
              "      <td>-0.213666</td>\n",
              "      <td>-0.265178</td>\n",
              "      <td>-0.020348</td>\n",
              "      <td>-0.309221</td>\n",
              "      <td>-0.446614</td>\n",
              "      <td>-0.392979</td>\n",
              "      <td>0.400869</td>\n",
              "      <td>0.209144</td>\n",
              "      <td>0.999980</td>\n",
              "      <td>-0.796421</td>\n",
              "      <td>-0.905167</td>\n",
              "      <td>-0.253032</td>\n",
              "      <td>-0.453571</td>\n",
              "      <td>0.496375</td>\n",
              "      <td>-0.544815</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.289580</td>\n",
              "      <td>-0.917304</td>\n",
              "      <td>0.874065</td>\n",
              "      <td>-0.410036</td>\n",
              "      <td>0.887686</td>\n",
              "      <td>-0.891297</td>\n",
              "      <td>-0.080705</td>\n",
              "      <td>-0.255990</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.891756</td>\n",
              "      <td>-0.332590</td>\n",
              "      <td>-0.503152</td>\n",
              "      <td>0.638434</td>\n",
              "      <td>-0.900726</td>\n",
              "      <td>0.892726</td>\n",
              "      <td>0.026648</td>\n",
              "      <td>-0.237032</td>\n",
              "      <td>-0.610219</td>\n",
              "      <td>0.718728</td>\n",
              "      <td>-0.911580</td>\n",
              "      <td>-0.425955</td>\n",
              "      <td>-0.059750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.098515</td>\n",
              "      <td>-0.385608</td>\n",
              "      <td>-0.987904</td>\n",
              "      <td>0.494115</td>\n",
              "      <td>0.869421</td>\n",
              "      <td>-0.238608</td>\n",
              "      <td>-0.245373</td>\n",
              "      <td>0.274326</td>\n",
              "      <td>-0.947566</td>\n",
              "      <td>-0.950335</td>\n",
              "      <td>-0.018988</td>\n",
              "      <td>0.949433</td>\n",
              "      <td>-0.014700</td>\n",
              "      <td>0.939705</td>\n",
              "      <td>-0.249542</td>\n",
              "      <td>-0.130132</td>\n",
              "      <td>0.267692</td>\n",
              "      <td>-0.008533</td>\n",
              "      <td>0.047951</td>\n",
              "      <td>0.734438</td>\n",
              "      <td>0.511568</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>-0.642022</td>\n",
              "      <td>0.352938</td>\n",
              "      <td>0.385997</td>\n",
              "      <td>0.963973</td>\n",
              "      <td>-0.198282</td>\n",
              "      <td>-0.205098</td>\n",
              "      <td>0.149731</td>\n",
              "      <td>0.367538</td>\n",
              "      <td>0.343082</td>\n",
              "      <td>0.175255</td>\n",
              "      <td>-0.408339</td>\n",
              "      <td>-0.325079</td>\n",
              "      <td>-0.989443</td>\n",
              "      <td>-0.010332</td>\n",
              "      <td>0.279057</td>\n",
              "      <td>0.168347</td>\n",
              "      <td>-0.195600</td>\n",
              "      <td>-0.278317</td>\n",
              "      <td>...</td>\n",
              "      <td>0.652145</td>\n",
              "      <td>-0.299753</td>\n",
              "      <td>-0.139638</td>\n",
              "      <td>-0.173683</td>\n",
              "      <td>-0.443671</td>\n",
              "      <td>-0.027985</td>\n",
              "      <td>-0.349703</td>\n",
              "      <td>-0.388918</td>\n",
              "      <td>0.165237</td>\n",
              "      <td>0.035473</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>-0.882225</td>\n",
              "      <td>-0.953739</td>\n",
              "      <td>-0.245630</td>\n",
              "      <td>-0.413192</td>\n",
              "      <td>0.379641</td>\n",
              "      <td>-0.529157</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.287768</td>\n",
              "      <td>-0.922833</td>\n",
              "      <td>0.899929</td>\n",
              "      <td>-0.592388</td>\n",
              "      <td>0.953749</td>\n",
              "      <td>-0.889039</td>\n",
              "      <td>0.282065</td>\n",
              "      <td>-0.129607</td>\n",
              "      <td>0.664973</td>\n",
              "      <td>0.927450</td>\n",
              "      <td>-0.143531</td>\n",
              "      <td>-0.533200</td>\n",
              "      <td>0.266515</td>\n",
              "      <td>-0.961368</td>\n",
              "      <td>0.948298</td>\n",
              "      <td>-0.195683</td>\n",
              "      <td>-0.299023</td>\n",
              "      <td>-0.849391</td>\n",
              "      <td>0.298872</td>\n",
              "      <td>-0.932983</td>\n",
              "      <td>-0.178504</td>\n",
              "      <td>-0.309659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.180124</td>\n",
              "      <td>-0.413501</td>\n",
              "      <td>-0.984492</td>\n",
              "      <td>0.474194</td>\n",
              "      <td>0.865759</td>\n",
              "      <td>-0.281325</td>\n",
              "      <td>-0.225921</td>\n",
              "      <td>0.305099</td>\n",
              "      <td>-0.935964</td>\n",
              "      <td>-0.974516</td>\n",
              "      <td>0.008402</td>\n",
              "      <td>0.932913</td>\n",
              "      <td>0.182340</td>\n",
              "      <td>0.928759</td>\n",
              "      <td>-0.195707</td>\n",
              "      <td>-0.154070</td>\n",
              "      <td>0.334482</td>\n",
              "      <td>-0.087378</td>\n",
              "      <td>0.104970</td>\n",
              "      <td>0.755661</td>\n",
              "      <td>0.508255</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>-0.580859</td>\n",
              "      <td>0.430080</td>\n",
              "      <td>0.409025</td>\n",
              "      <td>0.948664</td>\n",
              "      <td>-0.238847</td>\n",
              "      <td>-0.117083</td>\n",
              "      <td>0.270822</td>\n",
              "      <td>0.436732</td>\n",
              "      <td>0.326114</td>\n",
              "      <td>0.217338</td>\n",
              "      <td>-0.518259</td>\n",
              "      <td>-0.354096</td>\n",
              "      <td>-0.987442</td>\n",
              "      <td>-0.171870</td>\n",
              "      <td>0.272495</td>\n",
              "      <td>0.096164</td>\n",
              "      <td>-0.216041</td>\n",
              "      <td>-0.242049</td>\n",
              "      <td>...</td>\n",
              "      <td>0.606793</td>\n",
              "      <td>-0.327609</td>\n",
              "      <td>-0.150611</td>\n",
              "      <td>-0.184259</td>\n",
              "      <td>-0.386002</td>\n",
              "      <td>-0.137363</td>\n",
              "      <td>-0.393250</td>\n",
              "      <td>-0.383060</td>\n",
              "      <td>0.206357</td>\n",
              "      <td>0.095422</td>\n",
              "      <td>0.999989</td>\n",
              "      <td>-0.869633</td>\n",
              "      <td>-0.944107</td>\n",
              "      <td>-0.264682</td>\n",
              "      <td>-0.423192</td>\n",
              "      <td>0.436482</td>\n",
              "      <td>-0.529781</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.280890</td>\n",
              "      <td>-0.925910</td>\n",
              "      <td>0.897921</td>\n",
              "      <td>-0.559192</td>\n",
              "      <td>0.944515</td>\n",
              "      <td>-0.896119</td>\n",
              "      <td>0.235804</td>\n",
              "      <td>-0.174416</td>\n",
              "      <td>0.641793</td>\n",
              "      <td>0.917698</td>\n",
              "      <td>-0.214031</td>\n",
              "      <td>-0.523474</td>\n",
              "      <td>0.428578</td>\n",
              "      <td>-0.948966</td>\n",
              "      <td>0.931038</td>\n",
              "      <td>-0.180842</td>\n",
              "      <td>-0.408895</td>\n",
              "      <td>-0.821256</td>\n",
              "      <td>0.473733</td>\n",
              "      <td>-0.940421</td>\n",
              "      <td>-0.238981</td>\n",
              "      <td>-0.261727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       765       766       767\n",
              "0 -0.120891 -0.280994 -0.963245  ... -0.855487 -0.178540 -0.240451\n",
              "1 -0.183047 -0.320446 -0.967441  ... -0.887561 -0.124455 -0.239807\n",
              "2 -0.448309 -0.472410 -0.966038  ... -0.911580 -0.425955 -0.059750\n",
              "3 -0.098515 -0.385608 -0.987904  ... -0.932983 -0.178504 -0.309659\n",
              "4 -0.180124 -0.413501 -0.984492  ... -0.940421 -0.238981 -0.261727\n",
              "\n",
              "[5 rows x 768 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc9EZDjlAMoP"
      },
      "source": [
        "pickle.dump(corpus_bert_df, open(\"/content/drive/MyDrive/Colab Notebooks/BertModel.pkl\", \"wb\"))"
      ],
      "execution_count": 54,
      "outputs": []
    }
  ]
}