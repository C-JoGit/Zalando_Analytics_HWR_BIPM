{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Annelie Schridde\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_tags, strip_numeric, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short, stem_text\n",
    "import pickle\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "# import en_core_web_sm\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading emoji data ...\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Annelie\n",
      "[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Annelie\n",
      "[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Annelie\n",
      "[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "... OK (Got response in 0.56 seconds)\n",
      "Writing emoji data to C:\\Users\\Annelie Schridde\\.demoji\\codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('../')\n",
    "#import functions\n",
    "#exec(open('./functions.py').read())\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              user_id  user_statuses            name  \\\n",
       "0      0  1079317443523297280          12303      Boulder667   \n",
       "1      1  1079317443523297280          12303      Boulder667   \n",
       "2      2  1193535074660171776            693  FabIan68286784   \n",
       "3      3  1318999115313876996           1554     mantis_spam   \n",
       "4      4            310342425          11476     AndyBaldauf   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  @spdde @LadyBitchRay1 @spdbt @amazonDE @Zaland...         0   \n",
       "1  @spdde @LadyBitchRay1 Viel Spa√ü, damit eine Wa...         0   \n",
       "2  @missbellalugosi @Zalando Kleiner Einwand von ...         0   \n",
       "3  @missbellalugosi @Zalando Etwas aus PU als Jog...         0   \n",
       "4  @dicecco @Zalando aber erst wenn sie wieder d√º...         0   \n",
       "\n",
       "                        location      created  followers  is_user_verified  \\\n",
       "0             Liverpool, England  07-Mar-2021        116             False   \n",
       "1             Liverpool, England  07-Mar-2021        116             False   \n",
       "2                                 06-Mar-2021         57             False   \n",
       "3                                 06-Mar-2021       1273             False   \n",
       "4  Thurgau | St. Gallen | Z√ºrich  06-Mar-2021       1848             False   \n",
       "\n",
       "   favorite_count  in_reply_to_status_id  keyword language  \n",
       "0             0.0           1.368470e+18  zalando       de  \n",
       "1             1.0           1.368148e+18  zalando       de  \n",
       "2             0.0           1.368196e+18  zalando       de  \n",
       "3             2.0           1.368196e+18  zalando       de  \n",
       "4             0.0           1.368146e+18  zalando       de  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1079317443523297280</td>\n      <td>12303</td>\n      <td>Boulder667</td>\n      <td>@spdde @LadyBitchRay1 @spdbt @amazonDE @Zaland...</td>\n      <td>0</td>\n      <td>Liverpool, England</td>\n      <td>07-Mar-2021</td>\n      <td>116</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368470e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1079317443523297280</td>\n      <td>12303</td>\n      <td>Boulder667</td>\n      <td>@spdde @LadyBitchRay1 Viel Spa√ü, damit eine Wa...</td>\n      <td>0</td>\n      <td>Liverpool, England</td>\n      <td>07-Mar-2021</td>\n      <td>116</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368148e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1193535074660171776</td>\n      <td>693</td>\n      <td>FabIan68286784</td>\n      <td>@missbellalugosi @Zalando Kleiner Einwand von ...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>57</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368196e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1318999115313876996</td>\n      <td>1554</td>\n      <td>mantis_spam</td>\n      <td>@missbellalugosi @Zalando Etwas aus PU als Jog...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>1273</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>1.368196e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>310342425</td>\n      <td>11476</td>\n      <td>AndyBaldauf</td>\n      <td>@dicecco @Zalando aber erst wenn sie wieder d√º...</td>\n      <td>0</td>\n      <td>Thurgau | St. Gallen | Z√ºrich</td>\n      <td>06-Mar-2021</td>\n      <td>1848</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368146e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df = pickle.load(open('data_n_models/one_cleaned_df.pkl', \"rb\"))\n",
    "de_df = df[df.language == 'de'].reset_index()\n",
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_complete(tweet):\n",
    "    \"\"\"\n",
    "    tweet: pandas series\n",
    "    prepares tweets complete cleaning for further lemmatization and dering embeddings\n",
    "    \"\"\"\n",
    "    pat = r\"(\\\\n)|(@\\w*)|((www\\.[^\\s]+)|(https?://[^\\s]+))\"\n",
    "    tweet = tweet.str.replace(pat, '')\n",
    "\n",
    "    #remove repeated charachters\n",
    "    \n",
    "    #replace emoticons with words\n",
    "    #SMILEYS = {\":-(\":\"sad\", \":‚Äë)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "    tweet = tweet.str.replace(r':-\\)', ' smile')\n",
    "    tweet = tweet.str.replace(r':-\\(', ' sad')\n",
    "    tweet = tweet.str.replace(r':-\\/', ' confused')\n",
    "    tweet = tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "    #delete \\xa\n",
    "    tweet = tweet.str.replace('\\xa0', '')\n",
    "\n",
    "    tweet = tweet.str.replace('&amp', '')\n",
    "    tweet = tweet.str.replace('\\n', '')\n",
    "    tweet = tweet.str.replace('\"', '')\n",
    "    #to lower case\n",
    "    tweet = tweet.str.lower()\n",
    "\n",
    "    #covert hashtags to the normal text\n",
    "    tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "\n",
    "    #delete numbers\n",
    "    tweet = [strip_numeric(c) for c in tweet]\n",
    "\n",
    "    #replacing emojies with descriptions '‚ù§Ô∏è-> red heart'\n",
    "    #tweet = [demoji.replace_with_desc(c, ' ') for c in tweet]\n",
    "\n",
    "    #delete punctuation\n",
    "    tweet = [strip_punctuation(c) for c in tweet]\n",
    "\n",
    "    #remove stop words\n",
    "    tweet = [remove_stopwords(c) for c in tweet]\n",
    "\n",
    "    #remove short words\n",
    "    tweet = [strip_short(c) for c in tweet]\n",
    "\n",
    "    #remove mult whitespaces\n",
    "    tweet = [strip_multiple_whitespaces(c) for c in tweet]\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_vader(tweet):\n",
    "    \"\"\"\n",
    "    tweet: pandas series\n",
    "    prepares tweets for vader sentiment analysis\n",
    "    \"\"\"\n",
    "\n",
    "    pat = r\"(\\\\n)|(@\\w*)|((www\\.[^\\s]+)|(https?://[^\\s]+))\"\n",
    "    tweet = tweet.str.replace(pat, '')\n",
    "\n",
    "    #replace emoticons with words\n",
    "    #SMILEYS = {\":-(\":\"sad\", \":‚Äë)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "    #tweet = tweet.str.replace(r':-\\)', ' smile')\n",
    "    #tweet = tweet.str.replace(r':-\\(', ' sad')\n",
    "    #tweet = tweet.str.replace(r':-\\/', ' confused')\n",
    "    #tweet = tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "    #delete \\xa\n",
    "    tweet = tweet.str.replace('\\xa0', '')\n",
    "\n",
    "    tweet = tweet.str.replace('&amp', '')\n",
    "    tweet = tweet.str.replace('\\n', '')\n",
    "\n",
    "    #to lower case\n",
    "    #tweet = tweet.str.lower()\n",
    "\n",
    "    #covert hashtags to the normal text\n",
    "    tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "\n",
    "    #delete numbers\n",
    "    tweet = [strip_numeric(c) for c in tweet]\n",
    "\n",
    "    #replacing emojies with descriptions '‚ù§Ô∏è-> red heart'\n",
    "    #tweet = [demoji.replace_with_desc(c, ' ') for c in tweet]\n",
    "\n",
    "    #delete punctuation\n",
    "    #tweet = [strip_punctuation(c) for c in tweet]\n",
    "\n",
    "    #remove stop words\n",
    "    #tweet = [remove_stopwords(c) for c in tweet]\n",
    "\n",
    "    #remove short words\n",
    "    tweet = [strip_short(c) for c in tweet]\n",
    "\n",
    "    #remove mult whitespaces\n",
    "    tweet = [strip_multiple_whitespaces(c) for c in tweet]\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-6-abe84fc2115d>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(pat, '')\n",
      "<ipython-input-6-abe84fc2115d>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r':-\\)', ' smile')\n",
      "<ipython-input-6-abe84fc2115d>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r':-\\(', ' sad')\n",
      "<ipython-input-6-abe84fc2115d>:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r':-\\/', ' confused')\n",
      "<ipython-input-6-abe84fc2115d>:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              user_id  user_statuses            name  \\\n",
       "0      0  1079317443523297280          12303      Boulder667   \n",
       "1      1  1079317443523297280          12303      Boulder667   \n",
       "2      2  1193535074660171776            693  FabIan68286784   \n",
       "3      3  1318999115313876996           1554     mantis_spam   \n",
       "4      4            310342425          11476     AndyBaldauf   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  @spdde @LadyBitchRay1 @spdbt @amazonDE @Zaland...         0   \n",
       "1  @spdde @LadyBitchRay1 Viel Spa√ü, damit eine Wa...         0   \n",
       "2  @missbellalugosi @Zalando Kleiner Einwand von ...         0   \n",
       "3  @missbellalugosi @Zalando Etwas aus PU als Jog...         0   \n",
       "4  @dicecco @Zalando aber erst wenn sie wieder d√º...         0   \n",
       "\n",
       "                        location      created  followers  is_user_verified  \\\n",
       "0             Liverpool, England  07-Mar-2021        116             False   \n",
       "1             Liverpool, England  07-Mar-2021        116             False   \n",
       "2                                 06-Mar-2021         57             False   \n",
       "3                                 06-Mar-2021       1273             False   \n",
       "4  Thurgau | St. Gallen | Z√ºrich  06-Mar-2021       1848             False   \n",
       "\n",
       "   favorite_count  in_reply_to_status_id  keyword language  \\\n",
       "0             0.0           1.368470e+18  zalando       de   \n",
       "1             1.0           1.368148e+18  zalando       de   \n",
       "2             0.0           1.368196e+18  zalando       de   \n",
       "3             2.0           1.368196e+18  zalando       de   \n",
       "4             0.0           1.368146e+18  zalando       de   \n",
       "\n",
       "                                               clean  \n",
       "0                          quasi steuerfrei arbeiten  \n",
       "1  viel spa√ü damit eine wahl gewinnen stellt euch...  \n",
       "2  kleiner einwand von mir zur get√§tigten aussage...  \n",
       "3  etwas aus als jogginghose bezeichnen ist minde...  \n",
       "4      aber erst wenn sie wieder d√ºrfen playfullness  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n      <th>clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1079317443523297280</td>\n      <td>12303</td>\n      <td>Boulder667</td>\n      <td>@spdde @LadyBitchRay1 @spdbt @amazonDE @Zaland...</td>\n      <td>0</td>\n      <td>Liverpool, England</td>\n      <td>07-Mar-2021</td>\n      <td>116</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368470e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>quasi steuerfrei arbeiten</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1079317443523297280</td>\n      <td>12303</td>\n      <td>Boulder667</td>\n      <td>@spdde @LadyBitchRay1 Viel Spa√ü, damit eine Wa...</td>\n      <td>0</td>\n      <td>Liverpool, England</td>\n      <td>07-Mar-2021</td>\n      <td>116</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368148e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>viel spa√ü damit eine wahl gewinnen stellt euch...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1193535074660171776</td>\n      <td>693</td>\n      <td>FabIan68286784</td>\n      <td>@missbellalugosi @Zalando Kleiner Einwand von ...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>57</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368196e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>kleiner einwand von mir zur get√§tigten aussage...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1318999115313876996</td>\n      <td>1554</td>\n      <td>mantis_spam</td>\n      <td>@missbellalugosi @Zalando Etwas aus PU als Jog...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>1273</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>1.368196e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>etwas aus als jogginghose bezeichnen ist minde...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>310342425</td>\n      <td>11476</td>\n      <td>AndyBaldauf</td>\n      <td>@dicecco @Zalando aber erst wenn sie wieder d√º...</td>\n      <td>0</td>\n      <td>Thurgau | St. Gallen | Z√ºrich</td>\n      <td>06-Mar-2021</td>\n      <td>1848</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368146e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>aber erst wenn sie wieder d√ºrfen playfullness</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#import demoji\n",
    "de_df['clean'] = clean_complete(de_df.tweet)\n",
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-7-dfb30a3f3187>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(pat, '')\n",
      "<ipython-input-7-dfb30a3f3187>:28: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              user_id  user_statuses            name  \\\n",
       "0      0  1079317443523297280          12303      Boulder667   \n",
       "1      1  1079317443523297280          12303      Boulder667   \n",
       "2      2  1193535074660171776            693  FabIan68286784   \n",
       "3      3  1318999115313876996           1554     mantis_spam   \n",
       "4      4            310342425          11476     AndyBaldauf   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  @spdde @LadyBitchRay1 @spdbt @amazonDE @Zaland...         0   \n",
       "1  @spdde @LadyBitchRay1 Viel Spa√ü, damit eine Wa...         0   \n",
       "2  @missbellalugosi @Zalando Kleiner Einwand von ...         0   \n",
       "3  @missbellalugosi @Zalando Etwas aus PU als Jog...         0   \n",
       "4  @dicecco @Zalando aber erst wenn sie wieder d√º...         0   \n",
       "\n",
       "                        location      created  followers  is_user_verified  \\\n",
       "0             Liverpool, England  07-Mar-2021        116             False   \n",
       "1             Liverpool, England  07-Mar-2021        116             False   \n",
       "2                                 06-Mar-2021         57             False   \n",
       "3                                 06-Mar-2021       1273             False   \n",
       "4  Thurgau | St. Gallen | Z√ºrich  06-Mar-2021       1848             False   \n",
       "\n",
       "   favorite_count  in_reply_to_status_id  keyword language  \\\n",
       "0             0.0           1.368470e+18  zalando       de   \n",
       "1             1.0           1.368148e+18  zalando       de   \n",
       "2             0.0           1.368196e+18  zalando       de   \n",
       "3             2.0           1.368196e+18  zalando       de   \n",
       "4             0.0           1.368146e+18  zalando       de   \n",
       "\n",
       "                                               clean  \\\n",
       "0                          quasi steuerfrei arbeiten   \n",
       "1  viel spa√ü damit eine wahl gewinnen stellt euch...   \n",
       "2  kleiner einwand von mir zur get√§tigten aussage...   \n",
       "3  etwas aus als jogginghose bezeichnen ist minde...   \n",
       "4      aber erst wenn sie wieder d√ºrfen playfullness   \n",
       "\n",
       "                                         clean_vader  \n",
       "0                          Quasi steuerfrei arbeiten  \n",
       "1  Viel Spa√ü, damit eine Wahl gewinnen. Stellt Eu...  \n",
       "2  Kleiner Einwand von mir zur get√§tigten Aussage...  \n",
       "3  Etwas aus als Jogginghose bezeichnen ist minde...  \n",
       "4               aber erst wenn sie wieder d√ºrfen :-P  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1079317443523297280</td>\n      <td>12303</td>\n      <td>Boulder667</td>\n      <td>@spdde @LadyBitchRay1 @spdbt @amazonDE @Zaland...</td>\n      <td>0</td>\n      <td>Liverpool, England</td>\n      <td>07-Mar-2021</td>\n      <td>116</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368470e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>quasi steuerfrei arbeiten</td>\n      <td>Quasi steuerfrei arbeiten</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1079317443523297280</td>\n      <td>12303</td>\n      <td>Boulder667</td>\n      <td>@spdde @LadyBitchRay1 Viel Spa√ü, damit eine Wa...</td>\n      <td>0</td>\n      <td>Liverpool, England</td>\n      <td>07-Mar-2021</td>\n      <td>116</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368148e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>viel spa√ü damit eine wahl gewinnen stellt euch...</td>\n      <td>Viel Spa√ü, damit eine Wahl gewinnen. Stellt Eu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1193535074660171776</td>\n      <td>693</td>\n      <td>FabIan68286784</td>\n      <td>@missbellalugosi @Zalando Kleiner Einwand von ...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>57</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368196e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>kleiner einwand von mir zur get√§tigten aussage...</td>\n      <td>Kleiner Einwand von mir zur get√§tigten Aussage...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1318999115313876996</td>\n      <td>1554</td>\n      <td>mantis_spam</td>\n      <td>@missbellalugosi @Zalando Etwas aus PU als Jog...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>1273</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>1.368196e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>etwas aus als jogginghose bezeichnen ist minde...</td>\n      <td>Etwas aus als Jogginghose bezeichnen ist minde...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>310342425</td>\n      <td>11476</td>\n      <td>AndyBaldauf</td>\n      <td>@dicecco @Zalando aber erst wenn sie wieder d√º...</td>\n      <td>0</td>\n      <td>Thurgau | St. Gallen | Z√ºrich</td>\n      <td>06-Mar-2021</td>\n      <td>1848</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368146e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>aber erst wenn sie wieder d√ºrfen playfullness</td>\n      <td>aber erst wenn sie wieder d√ºrfen :-P</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "de_df['clean_vader'] = clean_vader(de_df.tweet)\n",
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "@missbellalugosi @Zalando Kleiner Einwand von mir zur get√§tigten Aussage, auf dem Bild steht ja Oberstoff Material 100% Polyurethan und weiter unten Material 100% Latex. Kann es sein das nur die obere Schicht pu ist und die untere Latex oder ist das ein Denkfehler seitens Zalando?\n",
      "kleiner einwand von mir zur get√§tigten aussage auf dem bild steht oberstoff material polyurethan und weiter unten material latex kann sein das nur die obere schicht ist und die untere latex oder ist das ein denkfehler seitens zalando\n",
      "Kleiner Einwand von mir zur get√§tigten Aussage, auf dem Bild steht Oberstoff Material Polyurethan und weiter unten Material Latex. Kann sein das nur die obere Schicht ist und die untere Latex oder ist das ein Denkfehler seitens Zalando?\n"
     ]
    }
   ],
   "source": [
    "print(de_df.tweet[2])\n",
    "print(de_df.clean[2])\n",
    "print(de_df.clean_vader[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vater sentiment analyzer\n",
    "#The Compound score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1(most extreme negative) and +1 (most extreme positive).\n",
    "\n",
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "de_df['compound'] = [sid_obj.polarity_scores(c)['compound'] for c in de_df['clean_vader']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           compound\n",
      "count  10222.000000\n",
      "mean      -0.161686\n",
      "std        0.368568\n",
      "min       -0.966100\n",
      "25%       -0.599400\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.969800\n"
     ]
    }
   ],
   "source": [
    "print(de_df[['clean_vader', 'compound']].describe())"
   ]
  },
  {
   "source": [
    "# Testing cleaning function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-13-5463527a300c>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n  de_df.tweet = de_df.tweet.str.replace(pat, '')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  Kleiner Einwand von mir zur get√§tigten Aussage, auf dem Bild steht ja Oberstoff Material 100% Polyurethan und weiter unten Material 100% Latex. Kann es sein das nur die obere Schicht pu ist und die untere Latex oder ist das ein Denkfehler seitens Zalando?'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#testing\n",
    "#delete links, users\n",
    "pat = r\"(\\\\n)|(@\\w*)|((https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}))\"\n",
    "de_df.tweet = de_df.tweet.str.replace(pat, '')\n",
    "de_df.tweet[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove chars more than twice\n",
    "#str.replace( /(.)\\1{2,}/g, '$1$1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-15-a5a60d69cb5d>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  de_df.tweet = de_df.tweet.str.replace(r':-\\)', ' smile')\n",
      "<ipython-input-15-a5a60d69cb5d>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  de_df.tweet = de_df.tweet.str.replace(r':-\\(', ' sad')\n",
      "<ipython-input-15-a5a60d69cb5d>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  de_df.tweet = de_df.tweet.str.replace(r':-\\/', ' confused')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  Kleiner Einwand von mir zur get√§tigten Aussage, auf dem Bild steht ja Oberstoff Material 100% Polyurethan und weiter unten Material 100% Latex. Kann es sein das nur die obere Schicht pu ist und die untere Latex oder ist das ein Denkfehler seitens Zalando?'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "\n",
    "#testing\n",
    "# #replace emoticons with words\n",
    "#SMILEYS = {\":-(\":\"sad\", \":‚Äë)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "de_df.tweet = de_df.tweet.str.replace(r':-\\)', ' smile')\n",
    "de_df.tweet = de_df.tweet.str.replace(r':-\\(', ' sad')\n",
    "de_df.tweet = de_df.tweet.str.replace(r':-\\/', ' confused')\n",
    "de_df.tweet = de_df.tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "de_df.tweet[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'     Quasi steuerfrei arbeiten'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#testing#delete \\xa\n",
    "de_df.tweet = de_df.tweet.str.replace('\\xa0', '')\n",
    "de_df.tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Ich Befriedigte Mich Nat√ºrlich bereits Heute ü§§welch Dumme Frage.... Die Gewinnerin von 25 Euro Zalando ist Heute......'"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#testing\n",
    "de_df.tweet = de_df.tweet.str.replace('&amp', '')\n",
    "de_df.tweet = de_df.tweet.str.replace('\\n', '')\n",
    "de_df.tweet[3140]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  kleiner einwand von mir zur get√§tigten aussage, auf dem bild steht ja oberstoff material 100% polyurethan und weiter unten material 100% latex. kann es sein das nur die obere schicht pu ist und die untere latex oder ist das ein denkfehler seitens zalando?'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "#testing#to lower case\n",
    "de_df.tweet = de_df.tweet.str.lower()\n",
    "de_df.tweet[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-19-46b7def794f7>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  de_df.tweet = de_df.tweet.str.replace(r'#([^\\s]+)', r'\\1')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  kleiner einwand von mir zur get√§tigten aussage, auf dem bild steht ja oberstoff material 100% polyurethan und weiter unten material 100% latex. kann es sein das nur die obere schicht pu ist und die untere latex oder ist das ein denkfehler seitens zalando?'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#testing#covert hashtags to the normal text\n",
    "de_df.tweet = de_df.tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "de_df.tweet[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'k√∂nnen wir uns auf die bezeichnung ‚Äûcouchhose‚Äú verst√§ndigen? f√ºhle mich durch die formulierung ‚Äûjogginghose‚Äú mental unter druck gesetzt. muss das sein   ; co?'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "#testing#delete numbers\n",
    "de_df.tweet = [strip_numeric(c) for c in de_df.tweet]\n",
    "de_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'wir schlie√üen eine partnerschaft mit  zur f√∂rderung von diversity ! mehr dazu in der pressemitteilung (link am ende)!//happy to announce our partnership with  to promote diversity! find more information in the press release:  '"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "#testing#replacing emojies with descriptions '‚ù§Ô∏è-> red heart'\n",
    "de_df.tweet = [demoji.replace_with_desc(c, ' ') for c in de_df.tweet]\n",
    "de_df.tweet[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'k√∂nnen wir uns auf die bezeichnung ‚Äûcouchhose‚Äú verst√§ndigen  f√ºhle mich durch die formulierung ‚Äûjogginghose‚Äú mental unter druck gesetzt  muss das sein     co '"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "##testing delete punctuation\n",
    "de_df.tweet = [strip_punctuation(c) for c in de_df.tweet]\n",
    "de_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'k√∂nnen wir uns auf die bezeichnung ‚Äûcouchhose‚Äú verst√§ndigen f√ºhle mich durch die formulierung ‚Äûjogginghose‚Äú mental unter druck gesetzt muss das sein'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "#testing\n",
    "de_df.tweet = [remove_stopwords(c) for c in de_df.tweet]\n",
    "de_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'k√∂nnen wir uns auf die bezeichnung ‚Äûcouchhose‚Äú verst√§ndigen f√ºhle mich durch die formulierung ‚Äûjogginghose‚Äú mental unter druck gesetzt muss das sein'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#testin\n",
    "de_df.tweet = [strip_multiple_whitespaces(c) for c in de_df.tweet]\n",
    "de_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tweet):\n",
    "    '''\n",
    "    tweet: pandas series\n",
    "    should be applied on the cleaned tweets to transform words to their initial base form.\n",
    "    For example: suggests -> suggest, deliveries -> delivery\n",
    "    '''\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tweet = [nlp(c) for c in tweet]\n",
    "    tweet = [\" \".join([token.lemma_ for token in t]) for t in tweet]\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# spacy.load('en_core_web_sm')\n",
    "# from spacy.lang.ge import German\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-fcdca94e77d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mde_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lem'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mde_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-fcdca94e77d1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mde_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lem'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mde_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "de_df['lem'] = [nlp(c) for c in de_df.clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lem'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-be68f01c13d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mde_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m868\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\deniz\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lem'"
     ]
    }
   ],
   "source": [
    "de_df.lem[868]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lem'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-660342813cd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meng_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lemma'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meng_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0meng_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\deniz\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lem'"
     ]
    }
   ],
   "source": [
    "de_df['lemma'] = [\" \".join([token.lemma_ for token in t]) for t in de_df.lem]\n",
    "de_df.lemma[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses           name  \\\n",
       "0        0      0   793418126500000000            521  MILESmobility   \n",
       "1        1      1  1119231287000000128             23       pici1303   \n",
       "2        2      2  1119231287000000128             23       pici1303   \n",
       "3        3      3  1119231287000000128             23       pici1303   \n",
       "4        4      4  1119231287000000128             23       pici1303   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Good News! Alle interessierten MitarbeiterInne...         0   \n",
       "1  @Zalando Ich wei√ü dass der Schein da rein muss...         0   \n",
       "2  @Zalando Ich hab mich nur gefragt wof√ºr dieser...         0   \n",
       "3  @Zalando Ich hab doch schon den R√ºcksendeschei...         0   \n",
       "4  @Zalando bei der Retoure ist noch ein einzelne...         0   \n",
       "\n",
       "              location      created  followers  is_user_verified language  \\\n",
       "0  Berlin, Deutschland  05-Mar-2021        768             False       de   \n",
       "1                       04-Mar-2021          0             False       de   \n",
       "2                       04-Mar-2021          0             False       de   \n",
       "3                       04-Mar-2021          0             False       de   \n",
       "4                       04-Mar-2021          0             False       de   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \n",
       "0  @zalando             NaN                    NaN  \n",
       "1  @zalando             NaN                    NaN  \n",
       "2  @zalando             NaN                    NaN  \n",
       "3  @zalando             NaN                    NaN  \n",
       "4  @zalando             NaN                    NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>793418126500000000</td>\n      <td>521</td>\n      <td>MILESmobility</td>\n      <td>Good News! Alle interessierten MitarbeiterInne...</td>\n      <td>0</td>\n      <td>Berlin, Deutschland</td>\n      <td>05-Mar-2021</td>\n      <td>768</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich wei√ü dass der Schein da rein muss...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab mich nur gefragt wof√ºr dieser...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab doch schon den R√ºcksendeschei...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando bei der Retoure ist noch ein einzelne...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "de_df.head()"
   ]
  },
  {
   "source": [
    "# Data description\n",
    "- tweet: initial tweet as it was downloaded from API\n",
    "- clean: tweet cleaned completely from punctuation, emojies, emoticons, stopwords, special characters, users, hashtags, links\n",
    "- clean_vader: tweet partly cleaned, saving punctuation, emoticons, emojies for using library Vader to get the sentiment of the tweet\n",
    "- compouns: from -1 (negative) to 1 (positive), 0 - neutral, a tweet sentiment derived fro, Vader library\n",
    "- lem: intermidiate step before lemmatization\n",
    "- lemma: lemmatized words (sent -> send)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Save the dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(eng_df, open(r'.\\de_df_labelled.pkl', 'wb'))"
   ]
  }
 ]
}