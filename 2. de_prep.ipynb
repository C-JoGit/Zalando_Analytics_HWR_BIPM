{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Annelie Schridde\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_tags, strip_numeric, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short, stem_text\n",
    "import pickle\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "# import en_core_web_sm\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Annelie Schridde\\AppData\\Roaming\\Python\\Python38\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "Downloading emoji data ...\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Annelie\n",
      "[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Annelie\n",
      "[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Annelie\n",
      "[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "... OK (Got response in 0.68 seconds)\n",
      "Writing emoji data to C:\\Users\\Annelie Schridde\\.demoji\\codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('../')\n",
    "#import functions\n",
    "#exec(open('./functions.py').read())\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses           name  \\\n",
       "0        0      0   793418126500000000            521  MILESmobility   \n",
       "1        1      1  1119231287000000128             23       pici1303   \n",
       "2        2      2  1119231287000000128             23       pici1303   \n",
       "3        3      3  1119231287000000128             23       pici1303   \n",
       "4        4      4  1119231287000000128             23       pici1303   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Good News! Alle interessierten MitarbeiterInne...         0   \n",
       "1  @Zalando Ich weiß dass der Schein da rein muss...         0   \n",
       "2  @Zalando Ich hab mich nur gefragt wofür dieser...         0   \n",
       "3  @Zalando Ich hab doch schon den Rücksendeschei...         0   \n",
       "4  @Zalando bei der Retoure ist noch ein einzelne...         0   \n",
       "\n",
       "              location      created  followers  is_user_verified language  \\\n",
       "0  Berlin, Deutschland  05-Mar-2021        768             False       de   \n",
       "1                       04-Mar-2021          0             False       de   \n",
       "2                       04-Mar-2021          0             False       de   \n",
       "3                       04-Mar-2021          0             False       de   \n",
       "4                       04-Mar-2021          0             False       de   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \n",
       "0  @zalando             NaN                    NaN  \n",
       "1  @zalando             NaN                    NaN  \n",
       "2  @zalando             NaN                    NaN  \n",
       "3  @zalando             NaN                    NaN  \n",
       "4  @zalando             NaN                    NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>793418126500000000</td>\n      <td>521</td>\n      <td>MILESmobility</td>\n      <td>Good News! Alle interessierten MitarbeiterInne...</td>\n      <td>0</td>\n      <td>Berlin, Deutschland</td>\n      <td>05-Mar-2021</td>\n      <td>768</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich weiß dass der Schein da rein muss...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab mich nur gefragt wofür dieser...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab doch schon den Rücksendeschei...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando bei der Retoure ist noch ein einzelne...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_json('./data_n_models/one_cleaned_df.json')\n",
    "de_df = df[df.language == 'de'].reset_index()\n",
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_complete(tweet):\n",
    "    \"\"\"\n",
    "    tweet: pandas series\n",
    "    prepares tweets complete cleaning for further lemmatization and dering embeddings\n",
    "    \"\"\"\n",
    "    pat = r\"(\\\\n)|(@\\w*)|((www\\.[^\\s]+)|(https?://[^\\s]+))\"\n",
    "    tweet = tweet.str.replace(pat, '')\n",
    "\n",
    "    #remove repeated charachters\n",
    "    \n",
    "    #replace emoticons with words\n",
    "    #SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "    tweet = tweet.str.replace(r':-\\)', ' smile')\n",
    "    tweet = tweet.str.replace(r':-\\(', ' sad')\n",
    "    tweet = tweet.str.replace(r':-\\/', ' confused')\n",
    "    tweet = tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "    #delete \\xa\n",
    "    tweet = tweet.str.replace('\\xa0', '')\n",
    "\n",
    "    tweet = tweet.str.replace('&amp', '')\n",
    "    tweet = tweet.str.replace('\\n', '')\n",
    "    tweet = tweet.str.replace('\"', '')\n",
    "    #to lower case\n",
    "    tweet = tweet.str.lower()\n",
    "\n",
    "    #covert hashtags to the normal text\n",
    "    tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "\n",
    "    #delete numbers\n",
    "    tweet = [strip_numeric(c) for c in tweet]\n",
    "\n",
    "    #replacing emojies with descriptions '❤️-> red heart'\n",
    "    #tweet = [demoji.replace_with_desc(c, ' ') for c in tweet]\n",
    "\n",
    "    #delete punctuation\n",
    "    tweet = [strip_punctuation(c) for c in tweet]\n",
    "\n",
    "    #remove stop words\n",
    "    tweet = [remove_stopwords(c) for c in tweet]\n",
    "\n",
    "    #remove short words\n",
    "    tweet = [strip_short(c) for c in tweet]\n",
    "\n",
    "    #remove mult whitespaces\n",
    "    tweet = [strip_multiple_whitespaces(c) for c in tweet]\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_vader(tweet):\n",
    "    \"\"\"\n",
    "    tweet: pandas series\n",
    "    prepares tweets for vader sentiment analysis\n",
    "    \"\"\"\n",
    "\n",
    "    pat = r\"(\\\\n)|(@\\w*)|((www\\.[^\\s]+)|(https?://[^\\s]+))\"\n",
    "    tweet = tweet.str.replace(pat, '')\n",
    "\n",
    "    #replace emoticons with words\n",
    "    #SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "    #tweet = tweet.str.replace(r':-\\)', ' smile')\n",
    "    #tweet = tweet.str.replace(r':-\\(', ' sad')\n",
    "    #tweet = tweet.str.replace(r':-\\/', ' confused')\n",
    "    #tweet = tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "    #delete \\xa\n",
    "    tweet = tweet.str.replace('\\xa0', '')\n",
    "\n",
    "    tweet = tweet.str.replace('&amp', '')\n",
    "    tweet = tweet.str.replace('\\n', '')\n",
    "\n",
    "    #to lower case\n",
    "    #tweet = tweet.str.lower()\n",
    "\n",
    "    #covert hashtags to the normal text\n",
    "    tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "\n",
    "    #delete numbers\n",
    "    tweet = [strip_numeric(c) for c in tweet]\n",
    "\n",
    "    #replacing emojies with descriptions '❤️-> red heart'\n",
    "    #tweet = [demoji.replace_with_desc(c, ' ') for c in tweet]\n",
    "\n",
    "    #delete punctuation\n",
    "    #tweet = [strip_punctuation(c) for c in tweet]\n",
    "\n",
    "    #remove stop words\n",
    "    #tweet = [remove_stopwords(c) for c in tweet]\n",
    "\n",
    "    #remove short words\n",
    "    tweet = [strip_short(c) for c in tweet]\n",
    "\n",
    "    #remove mult whitespaces\n",
    "    tweet = [strip_multiple_whitespaces(c) for c in tweet]\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-4-abe84fc2115d>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(pat, '')\n",
      "<ipython-input-4-abe84fc2115d>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r':-\\)', ' smile')\n",
      "<ipython-input-4-abe84fc2115d>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r':-\\(', ' sad')\n",
      "<ipython-input-4-abe84fc2115d>:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r':-\\/', ' confused')\n",
      "<ipython-input-4-abe84fc2115d>:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses           name  \\\n",
       "0        0      0   793418126500000000            521  MILESmobility   \n",
       "1        1      1  1119231287000000128             23       pici1303   \n",
       "2        2      2  1119231287000000128             23       pici1303   \n",
       "3        3      3  1119231287000000128             23       pici1303   \n",
       "4        4      4  1119231287000000128             23       pici1303   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Good News! Alle interessierten MitarbeiterInne...         0   \n",
       "1  @Zalando Ich weiß dass der Schein da rein muss...         0   \n",
       "2  @Zalando Ich hab mich nur gefragt wofür dieser...         0   \n",
       "3  @Zalando Ich hab doch schon den Rücksendeschei...         0   \n",
       "4  @Zalando bei der Retoure ist noch ein einzelne...         0   \n",
       "\n",
       "              location      created  followers  is_user_verified language  \\\n",
       "0  Berlin, Deutschland  05-Mar-2021        768             False       de   \n",
       "1                       04-Mar-2021          0             False       de   \n",
       "2                       04-Mar-2021          0             False       de   \n",
       "3                       04-Mar-2021          0             False       de   \n",
       "4                       04-Mar-2021          0             False       de   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \\\n",
       "0  @zalando             NaN                    NaN   \n",
       "1  @zalando             NaN                    NaN   \n",
       "2  @zalando             NaN                    NaN   \n",
       "3  @zalando             NaN                    NaN   \n",
       "4  @zalando             NaN                    NaN   \n",
       "\n",
       "                                               clean  \n",
       "0  good news alle interessierten mitarbeiterinnen...  \n",
       "1  ich weiß dass der schein rein muss aber ist mi...  \n",
       "2  ich hab mich nur gefragt wofür dieser extra co...  \n",
       "3  ich hab doch schon den rücksendeschein draufge...  \n",
       "4  bei der retoure ist noch ein einzelner extra c...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>793418126500000000</td>\n      <td>521</td>\n      <td>MILESmobility</td>\n      <td>Good News! Alle interessierten MitarbeiterInne...</td>\n      <td>0</td>\n      <td>Berlin, Deutschland</td>\n      <td>05-Mar-2021</td>\n      <td>768</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>good news alle interessierten mitarbeiterinnen...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich weiß dass der Schein da rein muss...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich weiß dass der schein rein muss aber ist mi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab mich nur gefragt wofür dieser...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich hab mich nur gefragt wofür dieser extra co...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab doch schon den Rücksendeschei...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich hab doch schon den rücksendeschein draufge...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando bei der Retoure ist noch ein einzelne...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>bei der retoure ist noch ein einzelner extra c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#import demoji\n",
    "de_df['clean'] = clean_complete(de_df.tweet)\n",
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-dfb30a3f3187>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(pat, '')\n",
      "<ipython-input-5-dfb30a3f3187>:28: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses           name  \\\n",
       "0        0      0   793418126500000000            521  MILESmobility   \n",
       "1        1      1  1119231287000000128             23       pici1303   \n",
       "2        2      2  1119231287000000128             23       pici1303   \n",
       "3        3      3  1119231287000000128             23       pici1303   \n",
       "4        4      4  1119231287000000128             23       pici1303   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Good News! Alle interessierten MitarbeiterInne...         0   \n",
       "1  @Zalando Ich weiß dass der Schein da rein muss...         0   \n",
       "2  @Zalando Ich hab mich nur gefragt wofür dieser...         0   \n",
       "3  @Zalando Ich hab doch schon den Rücksendeschei...         0   \n",
       "4  @Zalando bei der Retoure ist noch ein einzelne...         0   \n",
       "\n",
       "              location      created  followers  is_user_verified language  \\\n",
       "0  Berlin, Deutschland  05-Mar-2021        768             False       de   \n",
       "1                       04-Mar-2021          0             False       de   \n",
       "2                       04-Mar-2021          0             False       de   \n",
       "3                       04-Mar-2021          0             False       de   \n",
       "4                       04-Mar-2021          0             False       de   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \\\n",
       "0  @zalando             NaN                    NaN   \n",
       "1  @zalando             NaN                    NaN   \n",
       "2  @zalando             NaN                    NaN   \n",
       "3  @zalando             NaN                    NaN   \n",
       "4  @zalando             NaN                    NaN   \n",
       "\n",
       "                                               clean  \\\n",
       "0  good news alle interessierten mitarbeiterinnen...   \n",
       "1  ich weiß dass der schein rein muss aber ist mi...   \n",
       "2  ich hab mich nur gefragt wofür dieser extra co...   \n",
       "3  ich hab doch schon den rücksendeschein draufge...   \n",
       "4  bei der retoure ist noch ein einzelner extra c...   \n",
       "\n",
       "                                         clean_vader  \n",
       "0  Good News! Alle interessierten MitarbeiterInne...  \n",
       "1  Ich weiß dass der Schein rein muss aber was is...  \n",
       "2  Ich hab mich nur gefragt wofür dieser extra Co...  \n",
       "3  Ich hab doch schon den Rücksendeschein draufge...  \n",
       "4  bei der Retoure ist noch ein einzelner extra c...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>793418126500000000</td>\n      <td>521</td>\n      <td>MILESmobility</td>\n      <td>Good News! Alle interessierten MitarbeiterInne...</td>\n      <td>0</td>\n      <td>Berlin, Deutschland</td>\n      <td>05-Mar-2021</td>\n      <td>768</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>good news alle interessierten mitarbeiterinnen...</td>\n      <td>Good News! Alle interessierten MitarbeiterInne...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich weiß dass der Schein da rein muss...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich weiß dass der schein rein muss aber ist mi...</td>\n      <td>Ich weiß dass der Schein rein muss aber was is...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab mich nur gefragt wofür dieser...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich hab mich nur gefragt wofür dieser extra co...</td>\n      <td>Ich hab mich nur gefragt wofür dieser extra Co...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab doch schon den Rücksendeschei...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich hab doch schon den rücksendeschein draufge...</td>\n      <td>Ich hab doch schon den Rücksendeschein draufge...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando bei der Retoure ist noch ein einzelne...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>bei der retoure ist noch ein einzelner extra c...</td>\n      <td>bei der Retoure ist noch ein einzelner extra c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "de_df['clean_vader'] = clean_vader(de_df.tweet)\n",
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "@Zalando Ich hab mich nur gefragt wofür dieser extra Code ist? https://t.co/e8gQcklkL7\n",
      "ich hab mich nur gefragt wofür dieser extra code ist\n",
      "Ich hab mich nur gefragt wofür dieser extra Code ist?\n"
     ]
    }
   ],
   "source": [
    "print(de_df.tweet[2])\n",
    "print(de_df.clean[2])\n",
    "print(de_df.clean_vader[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vater sentiment analyzer\n",
    "#The Compound score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1(most extreme negative) and +1 (most extreme positive).\n",
    "\n",
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "de_df['compound'] = [sid_obj.polarity_scores(c)['compound'] for c in de_df['clean_vader']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           compound\n",
      "count  10605.000000\n",
      "mean      -0.161764\n",
      "std        0.368385\n",
      "min       -0.966100\n",
      "25%       -0.599400\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.969800\n"
     ]
    }
   ],
   "source": [
    "print(de_df[['clean_vader', 'compound']].describe())"
   ]
  },
  {
   "source": [
    "# Testing cleaning function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-11-5463527a300c>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n  de_df.tweet = de_df.tweet.str.replace(pat, '')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' Ich hab mich nur gefragt wofür dieser extra Code ist? '"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#testing\n",
    "#delete links, users\n",
    "pat = r\"(\\\\n)|(@\\w*)|((https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}))\"\n",
    "de_df.tweet = de_df.tweet.str.replace(pat, '')\n",
    "de_df.tweet[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove chars more than twice\n",
    "#str.replace( /(.)\\1{2,}/g, '$1$1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-13-a5a60d69cb5d>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  de_df.tweet = de_df.tweet.str.replace(r':-\\)', ' smile')\n",
      "<ipython-input-13-a5a60d69cb5d>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  de_df.tweet = de_df.tweet.str.replace(r':-\\(', ' sad')\n",
      "<ipython-input-13-a5a60d69cb5d>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  de_df.tweet = de_df.tweet.str.replace(r':-\\/', ' confused')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' Ich hab mich nur gefragt wofür dieser extra Code ist? '"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\n",
    "#testing\n",
    "# #replace emoticons with words\n",
    "#SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "de_df.tweet = de_df.tweet.str.replace(r':-\\)', ' smile')\n",
    "de_df.tweet = de_df.tweet.str.replace(r':-\\(', ' sad')\n",
    "de_df.tweet = de_df.tweet.str.replace(r':-\\/', ' confused')\n",
    "de_df.tweet = de_df.tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "de_df.tweet[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Good News! Alle interessierten MitarbeiterInnen der Berliner  erhalten täglich ein #Mobilitätsbudget in Höhe von 10€, das sie für Fahrten mit #MILES einlösen können.\\n\\nDanke an , die die ganze Aktion sponsern! '"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#testing#delete \\xa\n",
    "de_df.tweet = de_df.tweet.str.replace('\\xa0', '')\n",
    "de_df.tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' Sehen wir vielleicht bald auch eine Beauty-Eigenmarken bei Zalando?'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "#testing\n",
    "de_df.tweet = de_df.tweet.str.replace('&amp', '')\n",
    "de_df.tweet = de_df.tweet.str.replace('\\n', '')\n",
    "de_df.tweet[3140]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' ich hab mich nur gefragt wofür dieser extra code ist? '"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#testing#to lower case\n",
    "de_df.tweet = de_df.tweet.str.lower()\n",
    "de_df.tweet[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-17-46b7def794f7>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  de_df.tweet = de_df.tweet.str.replace(r'#([^\\s]+)', r'\\1')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' ich hab mich nur gefragt wofür dieser extra code ist? '"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#testing#covert hashtags to the normal text\n",
    "de_df.tweet = de_df.tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "de_df.tweet[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  solche loser'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "#testing#delete numbers\n",
    "de_df.tweet = [strip_numeric(c) for c in de_df.tweet]\n",
    "de_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'zalando braucht einfach tage für ne lieferung ich bestell da nie wieder wtf schonmal von nächster tag delivery gehört ach du scheiße ihr versager'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "#testing#replacing emojies with descriptions '❤️-> red heart'\n",
    "de_df.tweet = [demoji.replace_with_desc(c, ' ') for c in de_df.tweet]\n",
    "de_df.tweet[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'solche loser'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "##testing delete punctuation\n",
    "de_df.tweet = [strip_punctuation(c) for c in de_df.tweet]\n",
    "de_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'solche loser'"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "#testing\n",
    "de_df.tweet = [remove_stopwords(c) for c in de_df.tweet]\n",
    "de_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'solche loser'"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "#testin\n",
    "de_df.tweet = [strip_multiple_whitespaces(c) for c in de_df.tweet]\n",
    "de_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tweet):\n",
    "    '''\n",
    "    tweet: pandas series\n",
    "    should be applied on the cleaned tweets to transform words to their initial base form.\n",
    "    For example: suggests -> suggest, deliveries -> delivery\n",
    "    '''\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tweet = [nlp(c) for c in tweet]\n",
    "    tweet = [\" \".join([token.lemma_ for token in t]) for t in tweet]\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#spacy.load('en_core_web_sm')\n",
    "from spacy.lang.de import German\n",
    "#nlp = spacy.load(\"en_core_web_sm\") # English?\n",
    "nlp = spacy.load(\"de_core_news_sm\") # German\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_df['lem'] = [nlp(c) for c in de_df.clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "asos und zara hat eig immer"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "de_df.lem[868]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'solche lose'"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "de_df['lemma'] = [\" \".join([token.lemma_ for token in t]) for t in de_df.lem]\n",
    "de_df.lemma[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses           name  \\\n",
       "0        0      0   793418126500000000            521  MILESmobility   \n",
       "1        1      1  1119231287000000128             23       pici1303   \n",
       "2        2      2  1119231287000000128             23       pici1303   \n",
       "3        3      3  1119231287000000128             23       pici1303   \n",
       "4        4      4  1119231287000000128             23       pici1303   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  good news alle interessierten mitarbeiterinnen...         0   \n",
       "1  ich weiß dass der schein da rein muss aber ist...         0   \n",
       "2  ich hab mich nur gefragt wofür dieser extra co...         0   \n",
       "3  ich hab doch schon den rücksendeschein draufge...         0   \n",
       "4  bei der retoure ist noch ein einzelner extra q...         0   \n",
       "\n",
       "              location      created  followers  is_user_verified language  \\\n",
       "0  Berlin, Deutschland  05-Mar-2021        768             False       de   \n",
       "1                       04-Mar-2021          0             False       de   \n",
       "2                       04-Mar-2021          0             False       de   \n",
       "3                       04-Mar-2021          0             False       de   \n",
       "4                       04-Mar-2021          0             False       de   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \\\n",
       "0  @zalando             NaN                    NaN   \n",
       "1  @zalando             NaN                    NaN   \n",
       "2  @zalando             NaN                    NaN   \n",
       "3  @zalando             NaN                    NaN   \n",
       "4  @zalando             NaN                    NaN   \n",
       "\n",
       "                                               clean  \\\n",
       "0  good news alle interessierten mitarbeiterinnen...   \n",
       "1  ich weiß dass der schein rein muss aber ist mi...   \n",
       "2  ich hab mich nur gefragt wofür dieser extra co...   \n",
       "3  ich hab doch schon den rücksendeschein draufge...   \n",
       "4  bei der retoure ist noch ein einzelner extra c...   \n",
       "\n",
       "                                         clean_vader  compound  \\\n",
       "0  Good News! Alle interessierten MitarbeiterInne...   -0.7568   \n",
       "1  Ich weiß dass der Schein rein muss aber was is...    0.0000   \n",
       "2  Ich hab mich nur gefragt wofür dieser extra Co...    0.0000   \n",
       "3  Ich hab doch schon den Rücksendeschein draufge...    0.0000   \n",
       "4  bei der Retoure ist noch ein einzelner extra c...    0.0000   \n",
       "\n",
       "                                                 lem  \\\n",
       "0  (good, news, alle, interessierten, mitarbeiter...   \n",
       "1  (ich, weiß, dass, der, schein, rein, muss, abe...   \n",
       "2  (ich, hab, mich, nur, gefragt, wofür, dieser, ...   \n",
       "3  (ich, hab, doch, schon, den, rücksendeschein, ...   \n",
       "4  (bei, der, retoure, ist, noch, ein, einzelner,...   \n",
       "\n",
       "                                               lemma  \n",
       "0  good news all interessieren mitarbeiterinnen d...  \n",
       "1  ich weiß dass der schein rein muss aber sein m...  \n",
       "2  ich hab sich nur fragen wofür dies extra code ...  \n",
       "3  ich hab doch schon der rücksendeschein draufge...  \n",
       "4  bei der retoure sein noch einen einzeln extra ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n      <th>compound</th>\n      <th>lem</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>793418126500000000</td>\n      <td>521</td>\n      <td>MILESmobility</td>\n      <td>good news alle interessierten mitarbeiterinnen...</td>\n      <td>0</td>\n      <td>Berlin, Deutschland</td>\n      <td>05-Mar-2021</td>\n      <td>768</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>good news alle interessierten mitarbeiterinnen...</td>\n      <td>Good News! Alle interessierten MitarbeiterInne...</td>\n      <td>-0.7568</td>\n      <td>(good, news, alle, interessierten, mitarbeiter...</td>\n      <td>good news all interessieren mitarbeiterinnen d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>ich weiß dass der schein da rein muss aber ist...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich weiß dass der schein rein muss aber ist mi...</td>\n      <td>Ich weiß dass der Schein rein muss aber was is...</td>\n      <td>0.0000</td>\n      <td>(ich, weiß, dass, der, schein, rein, muss, abe...</td>\n      <td>ich weiß dass der schein rein muss aber sein m...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>ich hab mich nur gefragt wofür dieser extra co...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich hab mich nur gefragt wofür dieser extra co...</td>\n      <td>Ich hab mich nur gefragt wofür dieser extra Co...</td>\n      <td>0.0000</td>\n      <td>(ich, hab, mich, nur, gefragt, wofür, dieser, ...</td>\n      <td>ich hab sich nur fragen wofür dies extra code ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>ich hab doch schon den rücksendeschein draufge...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ich hab doch schon den rücksendeschein draufge...</td>\n      <td>Ich hab doch schon den Rücksendeschein draufge...</td>\n      <td>0.0000</td>\n      <td>(ich, hab, doch, schon, den, rücksendeschein, ...</td>\n      <td>ich hab doch schon der rücksendeschein draufge...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1119231287000000128</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>bei der retoure ist noch ein einzelner extra q...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>de</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>bei der retoure ist noch ein einzelner extra c...</td>\n      <td>bei der Retoure ist noch ein einzelner extra c...</td>\n      <td>0.0000</td>\n      <td>(bei, der, retoure, ist, noch, ein, einzelner,...</td>\n      <td>bei der retoure sein noch einen einzeln extra ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "de_df.head()"
   ]
  },
  {
   "source": [
    "# Data description\n",
    "- tweet: initial tweet as it was downloaded from API\n",
    "- clean: tweet cleaned completely from punctuation, emojies, emoticons, stopwords, special characters, users, hashtags, links\n",
    "- clean_vader: tweet partly cleaned, saving punctuation, emoticons, emojies for using library Vader to get the sentiment of the tweet\n",
    "- compouns: from -1 (negative) to 1 (positive), 0 - neutral, a tweet sentiment derived fro, Vader library\n",
    "- lem: intermidiate step before lemmatization\n",
    "- lemma: lemmatized words (sent -> send)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Save the dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(de_df, open(r'data_n_models/de_df_labelled.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}