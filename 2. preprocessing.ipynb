{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd022a63b945ad88ad6aa60a7f3f570c70abf6faa8a03284077614716ef20649993",
   "display_name": "Python 3.7.10 64-bit ('uni': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_tags, strip_numeric, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short, stem_text\n",
    "import pickle\n",
    "import en_core_web_sm\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n",
      "Downloading emoji data ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "... OK (Got response in 0.46 seconds)\n",
      "Writing emoji data to C:\\Users\\home\\.demoji\\codes.json ...\n",
      "... OK\n",
      "Downloading emoji data ...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "... OK (Got response in 0.43 seconds)\n",
      "Writing emoji data to C:\\Users\\home\\.demoji\\codes.json ...\n",
      "... OK\n",
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.42 seconds)\n",
      "Writing emoji data to C:\\Users\\home\\.demoji\\codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import functions\n",
    "exec(open('./functions.py').read())\n",
    "\n",
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              user_id  user_statuses             name  \\\n",
       "0      0   819101311715131392             77      Ali09685762   \n",
       "1      1  1189512849472643072            105       Labellerr1   \n",
       "2      2           2837691996            270  puneetjindalisb   \n",
       "3      3  1125728513666048000           9604    DommeLineCoUk   \n",
       "4      4           2614256724          35470         medboyUK   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0            @Zalando give me my money you owe me!!!         0   \n",
       "1  #VirtualStyling and try-on increases the conve...         0   \n",
       "2  #VirtualStyling and try-on increases the conve...         0   \n",
       "3  @missbellalugosi @Zalando Problem starts at Ad...         0   \n",
       "4  @missbellalugosi @Zalando Welcome to my world ...         0   \n",
       "\n",
       "            location      created  followers  is_user_verified  \\\n",
       "0                     07-Mar-2021          6             False   \n",
       "1         chandigarh  06-Mar-2021         18             False   \n",
       "2  Chandigarh, India  06-Mar-2021        149             False   \n",
       "3                     06-Mar-2021       2193             False   \n",
       "4  West Midlands, UK  06-Mar-2021       2503             False   \n",
       "\n",
       "   favorite_count  in_reply_to_status_id   keyword language  \n",
       "0             0.0                    NaN  @zalando       en  \n",
       "1             0.0                    NaN  @zalando       en  \n",
       "2             0.0                    NaN  @zalando       en  \n",
       "3             1.0           1.368196e+18  @zalando       en  \n",
       "4             1.0           1.368196e+18  @zalando       en  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>819101311715131392</td>\n      <td>77</td>\n      <td>Ali09685762</td>\n      <td>@Zalando give me my money you owe me!!!</td>\n      <td>0</td>\n      <td></td>\n      <td>07-Mar-2021</td>\n      <td>6</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1189512849472643072</td>\n      <td>105</td>\n      <td>Labellerr1</td>\n      <td>#VirtualStyling and try-on increases the conve...</td>\n      <td>0</td>\n      <td>chandigarh</td>\n      <td>06-Mar-2021</td>\n      <td>18</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2837691996</td>\n      <td>270</td>\n      <td>puneetjindalisb</td>\n      <td>#VirtualStyling and try-on increases the conve...</td>\n      <td>0</td>\n      <td>Chandigarh, India</td>\n      <td>06-Mar-2021</td>\n      <td>149</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1125728513666048000</td>\n      <td>9604</td>\n      <td>DommeLineCoUk</td>\n      <td>@missbellalugosi @Zalando Problem starts at Ad...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>2193</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368196e+18</td>\n      <td>@zalando</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2614256724</td>\n      <td>35470</td>\n      <td>medboyUK</td>\n      <td>@missbellalugosi @Zalando Welcome to my world ...</td>\n      <td>0</td>\n      <td>West Midlands, UK</td>\n      <td>06-Mar-2021</td>\n      <td>2503</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368196e+18</td>\n      <td>@zalando</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df = pickle.load(open('data_n_models/one_cleaned_df.pkl', \"rb\"))\n",
    "eng_df = df[df.language == 'en'].reset_index()\n",
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "frozenset({'really', 'mine', 'hereby', 'didn', 'everything', 'in', 'on', 'down', 'does', 'however', 'none', 'otherwise', 'full', 'done', 'much', 'show', 'fifteen', 'whoever', 'few', 'very', 'almost', 'thence', 'amongst', 'of', 'still', 'seeming', 'neither', 'could', 'why', 'something', 'thus', 'make', 'say', 'thru', 'when', 'three', 'meanwhile', 'until', 'himself', 'please', 'nobody', 'someone', 'myself', 'give', 'bottom', 'eight', 'every', 'both', 'anyone', 'namely', 'no', 'keep', 'or', 'who', 'these', 'a', 'the', 'don', 'may', 'doing', 'without', 'might', 'front', 'are', 'you', 'elsewhere', 'becoming', 'must', 'there', 'regarding', 'empty', 'take', 'sixty', 'we', 'own', 'seemed', 'below', 'else', 'becomes', 'together', 'whether', 'by', 'among', 'whence', 'whereby', 'con', 'found', 'as', 'such', 'will', 'around', 'indeed', 'here', 'less', 'somewhere', 'its', 'out', 'thin', 'our', 'rather', 'moreover', 'is', 'they', 'side', 'beforehand', 'up', 'being', 'after', 'sometime', 'hereupon', 'where', 'system', 'thereupon', 'toward', 'with', 'it', 'anything', 'since', 'whereas', 'many', 'across', 'wherever', 'his', 'whereafter', 'least', 'nine', 'seem', 'four', 'former', 'your', 'therein', 'either', 'he', 'because', 'anyway', 'throughout', 'twelve', 'would', 'besides', 'already', 'others', 'nowhere', 'she', 'once', 'first', 'sincere', 'doesn', 'now', 'again', 'eleven', 'third', 'get', 'beyond', 'go', 'be', 'yet', 'using', 'whole', 'then', 'more', 'from', 'can', 'even', 'onto', 'top', 'most', 'this', 'her', 'against', 'due', 'which', 'hers', 'fill', 'has', 'sometimes', 'enough', 'fire', 'call', 'their', 'between', 'anyhow', 'detail', 'interest', 'whose', 'de', 'that', 'have', 'six', 'several', 'beside', 'move', 'wherein', 'cannot', 'co', 'km', 'only', 'back', 'i', 'etc', 'thereby', 'towards', 'to', 'cry', 'during', 'were', 'any', 'had', 'computer', 'how', 'do', 'above', 'whereupon', 'thick', 'ours', 'upon', 'name', 'un', 'made', 'hereafter', 'inc', 'for', 'also', 'find', 'did', 'put', 'ever', 'anywhere', 'been', 'except', 'often', 'over', 'us', 'so', 'nor', 'further', 'formerly', 'per', 'somehow', 'see', 'noone', 'other', 'through', 'about', 'alone', 'at', 'itself', 'just', 'nothing', 'yourself', 'quite', 'herein', 'unless', 'eg', 'whom', 'became', 'if', 'herself', 'not', 'should', 'ltd', 'whenever', 'become', 'an', 'next', 'whither', 'along', 'twenty', 'well', 'everywhere', 'two', 'too', 'am', 'ie', 'off', 'than', 'bill', 'mostly', 'via', 'hundred', 'seems', 'latter', 'used', 'mill', 'therefore', 'yourselves', 'describe', 'serious', 'ten', 'although', 'them', 're', 'various', 'and', 'me', 'what', 'forty', 'never', 'nevertheless', 'all', 'each', 'five', 'afterwards', 'within', 'themselves', 'last', 'before', 'was', 'behind', 'fifty', 'hasnt', 'latterly', 'ourselves', 'perhaps', 'though', 'thereafter', 'my', 'whatever', 'amount', 'part', 'yours', 'while', 'him', 'amoungst', 'those', 'another', 'everyone', 'one', 'some', 'same', 'into', 'couldnt', 'cant', 'kg', 'hence', 'under', 'always', 'but'})\n"
     ]
    }
   ],
   "source": [
    "print(STOPWORDS)"
   ]
  },
  {
   "source": [
    "# Filter out companies` tweets\n",
    "There are some tweets that posted by companies themselves. In order to not take them into account we have to filter them out"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['MidwestWeather3',\n",
       " 'ASOS',\n",
       " 'Asos_m115',\n",
       " 'asos_order',\n",
       " 'asos_assyla',\n",
       " 'asos_askari',\n",
       " 'ASOS_Careers',\n",
       " 'nauj_asos',\n",
       " 'zalando_uk',\n",
       " 'Zalando_NL',\n",
       " 'Zalando',\n",
       " 'ZalandoTech',\n",
       " 'Zalando_Press',\n",
       " 'Proxy4Sure',\n",
       " 'Asos_Julia',\n",
       " '__asoS',\n",
       " 'ASOS_NickB',\n",
       " 'ASOS_again',\n",
       " 'ZalandoA',\n",
       " 'ASOS_HeretoHelp',\n",
       " 'boohoo_cshelp',\n",
       " 'BooHoo_Lili',\n",
       " 'Boohoo_Cracker_',\n",
       " 'boohoo',\n",
       " 'BOOHOO_ABI',\n",
       " 'Boohoo_DAN',\n",
       " 'boohoo_zoo',\n",
       " 'cracker_boohoo',\n",
       " 'asos_zhanna',\n",
       " 'boohooMAN',\n",
       " 'boohoo_h',\n",
       " 'JAI_BOOHOO',\n",
       " 'ServiceZalando',\n",
       " 'boohooSam_',\n",
       " 'Carpet_asos',\n",
       " 'boohooUSA',\n",
       " 'kosto_asos',\n",
       " 'Asos_Rocky',\n",
       " 'KaraBoohoo',\n",
       " 'icy_boohoo',\n",
       " 'zalandofi',\n",
       " '____boohoo',\n",
       " 'boohoo_tear',\n",
       " 'karthik_asos',\n",
       " 'agent_asos',\n",
       " 'boohooAus']"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "#collect all the names related to companies as well as bots and scripts\n",
    "names = []\n",
    "pat = r'(zalando|asos|boohoo|MidwestWeather3|Proxy4Sure)'\n",
    "for name in eng_df.name.unique():\n",
    "    match = re.findall(pat, name, re.IGNORECASE) \n",
    "    if len(match) > 0:\n",
    "        names.append(name)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(106575, 14)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100829, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "#check how much data left\n",
    "print(eng_df.shape)\n",
    "eng_df.drop(eng_df[eng_df.name.isin(names)].index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out the dataframe\n",
    "eng_df = eng_df.drop(eng_df[eng_df.name.isin(names)].index)"
   ]
  },
  {
   "source": [
    "# NB: Zalando is not discussed as much as other companies by english speakers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "asos        36694\n",
       "boohoo      24852\n",
       "zalando      2422\n",
       "@zalando      296\n",
       "bohoo         168\n",
       "Name: keyword, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "eng_df.keyword.value_counts()"
   ]
  },
  {
   "source": [
    "# Duplicated tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#check for tweets duplicates\n",
    "eng_df.tweet.value_counts()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 69,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Save up to 20% on ASOS https://t.co/FcTX4ytmzB #fashion                                                                                                                                                                                30\n",
       "@ASOS This account is all about positive vibes when in reality customers are being treated horribly. My parcel got delivered to wrong address and guess what, CS wished me a wonderful day after saying im not being refunded. Scam    28\n",
       "BOOHOO - - new clothes collection https://t.co/cRSIkKE0Ac                                                                                                                                                                              26\n",
       "boohoo cracker                                                                                                                                                                                                                         22\n",
       "BOOHOO MEN - new clothes collection https://t.co/VjNBRtmxRO                                                                                                                                                                            19\n",
       "                                                                                                                                                                                                                                       ..\n",
       "If i had enough money to buy my asos wishlist my wardrobe would be 😘👌🏻                                                                                                                                                                  1\n",
       "@War1sa here https://t.co/ZmcuS5SFoN                                                                                                                                                                                                    1\n",
       "@_lexieclarke1 @mia_sultana https://t.co/IsKppIt7Bm\\n\\nJust follow that link, you just pick a date you want Hermes to collect and they sort it 😊                                                                                        1\n",
       "@pokepupDrake @boohooMAN @boohoo_cshelp Becoming ninja turtle slowly lol 🧡💛                                                                                                                                                             1\n",
       "Ehhh ima make everyone block me tomorrow because i sheduled so.e boohoo im sad tweets...\\nWill most likely do much worse on secret sedpost acc though. Im so retarded                                                                   1\n",
       "Name: tweet, Length: 64432, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering out tweets duplicates\n",
    "eng_df = eng_df.drop_duplicates(subset=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "So good I had to share! Check out all the items I'm loving on @Poshmarkapp #poshmark #fashion #style #shopmycloset #cacique #asos #michaelkors: https://t.co/yPKy31w32Y https://t.co/870u72oi6l                                                                                   1\n",
       "@boohoo So in need of some  #boohootreats before I have to face friends again in real life next week! I think I've survived on tops only for twelve months!!!!! #WhoNeedsTrousersForZoomCalls                                                                                     1\n",
       "@itslordis think that was ASOS                                                                                                                                                                                                                                                    1\n",
       "So good I had to share! Check out all the items I'm loving on @Poshmarkapp from @HeatherHall07 #poshmark #fashion #style #shopmycloset #kutfromthekloth #boohoo: https://t.co/h4OlGDxHXr https://t.co/eAtpD9LVvA                                                                  1\n",
       "@ryanstruyk @morgfair Why wait until 2022?! Kill the filibuster now. Boohoo lindsey                                                                                                                                                                                               1\n",
       "                                                                                                                                                                                                                                                                                 ..\n",
       "Starting the week off with client dev edits ✨and re-writing bits of ASOS 🖤 Sending ink-stained things to @Maria_Tureaud 😈Mori is in full trouble-making mode, too 🐾 but brunch is THE highlight: pork cutlet ramen 🍜 \\n\\nWhat’s your plan for today? 🌿 https://t.co/4YCXI7Esqv    1\n",
       "@ASOS Missed the coaster lmao #MyASOSLuck https://t.co/OAcBYoo3Ro                                                                                                                                                                                                                 1\n",
       "boohoo x city girls 🔥🔥🔥                                                                                                                                                                                                                                                           1\n",
       "@jsguitargeek Yes. A red town at the cusp of the North and South forks of Long Island, NY. I know boohoo. 😉                                                                                                                                                                       1\n",
       "Ehhh ima make everyone block me tomorrow because i sheduled so.e boohoo im sad tweets...\\nWill most likely do much worse on secret sedpost acc though. Im so retarded                                                                                                             1\n",
       "Name: tweet, Length: 64432, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "#check for tweets duplicates\n",
    "eng_df.tweet.value_counts()"
   ]
  },
  {
   "source": [
    "# Functions for cleaning tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_complete(tweet):\n",
    "    \"\"\"\n",
    "    tweet: pandas series\n",
    "    prepares tweets complete cleaning for further lemmatization and dering embeddings\n",
    "    \"\"\"\n",
    "    pat = r\"(\\\\n)|(@\\w*)|((www\\.[^\\s]+)|(https?://[^\\s]+))\"\n",
    "    tweet = tweet.str.replace(pat, '')\n",
    "\n",
    "    #remove repeated charachters\n",
    "    \n",
    "    #replace emoticons with words\n",
    "    #SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "    tweet = tweet.str.replace(r':-\\)', ' smile')\n",
    "    tweet = tweet.str.replace(r':-\\(', ' sad')\n",
    "    tweet = tweet.str.replace(r':-\\/', ' confused')\n",
    "    tweet = tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "    #delete \\xa\n",
    "    tweet = tweet.str.replace('\\xa0', '')\n",
    "\n",
    "    tweet = tweet.str.replace('&amp', '')\n",
    "    tweet = tweet.str.replace('\\n', '')\n",
    "    tweet = tweet.str.replace('\"', '')\n",
    "    #to lower case\n",
    "    tweet = tweet.str.lower()\n",
    "\n",
    "    #covert hashtags to the normal text\n",
    "    tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "\n",
    "    #delete numbers\n",
    "    tweet = [strip_numeric(c) for c in tweet]\n",
    "\n",
    "    #replacing emojies with descriptions '❤️-> red heart'\n",
    "    tweet = [demoji.replace_with_desc(c, ' ') for c in tweet]\n",
    "\n",
    "    #delete punctuation\n",
    "    tweet = [strip_punctuation(c) for c in tweet]\n",
    "\n",
    "    #remove stop words\n",
    "    tweet = [remove_stopwords(c) for c in tweet]\n",
    "\n",
    "    #remove short words\n",
    "    tweet = [strip_short(c) for c in tweet]\n",
    "\n",
    "    #remove mult whitespaces\n",
    "    tweet = [strip_multiple_whitespaces(c) for c in tweet]\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_vader(tweet):\n",
    "    \"\"\"\n",
    "    tweet: pandas series\n",
    "    prepares tweets for vader sentiment analysis\n",
    "    \"\"\"\n",
    "\n",
    "    pat = r\"(\\\\n)|(@\\w*)|((www\\.[^\\s]+)|(https?://[^\\s]+))\"\n",
    "    tweet = tweet.str.replace(pat, '')\n",
    "\n",
    "    #replace emoticons with words\n",
    "    #SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "    #tweet = tweet.str.replace(r':-\\)', ' smile')\n",
    "    #tweet = tweet.str.replace(r':-\\(', ' sad')\n",
    "    #tweet = tweet.str.replace(r':-\\/', ' confused')\n",
    "    #tweet = tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "    #delete \\xa\n",
    "    tweet = tweet.str.replace('\\xa0', '')\n",
    "\n",
    "    tweet = tweet.str.replace('&amp', '')\n",
    "    tweet = tweet.str.replace('\\n', '')\n",
    "\n",
    "    #to lower case\n",
    "    #tweet = tweet.str.lower()\n",
    "\n",
    "    #covert hashtags to the normal text\n",
    "    tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "\n",
    "    #delete numbers\n",
    "    tweet = [strip_numeric(c) for c in tweet]\n",
    "\n",
    "    #replacing emojies with descriptions '❤️-> red heart'\n",
    "    #tweet = [demoji.replace_with_desc(c, ' ') for c in tweet]\n",
    "\n",
    "    #delete punctuation\n",
    "    #tweet = [strip_punctuation(c) for c in tweet]\n",
    "\n",
    "    #remove stop words\n",
    "    #tweet = [remove_stopwords(c) for c in tweet]\n",
    "\n",
    "    #remove short words\n",
    "    tweet = [strip_short(c) for c in tweet]\n",
    "\n",
    "    #remove mult whitespaces\n",
    "    tweet = [strip_multiple_whitespaces(c) for c in tweet]\n",
    "    return tweet\n"
   ]
  },
  {
   "source": [
    "# Applying cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:52: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:59: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:61: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:74: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              user_id  user_statuses             name  \\\n",
       "0      0   819101311715131392             77      Ali09685762   \n",
       "1      1  1189512849472643072            105       Labellerr1   \n",
       "2      2           2837691996            270  puneetjindalisb   \n",
       "3      3  1125728513666048000           9604    DommeLineCoUk   \n",
       "4      4           2614256724          35470         medboyUK   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0            @Zalando give me my money you owe me!!!         0   \n",
       "1  #VirtualStyling and try-on increases the conve...         0   \n",
       "2  #VirtualStyling and try-on increases the conve...         0   \n",
       "3  @missbellalugosi @Zalando Problem starts at Ad...         0   \n",
       "4  @missbellalugosi @Zalando Welcome to my world ...         0   \n",
       "\n",
       "            location      created  followers  is_user_verified  \\\n",
       "0                     07-Mar-2021          6             False   \n",
       "1         chandigarh  06-Mar-2021         18             False   \n",
       "2  Chandigarh, India  06-Mar-2021        149             False   \n",
       "3                     06-Mar-2021       2193             False   \n",
       "4  West Midlands, UK  06-Mar-2021       2503             False   \n",
       "\n",
       "   favorite_count  in_reply_to_status_id   keyword language  \\\n",
       "0             0.0                    NaN  @zalando       en   \n",
       "1             0.0                    NaN  @zalando       en   \n",
       "2             0.0                    NaN  @zalando       en   \n",
       "3             1.0           1.368196e+18  @zalando       en   \n",
       "4             1.0           1.368196e+18  @zalando       en   \n",
       "\n",
       "                                               clean  \n",
       "0                                          money owe  \n",
       "1  virtualstyling try increases conversion rate l...  \n",
       "2  virtualstyling try increases conversion rate l...  \n",
       "3       problem starts adidas selling latex websites  \n",
       "4                     welcome world sneering disdain  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n      <th>clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>819101311715131392</td>\n      <td>77</td>\n      <td>Ali09685762</td>\n      <td>@Zalando give me my money you owe me!!!</td>\n      <td>0</td>\n      <td></td>\n      <td>07-Mar-2021</td>\n      <td>6</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>money owe</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1189512849472643072</td>\n      <td>105</td>\n      <td>Labellerr1</td>\n      <td>#VirtualStyling and try-on increases the conve...</td>\n      <td>0</td>\n      <td>chandigarh</td>\n      <td>06-Mar-2021</td>\n      <td>18</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>virtualstyling try increases conversion rate l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2837691996</td>\n      <td>270</td>\n      <td>puneetjindalisb</td>\n      <td>#VirtualStyling and try-on increases the conve...</td>\n      <td>0</td>\n      <td>Chandigarh, India</td>\n      <td>06-Mar-2021</td>\n      <td>149</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>virtualstyling try increases conversion rate l...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1125728513666048000</td>\n      <td>9604</td>\n      <td>DommeLineCoUk</td>\n      <td>@missbellalugosi @Zalando Problem starts at Ad...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>2193</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368196e+18</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>problem starts adidas selling latex websites</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2614256724</td>\n      <td>35470</td>\n      <td>medboyUK</td>\n      <td>@missbellalugosi @Zalando Welcome to my world ...</td>\n      <td>0</td>\n      <td>West Midlands, UK</td>\n      <td>06-Mar-2021</td>\n      <td>2503</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368196e+18</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>welcome world sneering disdain</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "eng_df['clean'] = clean_complete(eng_df.tweet)\n",
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:102: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              user_id  user_statuses             name  \\\n",
       "0      0   819101311715131392             77      Ali09685762   \n",
       "1      1  1189512849472643072            105       Labellerr1   \n",
       "2      2           2837691996            270  puneetjindalisb   \n",
       "3      3  1125728513666048000           9604    DommeLineCoUk   \n",
       "4      4           2614256724          35470         medboyUK   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0            @Zalando give me my money you owe me!!!         0   \n",
       "1  #VirtualStyling and try-on increases the conve...         0   \n",
       "2  #VirtualStyling and try-on increases the conve...         0   \n",
       "3  @missbellalugosi @Zalando Problem starts at Ad...         0   \n",
       "4  @missbellalugosi @Zalando Welcome to my world ...         0   \n",
       "\n",
       "            location      created  followers  is_user_verified  \\\n",
       "0                     07-Mar-2021          6             False   \n",
       "1         chandigarh  06-Mar-2021         18             False   \n",
       "2  Chandigarh, India  06-Mar-2021        149             False   \n",
       "3                     06-Mar-2021       2193             False   \n",
       "4  West Midlands, UK  06-Mar-2021       2503             False   \n",
       "\n",
       "   favorite_count  in_reply_to_status_id   keyword language  \\\n",
       "0             0.0                    NaN  @zalando       en   \n",
       "1             0.0                    NaN  @zalando       en   \n",
       "2             0.0                    NaN  @zalando       en   \n",
       "3             1.0           1.368196e+18  @zalando       en   \n",
       "4             1.0           1.368196e+18  @zalando       en   \n",
       "\n",
       "                                               clean  \\\n",
       "0                                          money owe   \n",
       "1  virtualstyling try increases conversion rate l...   \n",
       "2  virtualstyling try increases conversion rate l...   \n",
       "3       problem starts adidas selling latex websites   \n",
       "4                     welcome world sneering disdain   \n",
       "\n",
       "                                         clean_vader  \n",
       "0                           give money you owe me!!!  \n",
       "1  VirtualStyling and try-on increases the conver...  \n",
       "2  VirtualStyling and try-on increases the conver...  \n",
       "3  Problem starts Adidas. They're selling latex t...  \n",
       "4                Welcome world sneering and disdain!  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>819101311715131392</td>\n      <td>77</td>\n      <td>Ali09685762</td>\n      <td>@Zalando give me my money you owe me!!!</td>\n      <td>0</td>\n      <td></td>\n      <td>07-Mar-2021</td>\n      <td>6</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>money owe</td>\n      <td>give money you owe me!!!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1189512849472643072</td>\n      <td>105</td>\n      <td>Labellerr1</td>\n      <td>#VirtualStyling and try-on increases the conve...</td>\n      <td>0</td>\n      <td>chandigarh</td>\n      <td>06-Mar-2021</td>\n      <td>18</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>virtualstyling try increases conversion rate l...</td>\n      <td>VirtualStyling and try-on increases the conver...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2837691996</td>\n      <td>270</td>\n      <td>puneetjindalisb</td>\n      <td>#VirtualStyling and try-on increases the conve...</td>\n      <td>0</td>\n      <td>Chandigarh, India</td>\n      <td>06-Mar-2021</td>\n      <td>149</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>virtualstyling try increases conversion rate l...</td>\n      <td>VirtualStyling and try-on increases the conver...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1125728513666048000</td>\n      <td>9604</td>\n      <td>DommeLineCoUk</td>\n      <td>@missbellalugosi @Zalando Problem starts at Ad...</td>\n      <td>0</td>\n      <td></td>\n      <td>06-Mar-2021</td>\n      <td>2193</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368196e+18</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>problem starts adidas selling latex websites</td>\n      <td>Problem starts Adidas. They're selling latex t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2614256724</td>\n      <td>35470</td>\n      <td>medboyUK</td>\n      <td>@missbellalugosi @Zalando Welcome to my world ...</td>\n      <td>0</td>\n      <td>West Midlands, UK</td>\n      <td>06-Mar-2021</td>\n      <td>2503</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368196e+18</td>\n      <td>@zalando</td>\n      <td>en</td>\n      <td>welcome world sneering disdain</td>\n      <td>Welcome world sneering and disdain!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "eng_df['clean_vader'] = clean_vader(eng_df.tweet)\n",
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Absolutely disgraceful that @ASOS @ASOS_HeretoHelp are refusing to help with refund issues on @Topshop orders. Buyers beware! https://t.co/zSz78WnvOp\n",
      "absolutely disgraceful refusing help refund issues orders buyers beware\n",
      "Absolutely disgraceful that are refusing help with refund issues orders. Buyers beware!\n"
     ]
    }
   ],
   "source": [
    "#check the results\n",
    "print(eng_df.tweet[878])\n",
    "print(eng_df.clean[878])\n",
    "print(eng_df.clean_vader[878])"
   ]
  },
  {
   "source": [
    "# get sentiment analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vater sentiment analyzer\n",
    "#The Compound score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1(most extreme negative) and +1 (most extreme positive).\n",
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "eng_df['compound'] = [sid_obj.polarity_scores(c)['compound'] for c in eng_df['clean_vader']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           compound\n",
      "count  64432.000000\n",
      "mean       0.129331\n",
      "std        0.463488\n",
      "min       -0.999900\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.493900\n",
      "max        0.999900\n"
     ]
    }
   ],
   "source": [
    "print(eng_df[['clean_vader', 'compound']].describe())"
   ]
  },
  {
   "source": [
    "# Testing cleaning function \n",
    "shoud not be executed if you want to reproduce the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Hey ! I ordered some products from your web shop. All items had “fast delivery” and are supposed to arrive today. Unfortunately you have not even shipped the parcel to me. This is not the first time that this happens.\\n:-('"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#testing\n",
    "#delete links, users\n",
    "pat = r\"(\\\\n)|(@\\w*)|((https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}))\"\n",
    "eng_df.tweet = eng_df.tweet.str.replace(pat, '')\n",
    "eng_df.tweet[3140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove chars more than twice\n",
    "#str.replace( /(.)\\1{2,}/g, '$1$1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Hey ! I ordered some products from your web shop. All items had “fast delivery” and are supposed to arrive today. Unfortunately you have not even shipped the parcel to me. This is not the first time that this happens.\\n sad'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "\n",
    "#testing\n",
    "# #replace emoticons with words\n",
    "#SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r':-\\)', ' smile')\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r':-\\(', ' sad')\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r':-\\/', ' confused')\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "eng_df.tweet[3140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Who and what has made our greener retailing tracker this week? Step forward,, ,,, ,, ,,,, and '"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#testing#delete \\xa\n",
    "eng_df.tweet = eng_df.tweet.str.replace('\\xa0', '')\n",
    "eng_df.tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Hey ! I ordered some products from your web shop. All items had “fast delivery” and are supposed to arrive today. Unfortunately you have not even shipped the parcel to me. This is not the first time that this happens. sad'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#testing\n",
    "eng_df.tweet = eng_df.tweet.str.replace('&amp', '')\n",
    "eng_df.tweet = eng_df.tweet.str.replace('\\n', '')\n",
    "eng_df.tweet[3140]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hey ! i ordered some products from your web shop. all items had “fast delivery” and are supposed to arrive today. unfortunately you have not even shipped the parcel to me. this is not the first time that this happens. sad'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#testing#to lower case\n",
    "eng_df.tweet = eng_df.tweet.str.lower()\n",
    "eng_df.tweet[3140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hey ! i ordered some products from your web shop. all items had “fast delivery” and are supposed to arrive today. unfortunately you have not even shipped the parcel to me. this is not the first time that this happens. sad'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#testing#covert hashtags to the normal text\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "eng_df.tweet[3140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  zalando thinks im big and/or pregnant and suggests me lovely maternity clothes ❤️❤️❤️❤️❤️❤️❤️ thanks i love it ❤️❤️❤️❤️'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "#testing#delete numbers\n",
    "eng_df.tweet = [strip_numeric(c) for c in eng_df.tweet]\n",
    "eng_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"new  redezign for circularity pilot product is out now! all products of the pilot are equipped with our  a digital tag which saves all product data. once scanned, you are able to discover the product's history through a digital product site  down arrow  recycling symbol  \""
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#testing#replacing emojies with descriptions '❤️-> red heart'\n",
    "eng_df.tweet = [demoji.replace_with_desc(c, ' ') for c in eng_df.tweet]\n",
    "eng_df.tweet[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  zalando thinks im big and or pregnant and suggests me lovely maternity clothes  red heart  red heart  red heart  red heart  red heart  red heart  red heart  thanks i love it  red heart  red heart  red heart  red heart '"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "##testing delete punctuation\n",
    "eng_df.tweet = [strip_punctuation(c) for c in eng_df.tweet]\n",
    "eng_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'zalando thinks im big pregnant suggests lovely maternity clothes red heart red heart red heart red heart red heart red heart red heart thanks love red heart red heart red heart red heart'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#testing\n",
    "eng_df.tweet = [remove_stopwords(c) for c in eng_df.tweet]\n",
    "eng_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'zalando thinks big pregnant suggests lovely maternity clothes red heart red heart red heart red heart red heart red heart red heart thanks love red heart red heart red heart red heart'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "#testin\n",
    "eng_df.tweet = [strip_multiple_whitespaces(c) for c in eng_df.tweet]\n",
    "eng_df.tweet[7]"
   ]
  },
  {
   "source": [
    "# Lemmatization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tweet):\n",
    "    '''\n",
    "    tweet: pandas series\n",
    "    should be applied on the cleaned tweets to transform words to their initial base form.\n",
    "    For example: suggests -> suggest, deliveries -> delivery\n",
    "    '''\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tweet = [nlp(c) for c in tweet]\n",
    "    tweet = [\" \".join([token.lemma_ for token in t]) for t in tweet]\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_df['lem'] = [nlp(c) for c in eng_df.clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "asos stands “as seen screen” exploding head exploding head"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "eng_df.lem[868]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'fyi absolutely useless select puntoposte shipping apparently way know location choose available happen automatically ship refund tell order'"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "eng_df['lemma'] = [\" \".join([token.lemma_ for token in t]) for t in eng_df.lem]\n",
    "eng_df.lemma[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses            name  \\\n",
       "0      383      0  1323291682000000000            133   GreenerRetail   \n",
       "1      384      1  1259761930000000000              1    fattybabycat   \n",
       "2      385      2   835467350200000128           2296   piotrkarwatka   \n",
       "3      386      3             58485935            114  MissyDawn27586   \n",
       "4      387      4  1059339104000000000          11725    CarolCooney7   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Who and what has made our greener retailing tr...         0   \n",
       "1  .@Zalando offers nothing more than scripted, c...         0   \n",
       "2  We've got a great talk with Fabian Wesner on h...         0   \n",
       "3  @Zalando recieved wrong item... don’t know how...         0   \n",
       "4  @DrewLawDesign @Zalando  have sent me a few de...         0   \n",
       "\n",
       "          location      created  followers  is_user_verified language  \\\n",
       "0     Planet Earth  05-Mar-2021         70             False       en   \n",
       "1                   05-Mar-2021          0             False       en   \n",
       "2  Wrocław, Polska  05-Mar-2021       1347             False       en   \n",
       "3                   05-Mar-2021         27             False       en   \n",
       "4                   05-Mar-2021        457             False       en   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \\\n",
       "0  @zalando             NaN                    NaN   \n",
       "1  @zalando             NaN                    NaN   \n",
       "2  @zalando             NaN                    NaN   \n",
       "3  @zalando             NaN                    NaN   \n",
       "4  @zalando             NaN                    NaN   \n",
       "\n",
       "                                               clean  \\\n",
       "0  greener retailing tracker week step forward an...   \n",
       "1  offers scripted cordial replies instead actual...   \n",
       "2  got great talk fabian wesner new venture roq t...   \n",
       "3  recieved wrong item don’t know item cheaper it...   \n",
       "4                         sent deliveries paper bags   \n",
       "\n",
       "                                         clean_vader  compound  \\\n",
       "0  Who and what has made our greener retailing tr...    0.0000   \n",
       "1  offers nothing more than scripted, cordial rep...   -0.9060   \n",
       "2  We've got great talk with Fabian Wesner his ne...    0.6249   \n",
       "3  recieved wrong item... don’t know how about th...   -0.4767   \n",
       "4           have sent few deliveries paper bags now.    0.0000   \n",
       "\n",
       "                                                 lem  \\\n",
       "0  (greener, retailing, tracker, week, step, forw...   \n",
       "1  (offers, scripted, cordial, replies, instead, ...   \n",
       "2  (got, great, talk, fabian, wesner, new, ventur...   \n",
       "3  (recieved, wrong, item, do, n’t, know, item, c...   \n",
       "4                    (sent, deliveries, paper, bags)   \n",
       "\n",
       "                                               lemma  \n",
       "0  greener retailing tracker week step forward an...  \n",
       "1  offer script cordial reply instead actual cust...  \n",
       "2  get great talk fabian wesner new venture roq t...  \n",
       "3  recieve wrong item do n’t know item cheap item...  \n",
       "4                            send delivery paper bag  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n      <th>compound</th>\n      <th>lem</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>383</td>\n      <td>0</td>\n      <td>1323291682000000000</td>\n      <td>133</td>\n      <td>GreenerRetail</td>\n      <td>Who and what has made our greener retailing tr...</td>\n      <td>0</td>\n      <td>Planet Earth</td>\n      <td>05-Mar-2021</td>\n      <td>70</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>greener retailing tracker week step forward an...</td>\n      <td>Who and what has made our greener retailing tr...</td>\n      <td>0.0000</td>\n      <td>(greener, retailing, tracker, week, step, forw...</td>\n      <td>greener retailing tracker week step forward an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>384</td>\n      <td>1</td>\n      <td>1259761930000000000</td>\n      <td>1</td>\n      <td>fattybabycat</td>\n      <td>.@Zalando offers nothing more than scripted, c...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>offers scripted cordial replies instead actual...</td>\n      <td>offers nothing more than scripted, cordial rep...</td>\n      <td>-0.9060</td>\n      <td>(offers, scripted, cordial, replies, instead, ...</td>\n      <td>offer script cordial reply instead actual cust...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>385</td>\n      <td>2</td>\n      <td>835467350200000128</td>\n      <td>2296</td>\n      <td>piotrkarwatka</td>\n      <td>We've got a great talk with Fabian Wesner on h...</td>\n      <td>0</td>\n      <td>Wrocław, Polska</td>\n      <td>05-Mar-2021</td>\n      <td>1347</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>got great talk fabian wesner new venture roq t...</td>\n      <td>We've got great talk with Fabian Wesner his ne...</td>\n      <td>0.6249</td>\n      <td>(got, great, talk, fabian, wesner, new, ventur...</td>\n      <td>get great talk fabian wesner new venture roq t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>386</td>\n      <td>3</td>\n      <td>58485935</td>\n      <td>114</td>\n      <td>MissyDawn27586</td>\n      <td>@Zalando recieved wrong item... don’t know how...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>27</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>recieved wrong item don’t know item cheaper it...</td>\n      <td>recieved wrong item... don’t know how about th...</td>\n      <td>-0.4767</td>\n      <td>(recieved, wrong, item, do, n’t, know, item, c...</td>\n      <td>recieve wrong item do n’t know item cheap item...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>387</td>\n      <td>4</td>\n      <td>1059339104000000000</td>\n      <td>11725</td>\n      <td>CarolCooney7</td>\n      <td>@DrewLawDesign @Zalando  have sent me a few de...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>457</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>sent deliveries paper bags</td>\n      <td>have sent few deliveries paper bags now.</td>\n      <td>0.0000</td>\n      <td>(sent, deliveries, paper, bags)</td>\n      <td>send delivery paper bag</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "eng_df.head()"
   ]
  },
  {
   "source": [
    "# Data description\n",
    "- tweet: initial tweet as it was downloaded from API\n",
    "- clean: tweet cleaned completely from punctuation, emojies, emoticons, stopwords, special characters, users, hashtags, links\n",
    "- clean_vader: tweet partly cleaned, saving punctuation, emoticons, emojies for using library Vader to get the sentiment of the tweet\n",
    "- compouns: from -1 (negative) to 1 (positive), 0 - neutral, a tweet sentiment derived from Vader library\n",
    "- lem: intermidiate step before lemmatization\n",
    "- lemma: lemmatized words (sent -> send)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Save the dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(eng_df, open(r'.\\data_n_models\\eng_df_labelled.pkl', 'wb'))"
   ]
  }
 ]
}