{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd022a63b945ad88ad6aa60a7f3f570c70abf6faa8a03284077614716ef20649993",
   "display_name": "Python 3.7.10 64-bit ('uni': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_tags, strip_numeric, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short, stem_text\n",
    "import pickle\n",
    "import en_core_web_sm\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading emoji data ...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "... OK (Got response in 0.47 seconds)\n",
      "Writing emoji data to C:\\Users\\home\\.demoji\\codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import functions\n",
    "exec(open('./functions.py').read())\n",
    "\n",
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses            name  \\\n",
       "0      383      0  1323291682000000000            133   GreenerRetail   \n",
       "1      384      1  1259761930000000000              1    fattybabycat   \n",
       "2      385      2   835467350200000128           2296   piotrkarwatka   \n",
       "3      386      3             58485935            114  MissyDawn27586   \n",
       "4      387      4  1059339104000000000          11725    CarolCooney7   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Who and what has made our greener retailing tr...         0   \n",
       "1  .@Zalando offers nothing more than scripted, c...         0   \n",
       "2  We've got a great talk with Fabian Wesner on h...         0   \n",
       "3  @Zalando recieved wrong item... don’t know how...         0   \n",
       "4  @DrewLawDesign @Zalando  have sent me a few de...         0   \n",
       "\n",
       "          location      created  followers  is_user_verified language  \\\n",
       "0     Planet Earth  05-Mar-2021         70             False       en   \n",
       "1                   05-Mar-2021          0             False       en   \n",
       "2  Wrocław, Polska  05-Mar-2021       1347             False       en   \n",
       "3                   05-Mar-2021         27             False       en   \n",
       "4                   05-Mar-2021        457             False       en   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \n",
       "0  @zalando             NaN                    NaN  \n",
       "1  @zalando             NaN                    NaN  \n",
       "2  @zalando             NaN                    NaN  \n",
       "3  @zalando             NaN                    NaN  \n",
       "4  @zalando             NaN                    NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>383</td>\n      <td>0</td>\n      <td>1323291682000000000</td>\n      <td>133</td>\n      <td>GreenerRetail</td>\n      <td>Who and what has made our greener retailing tr...</td>\n      <td>0</td>\n      <td>Planet Earth</td>\n      <td>05-Mar-2021</td>\n      <td>70</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>384</td>\n      <td>1</td>\n      <td>1259761930000000000</td>\n      <td>1</td>\n      <td>fattybabycat</td>\n      <td>.@Zalando offers nothing more than scripted, c...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>385</td>\n      <td>2</td>\n      <td>835467350200000128</td>\n      <td>2296</td>\n      <td>piotrkarwatka</td>\n      <td>We've got a great talk with Fabian Wesner on h...</td>\n      <td>0</td>\n      <td>Wrocław, Polska</td>\n      <td>05-Mar-2021</td>\n      <td>1347</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>386</td>\n      <td>3</td>\n      <td>58485935</td>\n      <td>114</td>\n      <td>MissyDawn27586</td>\n      <td>@Zalando recieved wrong item... don’t know how...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>27</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>387</td>\n      <td>4</td>\n      <td>1059339104000000000</td>\n      <td>11725</td>\n      <td>CarolCooney7</td>\n      <td>@DrewLawDesign @Zalando  have sent me a few de...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>457</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "df = pd.read_json('one_cleaned_df.json')\n",
    "eng_df = df[df.language == 'en'].reset_index()\n",
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "frozenset({'really', 'mine', 'hereby', 'didn', 'everything', 'in', 'on', 'down', 'does', 'however', 'none', 'otherwise', 'full', 'done', 'much', 'show', 'fifteen', 'whoever', 'few', 'very', 'almost', 'thence', 'amongst', 'of', 'still', 'seeming', 'neither', 'could', 'why', 'something', 'thus', 'make', 'say', 'thru', 'when', 'three', 'meanwhile', 'until', 'himself', 'please', 'nobody', 'someone', 'myself', 'give', 'bottom', 'eight', 'every', 'both', 'anyone', 'namely', 'no', 'keep', 'or', 'who', 'these', 'a', 'the', 'don', 'may', 'doing', 'without', 'might', 'front', 'are', 'you', 'elsewhere', 'becoming', 'must', 'there', 'regarding', 'empty', 'take', 'sixty', 'we', 'own', 'seemed', 'below', 'else', 'becomes', 'together', 'whether', 'by', 'among', 'whence', 'whereby', 'con', 'found', 'as', 'such', 'will', 'around', 'indeed', 'here', 'less', 'somewhere', 'its', 'out', 'thin', 'our', 'rather', 'moreover', 'is', 'they', 'side', 'beforehand', 'up', 'being', 'after', 'sometime', 'hereupon', 'where', 'system', 'thereupon', 'toward', 'with', 'it', 'anything', 'since', 'whereas', 'many', 'across', 'wherever', 'his', 'whereafter', 'least', 'nine', 'seem', 'four', 'former', 'your', 'therein', 'either', 'he', 'because', 'anyway', 'throughout', 'twelve', 'would', 'besides', 'already', 'others', 'nowhere', 'she', 'once', 'first', 'sincere', 'doesn', 'now', 'again', 'eleven', 'third', 'get', 'beyond', 'go', 'be', 'yet', 'using', 'whole', 'then', 'more', 'from', 'can', 'even', 'onto', 'top', 'most', 'this', 'her', 'against', 'due', 'which', 'hers', 'fill', 'has', 'sometimes', 'enough', 'fire', 'call', 'their', 'between', 'anyhow', 'detail', 'interest', 'whose', 'de', 'that', 'have', 'six', 'several', 'beside', 'move', 'wherein', 'cannot', 'co', 'km', 'only', 'back', 'i', 'etc', 'thereby', 'towards', 'to', 'cry', 'during', 'were', 'any', 'had', 'computer', 'how', 'do', 'above', 'whereupon', 'thick', 'ours', 'upon', 'name', 'un', 'made', 'hereafter', 'inc', 'for', 'also', 'find', 'did', 'put', 'ever', 'anywhere', 'been', 'except', 'often', 'over', 'us', 'so', 'nor', 'further', 'formerly', 'per', 'somehow', 'see', 'noone', 'other', 'through', 'about', 'alone', 'at', 'itself', 'just', 'nothing', 'yourself', 'quite', 'herein', 'unless', 'eg', 'whom', 'became', 'if', 'herself', 'not', 'should', 'ltd', 'whenever', 'become', 'an', 'next', 'whither', 'along', 'twenty', 'well', 'everywhere', 'two', 'too', 'am', 'ie', 'off', 'than', 'bill', 'mostly', 'via', 'hundred', 'seems', 'latter', 'used', 'mill', 'therefore', 'yourselves', 'describe', 'serious', 'ten', 'although', 'them', 're', 'various', 'and', 'me', 'what', 'forty', 'never', 'nevertheless', 'all', 'each', 'five', 'afterwards', 'within', 'themselves', 'last', 'before', 'was', 'behind', 'fifty', 'hasnt', 'latterly', 'ourselves', 'perhaps', 'though', 'thereafter', 'my', 'whatever', 'amount', 'part', 'yours', 'while', 'him', 'amoungst', 'those', 'another', 'everyone', 'one', 'some', 'same', 'into', 'couldnt', 'cant', 'kg', 'hence', 'under', 'always', 'but'})\n"
     ]
    }
   ],
   "source": [
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_complete(tweet):\n",
    "    \"\"\"\n",
    "    tweet: pandas series\n",
    "    prepares tweets complete cleaning for further lemmatization and dering embeddings\n",
    "    \"\"\"\n",
    "    pat = r\"(\\\\n)|(@\\w*)|((www\\.[^\\s]+)|(https?://[^\\s]+))\"\n",
    "    tweet = tweet.str.replace(pat, '')\n",
    "\n",
    "    #remove repeated charachters\n",
    "    \n",
    "    #replace emoticons with words\n",
    "    #SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "    tweet = tweet.str.replace(r':-\\)', ' smile')\n",
    "    tweet = tweet.str.replace(r':-\\(', ' sad')\n",
    "    tweet = tweet.str.replace(r':-\\/', ' confused')\n",
    "    tweet = tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "    #delete \\xa\n",
    "    tweet = tweet.str.replace('\\xa0', '')\n",
    "\n",
    "    tweet = tweet.str.replace('&amp', '')\n",
    "    tweet = tweet.str.replace('\\n', '')\n",
    "    tweet = tweet.str.replace('\"', '')\n",
    "    #to lower case\n",
    "    tweet = tweet.str.lower()\n",
    "\n",
    "    #covert hashtags to the normal text\n",
    "    tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "\n",
    "    #delete numbers\n",
    "    tweet = [strip_numeric(c) for c in tweet]\n",
    "\n",
    "    #replacing emojies with descriptions '❤️-> red heart'\n",
    "    tweet = [demoji.replace_with_desc(c, ' ') for c in tweet]\n",
    "\n",
    "    #delete punctuation\n",
    "    tweet = [strip_punctuation(c) for c in tweet]\n",
    "\n",
    "    #remove stop words\n",
    "    tweet = [remove_stopwords(c) for c in tweet]\n",
    "\n",
    "    #remove short words\n",
    "    tweet = [strip_short(c) for c in tweet]\n",
    "\n",
    "    #remove mult whitespaces\n",
    "    tweet = [strip_multiple_whitespaces(c) for c in tweet]\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_vader(tweet):\n",
    "    \"\"\"\n",
    "    tweet: pandas series\n",
    "    prepares tweets for vader sentiment analysis\n",
    "    \"\"\"\n",
    "\n",
    "    pat = r\"(\\\\n)|(@\\w*)|((www\\.[^\\s]+)|(https?://[^\\s]+))\"\n",
    "    tweet = tweet.str.replace(pat, '')\n",
    "\n",
    "    #replace emoticons with words\n",
    "    #SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "    #tweet = tweet.str.replace(r':-\\)', ' smile')\n",
    "    #tweet = tweet.str.replace(r':-\\(', ' sad')\n",
    "    #tweet = tweet.str.replace(r':-\\/', ' confused')\n",
    "    #tweet = tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "    #delete \\xa\n",
    "    tweet = tweet.str.replace('\\xa0', '')\n",
    "\n",
    "    tweet = tweet.str.replace('&amp', '')\n",
    "    tweet = tweet.str.replace('\\n', '')\n",
    "\n",
    "    #to lower case\n",
    "    #tweet = tweet.str.lower()\n",
    "\n",
    "    #covert hashtags to the normal text\n",
    "    tweet = tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "\n",
    "    #delete numbers\n",
    "    tweet = [strip_numeric(c) for c in tweet]\n",
    "\n",
    "    #replacing emojies with descriptions '❤️-> red heart'\n",
    "    #tweet = [demoji.replace_with_desc(c, ' ') for c in tweet]\n",
    "\n",
    "    #delete punctuation\n",
    "    #tweet = [strip_punctuation(c) for c in tweet]\n",
    "\n",
    "    #remove stop words\n",
    "    #tweet = [remove_stopwords(c) for c in tweet]\n",
    "\n",
    "    #remove short words\n",
    "    tweet = [strip_short(c) for c in tweet]\n",
    "\n",
    "    #remove mult whitespaces\n",
    "    tweet = [strip_multiple_whitespaces(c) for c in tweet]\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses            name  \\\n",
       "0      383      0  1323291682000000000            133   GreenerRetail   \n",
       "1      384      1  1259761930000000000              1    fattybabycat   \n",
       "2      385      2   835467350200000128           2296   piotrkarwatka   \n",
       "3      386      3             58485935            114  MissyDawn27586   \n",
       "4      387      4  1059339104000000000          11725    CarolCooney7   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Who and what has made our greener retailing tr...         0   \n",
       "1  .@Zalando offers nothing more than scripted, c...         0   \n",
       "2  We've got a great talk with Fabian Wesner on h...         0   \n",
       "3  @Zalando recieved wrong item... don’t know how...         0   \n",
       "4  @DrewLawDesign @Zalando  have sent me a few de...         0   \n",
       "\n",
       "          location      created  followers  is_user_verified language  \\\n",
       "0     Planet Earth  05-Mar-2021         70             False       en   \n",
       "1                   05-Mar-2021          0             False       en   \n",
       "2  Wrocław, Polska  05-Mar-2021       1347             False       en   \n",
       "3                   05-Mar-2021         27             False       en   \n",
       "4                   05-Mar-2021        457             False       en   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \\\n",
       "0  @zalando             NaN                    NaN   \n",
       "1  @zalando             NaN                    NaN   \n",
       "2  @zalando             NaN                    NaN   \n",
       "3  @zalando             NaN                    NaN   \n",
       "4  @zalando             NaN                    NaN   \n",
       "\n",
       "                                               clean  \\\n",
       "0        greener retailing tracker week step forward   \n",
       "1  offers scripted cordial replies instead actual...   \n",
       "2  got great talk fabian wesner new venture roq t...   \n",
       "3  recieved wrong item don’t know item cheaper it...   \n",
       "4                         sent deliveries paper bags   \n",
       "\n",
       "                                         clean_vader  compound  \\\n",
       "0  Who and what has made our greener retailing tr...    0.0000   \n",
       "1  offers nothing more than scripted, cordial rep...   -0.9060   \n",
       "2  We've got great talk with Fabian Wesner his ne...    0.6249   \n",
       "3  recieved wrong item... don’t know how about th...   -0.4767   \n",
       "4           have sent few deliveries paper bags now.    0.0000   \n",
       "\n",
       "                                                 lem  \\\n",
       "0  (greener, retailing, tracker, week, step, forw...   \n",
       "1  (offers, scripted, cordial, replies, instead, ...   \n",
       "2  (got, great, talk, fabian, wesner, new, ventur...   \n",
       "3  (recieved, wrong, item, do, n’t, know, item, c...   \n",
       "4                    (sent, deliveries, paper, bags)   \n",
       "\n",
       "                                               lemma  \n",
       "0  greener retailing tracker week step forward an...  \n",
       "1  offer script cordial reply instead actual cust...  \n",
       "2  get great talk fabian wesner new venture roq t...  \n",
       "3  recieve wrong item do n’t know item cheap item...  \n",
       "4                            send delivery paper bag  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n      <th>compound</th>\n      <th>lem</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>383</td>\n      <td>0</td>\n      <td>1323291682000000000</td>\n      <td>133</td>\n      <td>GreenerRetail</td>\n      <td>Who and what has made our greener retailing tr...</td>\n      <td>0</td>\n      <td>Planet Earth</td>\n      <td>05-Mar-2021</td>\n      <td>70</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>greener retailing tracker week step forward</td>\n      <td>Who and what has made our greener retailing tr...</td>\n      <td>0.0000</td>\n      <td>(greener, retailing, tracker, week, step, forw...</td>\n      <td>greener retailing tracker week step forward an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>384</td>\n      <td>1</td>\n      <td>1259761930000000000</td>\n      <td>1</td>\n      <td>fattybabycat</td>\n      <td>.@Zalando offers nothing more than scripted, c...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>offers scripted cordial replies instead actual...</td>\n      <td>offers nothing more than scripted, cordial rep...</td>\n      <td>-0.9060</td>\n      <td>(offers, scripted, cordial, replies, instead, ...</td>\n      <td>offer script cordial reply instead actual cust...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>385</td>\n      <td>2</td>\n      <td>835467350200000128</td>\n      <td>2296</td>\n      <td>piotrkarwatka</td>\n      <td>We've got a great talk with Fabian Wesner on h...</td>\n      <td>0</td>\n      <td>Wrocław, Polska</td>\n      <td>05-Mar-2021</td>\n      <td>1347</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>got great talk fabian wesner new venture roq t...</td>\n      <td>We've got great talk with Fabian Wesner his ne...</td>\n      <td>0.6249</td>\n      <td>(got, great, talk, fabian, wesner, new, ventur...</td>\n      <td>get great talk fabian wesner new venture roq t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>386</td>\n      <td>3</td>\n      <td>58485935</td>\n      <td>114</td>\n      <td>MissyDawn27586</td>\n      <td>@Zalando recieved wrong item... don’t know how...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>27</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>recieved wrong item don’t know item cheaper it...</td>\n      <td>recieved wrong item... don’t know how about th...</td>\n      <td>-0.4767</td>\n      <td>(recieved, wrong, item, do, n’t, know, item, c...</td>\n      <td>recieve wrong item do n’t know item cheap item...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>387</td>\n      <td>4</td>\n      <td>1059339104000000000</td>\n      <td>11725</td>\n      <td>CarolCooney7</td>\n      <td>@DrewLawDesign @Zalando  have sent me a few de...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>457</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>sent deliveries paper bags</td>\n      <td>have sent few deliveries paper bags now.</td>\n      <td>0.0000</td>\n      <td>(sent, deliveries, paper, bags)</td>\n      <td>send delivery paper bag</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "eng_df['clean'] = clean_complete(eng_df.tweet)\n",
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses            name  \\\n",
       "0      383      0  1323291682000000000            133   GreenerRetail   \n",
       "1      384      1  1259761930000000000              1    fattybabycat   \n",
       "2      385      2   835467350200000128           2296   piotrkarwatka   \n",
       "3      386      3             58485935            114  MissyDawn27586   \n",
       "4      387      4  1059339104000000000          11725    CarolCooney7   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Who and what has made our greener retailing tr...         0   \n",
       "1  .@Zalando offers nothing more than scripted, c...         0   \n",
       "2  We've got a great talk with Fabian Wesner on h...         0   \n",
       "3  @Zalando recieved wrong item... don’t know how...         0   \n",
       "4  @DrewLawDesign @Zalando  have sent me a few de...         0   \n",
       "\n",
       "          location      created  followers  is_user_verified language  \\\n",
       "0     Planet Earth  05-Mar-2021         70             False       en   \n",
       "1                   05-Mar-2021          0             False       en   \n",
       "2  Wrocław, Polska  05-Mar-2021       1347             False       en   \n",
       "3                   05-Mar-2021         27             False       en   \n",
       "4                   05-Mar-2021        457             False       en   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \\\n",
       "0  @zalando             NaN                    NaN   \n",
       "1  @zalando             NaN                    NaN   \n",
       "2  @zalando             NaN                    NaN   \n",
       "3  @zalando             NaN                    NaN   \n",
       "4  @zalando             NaN                    NaN   \n",
       "\n",
       "                                               clean  \\\n",
       "0  greener retailing tracker week step forward an...   \n",
       "1  offers scripted cordial replies instead actual...   \n",
       "2  got great talk fabian wesner new venture roq t...   \n",
       "3  recieved wrong item don’t know item cheaper it...   \n",
       "4                         sent deliveries paper bags   \n",
       "\n",
       "                                         clean_vader  \n",
       "0  Who and what has made our greener retailing tr...  \n",
       "1  offers nothing more than scripted, cordial rep...  \n",
       "2  We've got great talk with Fabian Wesner his ne...  \n",
       "3  recieved wrong item... don’t know how about th...  \n",
       "4           have sent few deliveries paper bags now.  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>383</td>\n      <td>0</td>\n      <td>1323291682000000000</td>\n      <td>133</td>\n      <td>GreenerRetail</td>\n      <td>Who and what has made our greener retailing tr...</td>\n      <td>0</td>\n      <td>Planet Earth</td>\n      <td>05-Mar-2021</td>\n      <td>70</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>greener retailing tracker week step forward an...</td>\n      <td>Who and what has made our greener retailing tr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>384</td>\n      <td>1</td>\n      <td>1259761930000000000</td>\n      <td>1</td>\n      <td>fattybabycat</td>\n      <td>.@Zalando offers nothing more than scripted, c...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>offers scripted cordial replies instead actual...</td>\n      <td>offers nothing more than scripted, cordial rep...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>385</td>\n      <td>2</td>\n      <td>835467350200000128</td>\n      <td>2296</td>\n      <td>piotrkarwatka</td>\n      <td>We've got a great talk with Fabian Wesner on h...</td>\n      <td>0</td>\n      <td>Wrocław, Polska</td>\n      <td>05-Mar-2021</td>\n      <td>1347</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>got great talk fabian wesner new venture roq t...</td>\n      <td>We've got great talk with Fabian Wesner his ne...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>386</td>\n      <td>3</td>\n      <td>58485935</td>\n      <td>114</td>\n      <td>MissyDawn27586</td>\n      <td>@Zalando recieved wrong item... don’t know how...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>27</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>recieved wrong item don’t know item cheaper it...</td>\n      <td>recieved wrong item... don’t know how about th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>387</td>\n      <td>4</td>\n      <td>1059339104000000000</td>\n      <td>11725</td>\n      <td>CarolCooney7</td>\n      <td>@DrewLawDesign @Zalando  have sent me a few de...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>457</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>sent deliveries paper bags</td>\n      <td>have sent few deliveries paper bags now.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "eng_df['clean_vader'] = clean_vader(eng_df.tweet)\n",
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "@ASOS I’ll be going back to work soon from maternity leave and am in desperate need of a new work wardrobe! #ASOSTreatMe https://t.co/uitdGUZNwJ\n",
      "i’ll going work soon maternity leave desperate need new work wardrobe asostreatme\n",
      "I’ll going back work soon from maternity leave and desperate need new work wardrobe! ASOSTreatMe\n"
     ]
    }
   ],
   "source": [
    "print(eng_df.tweet[878])\n",
    "print(eng_df.clean[878])\n",
    "print(eng_df.clean_vader[878])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vater sentiment analyzer\n",
    "#The Compound score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1(most extreme negative) and +1 (most extreme positive).\n",
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "eng_df['compound'] = [sid_obj.polarity_scores(c)['compound'] for c in eng_df['clean_vader']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            compound\n",
      "count  109987.000000\n",
      "mean        0.133001\n",
      "std         0.450338\n",
      "min        -0.999900\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.493900\n",
      "max         0.999900\n"
     ]
    }
   ],
   "source": [
    "print(eng_df[['clean_vader', 'compound']].describe())"
   ]
  },
  {
   "source": [
    "# Testing cleaning function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Hey ! I ordered some products from your web shop. All items had “fast delivery” and are supposed to arrive today. Unfortunately you have not even shipped the parcel to me. This is not the first time that this happens.\\n:-('"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#testing\n",
    "#delete links, users\n",
    "pat = r\"(\\\\n)|(@\\w*)|((https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}))\"\n",
    "eng_df.tweet = eng_df.tweet.str.replace(pat, '')\n",
    "eng_df.tweet[3140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove chars more than twice\n",
    "#str.replace( /(.)\\1{2,}/g, '$1$1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n",
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Hey ! I ordered some products from your web shop. All items had “fast delivery” and are supposed to arrive today. Unfortunately you have not even shipped the parcel to me. This is not the first time that this happens.\\n sad'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "\n",
    "#testing\n",
    "# #replace emoticons with words\n",
    "#SMILEYS = {\":-(\":\"sad\", \":‑)\":\"smiley\", \":-P\":\"playfullness\", \":-/\":'confused'}\n",
    "\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r':-\\)', ' smile')\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r':-\\(', ' sad')\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r':-\\/', ' confused')\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r':-P', ' playfullness')\n",
    "\n",
    "eng_df.tweet[3140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Who and what has made our greener retailing tracker this week? Step forward,, ,,, ,, ,,,, and '"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#testing#delete \\xa\n",
    "eng_df.tweet = eng_df.tweet.str.replace('\\xa0', '')\n",
    "eng_df.tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Hey ! I ordered some products from your web shop. All items had “fast delivery” and are supposed to arrive today. Unfortunately you have not even shipped the parcel to me. This is not the first time that this happens. sad'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#testing\n",
    "eng_df.tweet = eng_df.tweet.str.replace('&amp', '')\n",
    "eng_df.tweet = eng_df.tweet.str.replace('\\n', '')\n",
    "eng_df.tweet[3140]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hey ! i ordered some products from your web shop. all items had “fast delivery” and are supposed to arrive today. unfortunately you have not even shipped the parcel to me. this is not the first time that this happens. sad'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#testing#to lower case\n",
    "eng_df.tweet = eng_df.tweet.str.lower()\n",
    "eng_df.tweet[3140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Anaconda\\envs\\uni\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hey ! i ordered some products from your web shop. all items had “fast delivery” and are supposed to arrive today. unfortunately you have not even shipped the parcel to me. this is not the first time that this happens. sad'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#testing#covert hashtags to the normal text\n",
    "eng_df.tweet = eng_df.tweet.str.replace(r'#([^\\s]+)', r'\\1')\n",
    "eng_df.tweet[3140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  zalando thinks im big and/or pregnant and suggests me lovely maternity clothes ❤️❤️❤️❤️❤️❤️❤️ thanks i love it ❤️❤️❤️❤️'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "#testing#delete numbers\n",
    "eng_df.tweet = [strip_numeric(c) for c in eng_df.tweet]\n",
    "eng_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"new  redezign for circularity pilot product is out now! all products of the pilot are equipped with our  a digital tag which saves all product data. once scanned, you are able to discover the product's history through a digital product site  down arrow  recycling symbol  \""
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#testing#replacing emojies with descriptions '❤️-> red heart'\n",
    "eng_df.tweet = [demoji.replace_with_desc(c, ' ') for c in eng_df.tweet]\n",
    "eng_df.tweet[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'  zalando thinks im big and or pregnant and suggests me lovely maternity clothes  red heart  red heart  red heart  red heart  red heart  red heart  red heart  thanks i love it  red heart  red heart  red heart  red heart '"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "##testing delete punctuation\n",
    "eng_df.tweet = [strip_punctuation(c) for c in eng_df.tweet]\n",
    "eng_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'zalando thinks im big pregnant suggests lovely maternity clothes red heart red heart red heart red heart red heart red heart red heart thanks love red heart red heart red heart red heart'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#testing\n",
    "eng_df.tweet = [remove_stopwords(c) for c in eng_df.tweet]\n",
    "eng_df.tweet[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'zalando thinks big pregnant suggests lovely maternity clothes red heart red heart red heart red heart red heart red heart red heart thanks love red heart red heart red heart red heart'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "#testin\n",
    "eng_df.tweet = [strip_multiple_whitespaces(c) for c in eng_df.tweet]\n",
    "eng_df.tweet[7]"
   ]
  },
  {
   "source": [
    "# Lemmatization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tweet):\n",
    "    '''\n",
    "    tweet: pandas series\n",
    "    should be applied on the cleaned tweets to transform words to their initial base form.\n",
    "    For example: suggests -> suggest, deliveries -> delivery\n",
    "    '''\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tweet = [nlp(c) for c in tweet]\n",
    "    tweet = [\" \".join([token.lemma_ for token in t]) for t in tweet]\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_df['lem'] = [nlp(c) for c in eng_df.clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "asos stands “as seen screen” exploding head exploding head"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "eng_df.lem[868]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'zalando think big pregnant suggest lovely maternity clothe red heart red heart red heart red heart red heart red heart red heart thank love red heart red heart red heart red heart'"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "eng_df['lemma'] = [\" \".join([token.lemma_ for token in t]) for t in eng_df.lem]\n",
    "eng_df.lemma[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0  index              user_id  user_statuses            name  \\\n",
       "0      383      0  1323291682000000000            133   GreenerRetail   \n",
       "1      384      1  1259761930000000000              1    fattybabycat   \n",
       "2      385      2   835467350200000128           2296   piotrkarwatka   \n",
       "3      386      3             58485935            114  MissyDawn27586   \n",
       "4      387      4  1059339104000000000          11725    CarolCooney7   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  Who and what has made our greener retailing tr...         0   \n",
       "1  .@Zalando offers nothing more than scripted, c...         0   \n",
       "2  We've got a great talk with Fabian Wesner on h...         0   \n",
       "3  @Zalando recieved wrong item... don’t know how...         0   \n",
       "4  @DrewLawDesign @Zalando  have sent me a few de...         0   \n",
       "\n",
       "          location      created  followers  is_user_verified language  \\\n",
       "0     Planet Earth  05-Mar-2021         70             False       en   \n",
       "1                   05-Mar-2021          0             False       en   \n",
       "2  Wrocław, Polska  05-Mar-2021       1347             False       en   \n",
       "3                   05-Mar-2021         27             False       en   \n",
       "4                   05-Mar-2021        457             False       en   \n",
       "\n",
       "    keyword  favorite_count  in_reply_to_status_id  \\\n",
       "0  @zalando             NaN                    NaN   \n",
       "1  @zalando             NaN                    NaN   \n",
       "2  @zalando             NaN                    NaN   \n",
       "3  @zalando             NaN                    NaN   \n",
       "4  @zalando             NaN                    NaN   \n",
       "\n",
       "                                               clean  \\\n",
       "0  greener retailing tracker week step forward an...   \n",
       "1  offers scripted cordial replies instead actual...   \n",
       "2  got great talk fabian wesner new venture roq t...   \n",
       "3  recieved wrong item don’t know item cheaper it...   \n",
       "4                         sent deliveries paper bags   \n",
       "\n",
       "                                         clean_vader  compound  \\\n",
       "0  Who and what has made our greener retailing tr...    0.0000   \n",
       "1  offers nothing more than scripted, cordial rep...   -0.9060   \n",
       "2  We've got great talk with Fabian Wesner his ne...    0.6249   \n",
       "3  recieved wrong item... don’t know how about th...   -0.4767   \n",
       "4           have sent few deliveries paper bags now.    0.0000   \n",
       "\n",
       "                                                 lem  \\\n",
       "0  (greener, retailing, tracker, week, step, forw...   \n",
       "1  (offers, scripted, cordial, replies, instead, ...   \n",
       "2  (got, great, talk, fabian, wesner, new, ventur...   \n",
       "3  (recieved, wrong, item, do, n’t, know, item, c...   \n",
       "4                    (sent, deliveries, paper, bags)   \n",
       "\n",
       "                                               lemma  \n",
       "0  greener retailing tracker week step forward an...  \n",
       "1  offer script cordial reply instead actual cust...  \n",
       "2  get great talk fabian wesner new venture roq t...  \n",
       "3  recieve wrong item do n’t know item cheap item...  \n",
       "4                            send delivery paper bag  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>language</th>\n      <th>keyword</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n      <th>compound</th>\n      <th>lem</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>383</td>\n      <td>0</td>\n      <td>1323291682000000000</td>\n      <td>133</td>\n      <td>GreenerRetail</td>\n      <td>Who and what has made our greener retailing tr...</td>\n      <td>0</td>\n      <td>Planet Earth</td>\n      <td>05-Mar-2021</td>\n      <td>70</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>greener retailing tracker week step forward an...</td>\n      <td>Who and what has made our greener retailing tr...</td>\n      <td>0.0000</td>\n      <td>(greener, retailing, tracker, week, step, forw...</td>\n      <td>greener retailing tracker week step forward an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>384</td>\n      <td>1</td>\n      <td>1259761930000000000</td>\n      <td>1</td>\n      <td>fattybabycat</td>\n      <td>.@Zalando offers nothing more than scripted, c...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>offers scripted cordial replies instead actual...</td>\n      <td>offers nothing more than scripted, cordial rep...</td>\n      <td>-0.9060</td>\n      <td>(offers, scripted, cordial, replies, instead, ...</td>\n      <td>offer script cordial reply instead actual cust...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>385</td>\n      <td>2</td>\n      <td>835467350200000128</td>\n      <td>2296</td>\n      <td>piotrkarwatka</td>\n      <td>We've got a great talk with Fabian Wesner on h...</td>\n      <td>0</td>\n      <td>Wrocław, Polska</td>\n      <td>05-Mar-2021</td>\n      <td>1347</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>got great talk fabian wesner new venture roq t...</td>\n      <td>We've got great talk with Fabian Wesner his ne...</td>\n      <td>0.6249</td>\n      <td>(got, great, talk, fabian, wesner, new, ventur...</td>\n      <td>get great talk fabian wesner new venture roq t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>386</td>\n      <td>3</td>\n      <td>58485935</td>\n      <td>114</td>\n      <td>MissyDawn27586</td>\n      <td>@Zalando recieved wrong item... don’t know how...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>27</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>recieved wrong item don’t know item cheaper it...</td>\n      <td>recieved wrong item... don’t know how about th...</td>\n      <td>-0.4767</td>\n      <td>(recieved, wrong, item, do, n’t, know, item, c...</td>\n      <td>recieve wrong item do n’t know item cheap item...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>387</td>\n      <td>4</td>\n      <td>1059339104000000000</td>\n      <td>11725</td>\n      <td>CarolCooney7</td>\n      <td>@DrewLawDesign @Zalando  have sent me a few de...</td>\n      <td>0</td>\n      <td></td>\n      <td>05-Mar-2021</td>\n      <td>457</td>\n      <td>False</td>\n      <td>en</td>\n      <td>@zalando</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>sent deliveries paper bags</td>\n      <td>have sent few deliveries paper bags now.</td>\n      <td>0.0000</td>\n      <td>(sent, deliveries, paper, bags)</td>\n      <td>send delivery paper bag</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "eng_df.head()"
   ]
  },
  {
   "source": [
    "# Data description\n",
    "- tweet: initial tweet as it was downloaded from API\n",
    "- clean: tweet cleaned completely from punctuation, emojies, emoticons, stopwords, special characters, users, hashtags, links\n",
    "- clean_vader: tweet partly cleaned, saving punctuation, emoticons, emojies for using library Vader to get the sentiment of the tweet\n",
    "- compouns: from -1 (negative) to 1 (positive), 0 - neutral, a tweet sentiment derived fro, Vader library\n",
    "- lem: intermidiate step before lemmatization\n",
    "- lemma: lemmatized words (sent -> send)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Save the dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(eng_df, open(r'.\\data_n_models\\eng_df_labelled.pkl', 'wb'))"
   ]
  }
 ]
}