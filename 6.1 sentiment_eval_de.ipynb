{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Annelie\n[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package vader_lexicon to C:\\Users\\Annelie\n[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package punkt to C:\\Users\\Annelie\n[nltk_data]     Schridde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "#import functions\n",
    "#exec(open('./functions.py').read())\n",
    "%run functions.py\n",
    "import demoji\n",
    "#demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_bots(df):\n",
    "    #collect all the account names related to bots and scripts\n",
    "    names = []\n",
    "    pat = r'(bot\\s|script|bot_)'\n",
    "    for name in df.name.unique():\n",
    "        match = re.findall(pat, name, re.IGNORECASE) \n",
    "        if len(match) > 0:\n",
    "            names.append(name)\n",
    "    #look for a key words to identify a tweet related to bots and scripts\n",
    "    pattern = r\"(script|bot\\s|bots\\s|bot_|cook|cop^e|destroy|proxy)\"\n",
    "    df['bot'] = False\n",
    "    for i, row in df.iterrows():\n",
    "        match = re.findall(pattern, row.tweet, re.IGNORECASE) \n",
    "        if len(match) > 0 or row.isin(names)['name'] == True:\n",
    "            df['bot'].loc[i] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Annelie Schridde\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              user_id  user_statuses           name  \\\n",
       "0      1  1079317443523297280          12303     Boulder667   \n",
       "1      4            310342425          11476    AndyBaldauf   \n",
       "2     10   793418126532734976            521  MILESmobility   \n",
       "3     11  1119231287078858752             23       pici1303   \n",
       "4     12  1119231287078858752             23       pici1303   \n",
       "\n",
       "                                               tweet  retweets  \\\n",
       "0  @spdde @LadyBitchRay1 Viel Spaß, damit eine Wa...         0   \n",
       "1  @dicecco @Zalando aber erst wenn sie wieder dü...         0   \n",
       "2  Good News! Alle interessierten MitarbeiterInne...         0   \n",
       "3  @Zalando Ich weiß dass der Schein da rein muss...         0   \n",
       "4  @Zalando Ich hab mich nur gefragt wofür dieser...         0   \n",
       "\n",
       "                        location      created  followers  is_user_verified  \\\n",
       "0             Liverpool, England  07-Mar-2021        116             False   \n",
       "1  Thurgau | St. Gallen | Zürich  06-Mar-2021       1848             False   \n",
       "2            Berlin, Deutschland  05-Mar-2021        766             False   \n",
       "3                                 04-Mar-2021          0             False   \n",
       "4                                 04-Mar-2021          0             False   \n",
       "\n",
       "   favorite_count  in_reply_to_status_id  keyword language  \\\n",
       "0             1.0           1.368148e+18  zalando       de   \n",
       "1             0.0           1.368146e+18  zalando       de   \n",
       "2             8.0                    NaN  zalando       de   \n",
       "3             0.0           1.367531e+18  zalando       de   \n",
       "4             0.0           1.367528e+18  zalando       de   \n",
       "\n",
       "                                               clean  \\\n",
       "0  viel spaß damit eine wahl gewinnen stellt euch...   \n",
       "1         aber erst wenn sie wieder dürfen verspielt   \n",
       "2  good news alle interessierten mitarbeiterinnen...   \n",
       "3  ich weiß dass der schein rein muss aber ist mi...   \n",
       "4  ich hab mich nur gefragt wofür dieser extra co...   \n",
       "\n",
       "                                         clean_vader  compound  \\\n",
       "0  Viel Spaß, damit eine Wahl gewinnen. Stellt Eu...   -0.5994   \n",
       "1               aber erst wenn sie wieder dürfen :-P    0.4995   \n",
       "2  Good News! Alle interessierten MitarbeiterInne...   -0.7568   \n",
       "3  Ich weiß dass der Schein rein muss aber was is...    0.0000   \n",
       "4  Ich hab mich nur gefragt wofür dieser extra Co...    0.0000   \n",
       "\n",
       "                                               lemma    bot  \n",
       "0  viel spaß damit einen wahl gewinnen stellen si...  False  \n",
       "1        aber erst wenn ich wieder dürfen verspielen  False  \n",
       "2  good news all interessieren mitarbeiterinnen d...  False  \n",
       "3  ich weiß dass der schein rein muss aber sein m...  False  \n",
       "4  ich hab sich nur fragen wofür dies extra code ...  False  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n      <th>compound</th>\n      <th>lemma</th>\n      <th>bot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1079317443523297280</td>\n      <td>12303</td>\n      <td>Boulder667</td>\n      <td>@spdde @LadyBitchRay1 Viel Spaß, damit eine Wa...</td>\n      <td>0</td>\n      <td>Liverpool, England</td>\n      <td>07-Mar-2021</td>\n      <td>116</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.368148e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>viel spaß damit eine wahl gewinnen stellt euch...</td>\n      <td>Viel Spaß, damit eine Wahl gewinnen. Stellt Eu...</td>\n      <td>-0.5994</td>\n      <td>viel spaß damit einen wahl gewinnen stellen si...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>310342425</td>\n      <td>11476</td>\n      <td>AndyBaldauf</td>\n      <td>@dicecco @Zalando aber erst wenn sie wieder dü...</td>\n      <td>0</td>\n      <td>Thurgau | St. Gallen | Zürich</td>\n      <td>06-Mar-2021</td>\n      <td>1848</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.368146e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>aber erst wenn sie wieder dürfen verspielt</td>\n      <td>aber erst wenn sie wieder dürfen :-P</td>\n      <td>0.4995</td>\n      <td>aber erst wenn ich wieder dürfen verspielen</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>793418126532734976</td>\n      <td>521</td>\n      <td>MILESmobility</td>\n      <td>Good News! Alle interessierten MitarbeiterInne...</td>\n      <td>0</td>\n      <td>Berlin, Deutschland</td>\n      <td>05-Mar-2021</td>\n      <td>766</td>\n      <td>False</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>good news alle interessierten mitarbeiterinnen...</td>\n      <td>Good News! Alle interessierten MitarbeiterInne...</td>\n      <td>-0.7568</td>\n      <td>good news all interessieren mitarbeiterinnen d...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>1119231287078858752</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich weiß dass der Schein da rein muss...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.367531e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>ich weiß dass der schein rein muss aber ist mi...</td>\n      <td>Ich weiß dass der Schein rein muss aber was is...</td>\n      <td>0.0000</td>\n      <td>ich weiß dass der schein rein muss aber sein m...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>1119231287078858752</td>\n      <td>23</td>\n      <td>pici1303</td>\n      <td>@Zalando Ich hab mich nur gefragt wofür dieser...</td>\n      <td>0</td>\n      <td></td>\n      <td>04-Mar-2021</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.367528e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>ich hab mich nur gefragt wofür dieser extra co...</td>\n      <td>Ich hab mich nur gefragt wofür dieser extra Co...</td>\n      <td>0.0000</td>\n      <td>ich hab sich nur fragen wofür dies extra code ...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#load labelled data (generated in file 2.preprocessing_en)\n",
    "data = pickle.load(open('data_n_models/de_df_labelled.pkl', \"rb\"))\n",
    "data.head()\n",
    "#filter out bot related data\n",
    "data = classify_bots(data)\n",
    "data = data[data['bot']==False]\n",
    "data = data.drop_duplicates(subset=['lemma'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change compound from continous to categorical variable\n",
    "data[\"compound\"] = np.where(data[\"compound\"] > 0, 1, data[\"compound\"])\n",
    "data[\"compound\"] = np.where(data[\"compound\"] < 0, -1, data[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = data.sample(frac=1, random_state= 42) # shuffle data for random tweets to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    " # filter out 500 first tweets from shuffled data\n",
    " shuffled_df.iloc[0:500]#.to_csv('data_n_models/de_vader_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually labelled data in Excel and imported it again to our Github for further usage.\n",
    "# deleted compound so that the vader sentiment will not influence the manual labelling\n",
    "\n",
    "df = pd.read_csv('data_n_models/de_man_labelled_data_new.csv', sep = ';').drop('index', axis= 1) # drop everything except Sentiment and index for merging with original shuffled data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  Sentiment\n",
       "0        2087         -1\n",
       "1         287          0\n",
       "2        2127          0\n",
       "3          94          0\n",
       "4         250          1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2087</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>287</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2127</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>94</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>250</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      index              user_id  user_statuses      name  \\\n",
       "2087      1  1200528183164067841          25959  ToskaBoy   \n",
       "\n",
       "                                                 tweet  retweets location  \\\n",
       "2087  @FriedhofchiIIer Boohoo soll doch in Rente gehen         0            \n",
       "\n",
       "          created  followers  is_user_verified  favorite_count  \\\n",
       "2087  08-Apr-2021        251             False             3.0   \n",
       "\n",
       "      in_reply_to_status_id keyword language                         clean  \\\n",
       "2087           1.380103e+18  boohoo       de  boohoo soll doch rente gehen   \n",
       "\n",
       "                       clean_vader  compound                         lemma  \\\n",
       "2087  Boohoo soll doch Rente gehen       0.0  boohoo soll doch rente gehen   \n",
       "\n",
       "        bot  \n",
       "2087  False  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n      <th>compound</th>\n      <th>lemma</th>\n      <th>bot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2087</th>\n      <td>1</td>\n      <td>1200528183164067841</td>\n      <td>25959</td>\n      <td>ToskaBoy</td>\n      <td>@FriedhofchiIIer Boohoo soll doch in Rente gehen</td>\n      <td>0</td>\n      <td></td>\n      <td>08-Apr-2021</td>\n      <td>251</td>\n      <td>False</td>\n      <td>3.0</td>\n      <td>1.380103e+18</td>\n      <td>boohoo</td>\n      <td>de</td>\n      <td>boohoo soll doch rente gehen</td>\n      <td>Boohoo soll doch Rente gehen</td>\n      <td>0.0</td>\n      <td>boohoo soll doch rente gehen</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "shuffled_df[shuffled_df.index == 2087] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner merge for only data with vader and manual sentiment, merging on indexes\n",
    "\n",
    "merged_df = pd.merge(shuffled_df, df, right_on='Unnamed: 0', left_index=True, how = 'inner') # Unnamed is here the old index for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(['Unnamed: 0'], axis = 1) # afterwards we can drop it, as we have the original index from the left dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop('index', axis = 1).reset_index().drop('index', axis = 1).reset_index() # same for the index and we can reset everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.Sentiment = merged_df.Sentiment.astype('float64') # changing Sentiment to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     index              user_id  user_statuses             name  \\\n",
       "39      79  1358102479657967618           3586  localbunnybitch   \n",
       "107    256           1027214204          67514   JudicatorPredo   \n",
       "144    155             33618241           7969     cyclist_city   \n",
       "52      86             23059415          14583         birgitzz   \n",
       "196     25  1250097593612472322           1868        zItzMatze   \n",
       "\n",
       "                                                 tweet  retweets  \\\n",
       "39   @whosmartinn Achsooooo ja hm\\nAlso bei vinted ...         0   \n",
       "107  @undalles0yeah @isi_peazy Weiß gar nicht, ob Z...         0   \n",
       "144  @Zalando_Press @Vizions2017 Super! Warum nicht...         0   \n",
       "52   Von wegen, Umsatzeinbruch während Corona --&gt...         2   \n",
       "196  @aycaxkaya asos, die hatten da zwei übelst nic...         0   \n",
       "\n",
       "                location      created  followers  is_user_verified  \\\n",
       "39               she/her  01-Mar-2021        207             False   \n",
       "107    Mitte des Flusses  12-Apr-2021        314             False   \n",
       "144      Berlin, Germany  02-Mar-2021       1223             False   \n",
       "52   Zurich, Switzerland  15-Mar-2021       1280             False   \n",
       "196     bei mir zu hause  04-Apr-2021         31             False   \n",
       "\n",
       "     favorite_count  in_reply_to_status_id  keyword language  \\\n",
       "39              2.0           1.366471e+18     asos       de   \n",
       "107             1.0           1.381686e+18  zalando       de   \n",
       "144             3.0                    NaN  zalando       de   \n",
       "52              2.0                    NaN  zalando       de   \n",
       "196             1.0           1.378645e+18     asos       de   \n",
       "\n",
       "                                                 clean  \\\n",
       "39   achsooooo hmalso bei vinted sind immer ganz ni...   \n",
       "107  weiß gar nicht zalando überhaupt schwarze zahl...   \n",
       "144              super warum nicht eurer heimat berlin   \n",
       "52   von wegen umsatzeinbruch während corona zaland...   \n",
       "196           asos die hatten zwei übelst nice tshirts   \n",
       "\n",
       "                                           clean_vader  compound  \\\n",
       "39   Achsooooo hmAlso bei vinted sind immer ganz ni...       1.0   \n",
       "107  Weiß gar nicht, Zalando überhaupt schwarze Zah...       0.0   \n",
       "144            Super! Warum nicht eurer Heimat Berlin?       1.0   \n",
       "52   Von wegen, Umsatzeinbruch während Corona --&gt...       0.0   \n",
       "196          asos, die hatten zwei übelst nice tshirts      -1.0   \n",
       "\n",
       "                                                 lemma    bot  Sentiment  \n",
       "39   achsooooo hmalso bei vinted sein immer ganz ni...  False        1.0  \n",
       "107  weiß gar nicht zalando überhaupt schwarze zahl...  False        0.0  \n",
       "144              super warum nicht eurer heimat berlin  False        1.0  \n",
       "52   von wegen umsatzeinbruch während corona zaland...  False        1.0  \n",
       "196            asos der haben zwei übelst nice tshirts  False        1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>user_statuses</th>\n      <th>name</th>\n      <th>tweet</th>\n      <th>retweets</th>\n      <th>location</th>\n      <th>created</th>\n      <th>followers</th>\n      <th>is_user_verified</th>\n      <th>favorite_count</th>\n      <th>in_reply_to_status_id</th>\n      <th>keyword</th>\n      <th>language</th>\n      <th>clean</th>\n      <th>clean_vader</th>\n      <th>compound</th>\n      <th>lemma</th>\n      <th>bot</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td>79</td>\n      <td>1358102479657967618</td>\n      <td>3586</td>\n      <td>localbunnybitch</td>\n      <td>@whosmartinn Achsooooo ja hm\\nAlso bei vinted ...</td>\n      <td>0</td>\n      <td>she/her</td>\n      <td>01-Mar-2021</td>\n      <td>207</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>1.366471e+18</td>\n      <td>asos</td>\n      <td>de</td>\n      <td>achsooooo hmalso bei vinted sind immer ganz ni...</td>\n      <td>Achsooooo hmAlso bei vinted sind immer ganz ni...</td>\n      <td>1.0</td>\n      <td>achsooooo hmalso bei vinted sein immer ganz ni...</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>256</td>\n      <td>1027214204</td>\n      <td>67514</td>\n      <td>JudicatorPredo</td>\n      <td>@undalles0yeah @isi_peazy Weiß gar nicht, ob Z...</td>\n      <td>0</td>\n      <td>Mitte des Flusses</td>\n      <td>12-Apr-2021</td>\n      <td>314</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.381686e+18</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>weiß gar nicht zalando überhaupt schwarze zahl...</td>\n      <td>Weiß gar nicht, Zalando überhaupt schwarze Zah...</td>\n      <td>0.0</td>\n      <td>weiß gar nicht zalando überhaupt schwarze zahl...</td>\n      <td>False</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>155</td>\n      <td>33618241</td>\n      <td>7969</td>\n      <td>cyclist_city</td>\n      <td>@Zalando_Press @Vizions2017 Super! Warum nicht...</td>\n      <td>0</td>\n      <td>Berlin, Germany</td>\n      <td>02-Mar-2021</td>\n      <td>1223</td>\n      <td>False</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>super warum nicht eurer heimat berlin</td>\n      <td>Super! Warum nicht eurer Heimat Berlin?</td>\n      <td>1.0</td>\n      <td>super warum nicht eurer heimat berlin</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>86</td>\n      <td>23059415</td>\n      <td>14583</td>\n      <td>birgitzz</td>\n      <td>Von wegen, Umsatzeinbruch während Corona --&amp;gt...</td>\n      <td>2</td>\n      <td>Zurich, Switzerland</td>\n      <td>15-Mar-2021</td>\n      <td>1280</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>zalando</td>\n      <td>de</td>\n      <td>von wegen umsatzeinbruch während corona zaland...</td>\n      <td>Von wegen, Umsatzeinbruch während Corona --&amp;gt...</td>\n      <td>0.0</td>\n      <td>von wegen umsatzeinbruch während corona zaland...</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>25</td>\n      <td>1250097593612472322</td>\n      <td>1868</td>\n      <td>zItzMatze</td>\n      <td>@aycaxkaya asos, die hatten da zwei übelst nic...</td>\n      <td>0</td>\n      <td>bei mir zu hause</td>\n      <td>04-Apr-2021</td>\n      <td>31</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.378645e+18</td>\n      <td>asos</td>\n      <td>de</td>\n      <td>asos die hatten zwei übelst nice tshirts</td>\n      <td>asos, die hatten zwei übelst nice tshirts</td>\n      <td>-1.0</td>\n      <td>asos der haben zwei übelst nice tshirts</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sentiment  -1.0   0.0   1.0\n",
       "compound                   \n",
       "-1.0         38    23    17\n",
       " 0.0         21    61    22\n",
       " 1.0          4     5    14"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Sentiment</th>\n      <th>-1.0</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>compound</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1.0</th>\n      <td>38</td>\n      <td>23</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>0.0</th>\n      <td>21</td>\n      <td>61</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>4</td>\n      <td>5</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "# column 'compound' from vader -> predicted values\n",
    "# column 'Sentiment' own labelled data -> true values\n",
    "# in order to determine the correctness of vader's sentiment evaluation we can use the confusion matrix to determine the false postives and negatives.\n",
    "\n",
    "pd.crosstab(merged_df.compound, merged_df.Sentiment, rownames=['compound'], colnames=['Sentiment'])\n"
   ]
  },
  {
   "source": [
    "True Positive (TP) \n",
    "\n",
    "    The predicted value matches the actual value\n",
    "    The actual value was positive and the model predicted a positive value\n",
    "\n",
    "True Negative (TN) \n",
    "\n",
    "    The predicted value matches the actual value\n",
    "    The actual value was negative and the model predicted a negative value\n",
    "\n",
    "False Positive (FP) – Type 1 error\n",
    "\n",
    "    The predicted value was falsely predicted\n",
    "    The actual value was negative but the model predicted a positive value\n",
    "    Also known as the Type 1 error\n",
    "\n",
    "False Negative (FN) – Type 2 error\n",
    "\n",
    "    The predicted value was falsely predicted\n",
    "    The actual value was positive but the model predicted a negative value\n",
    "    Also known as the Type 2 error\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}